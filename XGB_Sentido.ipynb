{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmdiegoar/Quant-code-t0/blob/main/XGB_Sentido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LA MEJORA DE GROK"
      ],
      "metadata": {
        "id": "oqaw_AHkEbnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mas listo que ayer"
      ],
      "metadata": {
        "id": "6x9IIbsCpVUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import files  # Para descargar el CSV en Colab\n",
        "from scipy import stats\n",
        "\n",
        "# Funciones de features\n",
        "def add_lagged_price_features(df):\n",
        "    for lag in range(1, 6):\n",
        "        df[f'close_lag_{lag}'] = df['Close'].shift(lag)\n",
        "    return df\n",
        "\n",
        "def calculate_RSI(series, period=7):\n",
        "    delta = series.diff(1)\n",
        "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def calculate_ROC(series, period=5):\n",
        "    return ((series - series.shift(period)) / series.shift(period)) * 100\n",
        "\n",
        "def calculate_PPO(series, fast_period=5, slow_period=9, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ppo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ppo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ppo - signal_line\n",
        "    return ppo, signal_line, histogram\n",
        "\n",
        "def calculate_volatility(series, window=20):\n",
        "    return series.rolling(window).std()\n",
        "\n",
        "def calculate_sma(series, period=5):\n",
        "    return series.rolling(window=period).mean()\n",
        "\n",
        "def calculate_sma21(series, period=21):\n",
        "    return series.rolling(window=period).mean()\n",
        "\n",
        "def calculate_sma30(series, period=30):\n",
        "    return series.rolling(window=period).mean()\n",
        "\n",
        "def calculate_earnings_season(df):\n",
        "    df['Is_Earnings_Season'] = df.index.month.isin([1, 4, 7, 10])\n",
        "    return df\n",
        "\n",
        "def calculate_christmas_rally(df):\n",
        "    df['Is_Christmas_Rally'] = df.index.month.isin([11, 12])\n",
        "    return df\n",
        "\n",
        "def create_features(df):\n",
        "    df = add_lagged_price_features(df)\n",
        "    df['Pct_change'] = df['Close'].pct_change()\n",
        "    for lag in range(1, 6):\n",
        "        df[f'lag_{lag}'] = df['Pct_change'].shift(lag)\n",
        "    df['RSI'] = calculate_RSI(df['Close'])\n",
        "    df['ROC'] = calculate_ROC(df['Close'])\n",
        "    df['PPO'], df['PPO_Signal'], df['PPO_Histogram'] = calculate_PPO(df['Close'])\n",
        "    df['SMA'] = calculate_sma(df['Close'])\n",
        "    df['SMA21'] = calculate_sma21(df['Close'])\n",
        "    df['SMA30'] = calculate_sma30(df['Close'])\n",
        "    df['Volatility'] = calculate_volatility(df['Close'])\n",
        "    df['Label'] = (df['Pct_change'] > 0).astype(int)\n",
        "    df['Return'] = np.log(df['Close'] / df['Close'].shift())\n",
        "    df = calculate_earnings_season(df)\n",
        "    df = calculate_christmas_rally(df)\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "# Definir fecha de corte manualmente (cambiar diariamente)\n",
        "end_date = dt.datetime(2025, 7, 20)  # Ejemplo: cambiar a 2025-07-18 mañana\n",
        "symbol=\"GGAL\"\n",
        "symbol=\"COME.BA\"\n",
        "# Fechas dinámicas\n",
        "start_date = dt.datetime(2001, 1, 1)  # Inicio fijo\n",
        "train_end = end_date - pd.Timedelta(days=780)  # 6 meses antes de end_date (ajustable)\n",
        "next_day = end_date + pd.Timedelta(days=1)  # Predicción para el día siguiente\n",
        "backtest_start = end_date - pd.Timedelta(days=5)  # Inicio del backtesting 6 meses antes de end_date (ajustable)\n",
        "\n",
        "# Descargar datos\n",
        "df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=False)\n",
        "\n",
        "# Verificar datos\n",
        "if df.empty:\n",
        "    raise ValueError(\"No se pudieron descargar datos. Verifica el símbolo, las fechas o la conexión.\")\n",
        "\n",
        "# Aplanar MultiIndex si existe\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    print(\"MultiIndex detectado en columnas. Aplanando...\")\n",
        "    df.columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "    print(\"Columnas asignadas después de aplanamiento:\", df.columns.tolist())\n",
        "    print(\"Últimas filas antes de corrección:\", df.tail())\n",
        "\n",
        "    # Corregir el orden de las columnas según tu mapeo\n",
        "    columns = df.columns.tolist()\n",
        "    df = df[[columns[4], columns[2], columns[3], columns[0], columns[5], columns[1]]]  # Reordenar\n",
        "    df.columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']  # Asignar nombres correctos\n",
        "    print(\"Últimas filas después de corrección:\", df.tail())\n",
        "\n",
        "if isinstance(df.index, pd.MultiIndex):\n",
        "    print(\"MultiIndex detectado en índice. Seleccionando ticker...\")\n",
        "    df = df.xs(symbol, level='Ticker', axis=0)\n",
        "df.index = pd.to_datetime(df.index)  # Asegurar índice datetime\n",
        "if not df.index.is_unique:\n",
        "    print(\"Advertencia: Índice con fechas duplicadas. Eliminando duplicados...\")\n",
        "    df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "# Verificar columnas\n",
        "print(\"Columnas del DataFrame después de descargar y corregir:\")\n",
        "print(df.columns)\n",
        "print(\"Últimas filas del DataFrame antes de crear features:\")\n",
        "print(df.tail())\n",
        "\n",
        "# Crear features\n",
        "df = create_features(df)\n",
        "\n",
        "# Verificar datos después de crear features\n",
        "print(\"\\nÚltimas filas del DataFrame después de crear features:\")\n",
        "print(df.tail())\n",
        "\n",
        "# Seleccionar features\n",
        "features = ['RSI', 'ROC', 'PPO', 'PPO_Signal', 'PPO_Histogram', 'Volatility', 'SMA', 'SMA21', 'SMA30',\n",
        "            'Is_Christmas_Rally', 'Is_Earnings_Season'] + [f'lag_{i}' for i in range(1, 6)] + \\\n",
        "           [f'close_lag_{i}' for i in range(1, 6)]\n",
        "X = df[features]\n",
        "y = df['Label']\n",
        "\n",
        "# Dividir datos en entrenamiento y prueba\n",
        "X_train_full = X[df.index <= train_end]\n",
        "y_train_full = y[df.index <= train_end]\n",
        "X_test = X[(df.index > train_end) & (df.index <= end_date)]  # Hasta end_date\n",
        "y_test = y[(df.index > train_end) & (df.index <= end_date)]\n",
        "\n",
        "# Optimizar hiperparámetros con RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'n_estimators': [100, 500, 900],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=20, cv=5, scoring='f1', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train_full, y_train_full)\n",
        "print(\"Mejores hiperparámetros:\", random_search.best_params_)\n",
        "\n",
        "# Usar el mejor modelo\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Optimizar el umbral\n",
        "y_train_prob = best_model.predict_proba(X_train_full)[:, 1]\n",
        "thresholds = np.arange(0.1, 0.9, 0.1)\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "for threshold in thresholds:\n",
        "    y_pred_threshold = (y_train_prob >= threshold).astype(int)\n",
        "    f1 = f1_score(y_train_full, y_pred_threshold)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = threshold\n",
        "print(\"Mejor umbral:\", best_threshold)\n",
        "\n",
        "#best_threshold=0.15\n",
        "\n",
        "\n",
        "# Backtesting con escalado dinámico para evitar data leak\n",
        "dates = df[(df.index >= backtest_start) & (df.index <= end_date)].index\n",
        "results = []\n",
        "\n",
        "for test_date in dates:\n",
        "    train_data = df[df.index < test_date].copy()\n",
        "    if train_data.empty or train_data['Label'].isna().all():\n",
        "        continue\n",
        "    train_data = train_data.dropna()\n",
        "\n",
        "    X_train_loop = train_data[features]\n",
        "    y_train_loop = train_data['Label']\n",
        "\n",
        "    scaler = StandardScaler()  # Reinicio dinámico del escalador\n",
        "    X_train_scaled = scaler.fit_transform(X_train_loop)\n",
        "    print(f\"Escalando datos hasta {train_data.index[-1]} para predecir {test_date}\")\n",
        "\n",
        "    best_model.fit(X_train_scaled, y_train_loop)\n",
        "\n",
        "    if test_date in df.index:\n",
        "        test_row = df.loc[[test_date]][features]\n",
        "        if test_row.empty:\n",
        "            continue\n",
        "        test_row_scaled = scaler.transform(test_row)\n",
        "\n",
        "        prediction_prob = best_model.predict_proba(test_row_scaled)[0][1]\n",
        "        prediction = 1 if prediction_prob >= best_threshold else 0\n",
        "\n",
        "        real_direction = df.loc[test_date, 'Label'] if pd.notna(df.loc[test_date, 'Label']) else None\n",
        "        close_price = df.loc[test_date, 'Close']\n",
        "\n",
        "        is_correct = int(prediction == real_direction) if real_direction is not None else None\n",
        "        data_date = df.index[df.index < test_date][-1] if not df[df.index < test_date].empty else None\n",
        "\n",
        "        results.append({\n",
        "            'Fecha Predicción': test_date,\n",
        "            'Fecha Datos': data_date,\n",
        "            'Predicción': 'Alcista' if prediction == 1 else 'Bajista',\n",
        "            'Resultado Real': 'Alcista' if real_direction == 1 else 'Bajista' if real_direction == 0 else None,\n",
        "            'Precio Cierre': close_price,\n",
        "            'Probabilidad Alcista': prediction_prob,\n",
        "            'Correcta': 'Sí' if is_correct == 1 else 'No' if is_correct == 0 else None\n",
        "        })\n",
        "\n",
        "# Crear tabla de resultados\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.set_index('Fecha Predicción', inplace=True)\n",
        "\n",
        "# Mostrar resultados\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(\"\\nResultados del backtesting (hasta\", end_date.strftime('%Y-%m-%d'), \"):\")\n",
        "print(\"Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\")\n",
        "print(results_df)\n",
        "\n",
        "# Guardar y descargar el CSV\n",
        "results_df.to_csv(f\"backtesting_results_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "files.download(f\"backtesting_results_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "print(f\"\\nArchivo 'backtesting_results_{end_date.strftime('%Y-%m-%d')}.csv' generado y descargado.\")\n",
        "\n",
        "# Métricas del backtesting\n",
        "#if results_df['Correcta'].notna().sum() > 0:\n",
        "#    accuracy = (results_df['Correcta'] == 'Sí').sum() / results_df['Correcta'].notna().sum()\n",
        "#    print(f\"\\nAccuracy del backtesting: {accuracy:.2%}\")\n",
        "\n",
        "#    valid_results = results_df[results_df['Correcta'].notna()]\n",
        "#    y_true = [1 if r == 'Alcista' else 0 for r in valid_results['Resultado Real']]\n",
        "#    y_pred = [1 if p == 'Alcista' else 0 for p in valid_results['Predicción']]\n",
        "#    print(\"\\nMatriz de Confusión:\")\n",
        "#    print(confusion_matrix(y_true, y_pred))\n",
        "#    print(\"\\nInforme de Clasificación:\")\n",
        "#    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# ROC-AUC para entrenamiento y prueba\n",
        "if not X_train_full.empty and not X_test.empty:\n",
        "    X_train_scaled = StandardScaler().fit_transform(X_train_full)\n",
        "    X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "    best_model.fit(X_train_scaled, y_train_full)\n",
        "    train_pred_proba = best_model.predict_proba(X_train_scaled)[:, 1]\n",
        "    test_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    roc_auc_train = roc_auc_score(y_train_full, train_pred_proba)\n",
        "    roc_auc_test = roc_auc_score(y_test, test_pred_proba)\n",
        "    # Verificar tamaños de las muestras\n",
        "    print(f\"Tamaño de y_train_full: {y_train_full.size}\")\n",
        "    print(f\"Tamaño de y_test: {y_test.size}\")\n",
        "    print(\"Distribución de clases en y_train_full:\")\n",
        "    print(y_train_full.value_counts())\n",
        "    print(\"Distribución de clases en y_test:\")\n",
        "    print(y_test.value_counts())\n",
        "\n",
        "\n",
        "    print(f\"\\nROC-AUC en el conjunto de entrenamiento: {roc_auc_train:.4f}\")\n",
        "    print(roc_auc_train)\n",
        "    print(f\"ROC-AUC en el conjunto de prueba: {roc_auc_test:.4f}\")\n",
        "    y_pred_test = (best_model.predict_proba(X_test_scaled)[:, 1] >= 0.3).astype(int)\n",
        "    print(\"\\nMatriz de Confusión (prueba):\")\n",
        "    print(confusion_matrix(y_test, y_pred_test))\n",
        "    print(\"\\nInforme de Clasificación (prueba):\")\n",
        "    print(classification_report(y_test, y_pred_test))\n",
        "else:\n",
        "    print(\"\\nAdvertencia: Conjunto de prueba o entrenamiento insuficiente. No se calculó ROC-AUC.\")\n",
        "\n",
        "# Predicción para el día siguiente\n",
        "last_features = df[features].iloc[-1:]\n",
        "scaler = StandardScaler()\n",
        "last_features_scaled = scaler.fit_transform(last_features)\n",
        "future_pred_prob = best_model.predict_proba(last_features_scaled)[0][1]\n",
        "future_pred = 1 if future_pred_prob >= best_threshold else 0\n",
        "\n",
        "returns = df['Return'].dropna()\n",
        "mean_return = returns.mean()\n",
        "std_return = returns.std()\n",
        "last_close = df['Close'].iloc[-1]\n",
        "expected_price = last_close * np.exp(mean_return + 0.5 * std_return**2)\n",
        "price_prob = future_pred_prob if future_pred == 1 else 1 - future_pred_prob\n",
        "\n",
        "action = 'BUY' if future_pred == 1 else 'SELL'\n",
        "direction = 1 if future_pred == 1 else -1\n",
        "\n",
        "print(f\"\\nPredicción para {next_day.strftime('%Y-%m-%d')} (basada en datos hasta {df.index[-1].strftime('%Y-%m-%d')}):\")\n",
        "print(f\"Papel: {symbol}\")\n",
        "print(f\"Precio actual: [{last_close:.4f}]\")\n",
        "print(f\"Precio esperado para el siguiente día (distribución log-normal): [{expected_price:.4f}]\")\n",
        "print(f\"Probabilidad de que el precio predicho sea correcto: [{price_prob:.4f}]\")\n",
        "print(f\"Corte: {df.index[-1]}\")\n",
        "print(f\"\\nPredicción para {next_day.strftime('%Y-%m-%d')}: {'Alcista' if future_pred == 1 else 'Bajista'} (Probabilidad Alcista: {future_pred_prob:.2%})\")\n",
        "print(f\"Pronóstico de dirección del activo (1: subida, -1: bajada): {direction}\")\n",
        "print(f\"Acción sugerida por la estrategia de trading: {action}\")"
      ],
      "metadata": {
        "id": "OReUSMZapafA",
        "outputId": "eeed036b-82e3-4aa5-cf0d-83640663a672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex detectado en columnas. Aplanando...\n",
            "Columnas asignadas después de aplanamiento: ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
            "Últimas filas antes de corrección:               Open    High     Low   Close  Volume  Adj Close\n",
            "Date                                                         \n",
            "2025-07-11  113.00  113.00  116.75  112.00  114.00    3962018\n",
            "2025-07-14  116.75  116.75  117.00  110.75  113.00    6049860\n",
            "2025-07-15  117.25  117.25  119.75  115.00  116.75    4634404\n",
            "2025-07-16  114.75  114.75  117.50  113.25  117.00    2916160\n",
            "2025-07-17  116.50  116.50  118.25  113.75  114.75    3290862\n",
            "Últimas filas después de corrección:               Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-07-11  114.00  116.75  112.00  113.00  3962018     113.00\n",
            "2025-07-14  113.00  117.00  110.75  116.75  6049860     116.75\n",
            "2025-07-15  116.75  119.75  115.00  117.25  4634404     117.25\n",
            "2025-07-16  117.00  117.50  113.25  114.75  2916160     114.75\n",
            "2025-07-17  114.75  118.25  113.75  116.50  3290862     116.50\n",
            "Columnas del DataFrame después de descargar y corregir:\n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'], dtype='object')\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-07-11  114.00  116.75  112.00  113.00  3962018     113.00\n",
            "2025-07-14  113.00  117.00  110.75  116.75  6049860     116.75\n",
            "2025-07-15  116.75  119.75  115.00  117.25  4634404     117.25\n",
            "2025-07-16  117.00  117.50  113.25  114.75  2916160     114.75\n",
            "2025-07-17  114.75  118.25  113.75  116.50  3290862     116.50\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-07-11  114.00  116.75  112.00  113.00  3962018     113.00       116.00   \n",
            "2025-07-14  113.00  117.00  110.75  116.75  6049860     116.75       113.00   \n",
            "2025-07-15  116.75  119.75  115.00  117.25  4634404     117.25       116.75   \n",
            "2025-07-16  117.00  117.50  113.25  114.75  2916160     114.75       117.25   \n",
            "2025-07-17  114.75  118.25  113.75  116.50  3290862     116.50       114.75   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  Pct_change  \\\n",
            "Date                                                                         \n",
            "2025-07-11       115.50       114.50        119.0       121.75   -0.025862   \n",
            "2025-07-14       116.00       115.50        114.5       119.00    0.033186   \n",
            "2025-07-15       113.00       116.00        115.5       114.50    0.004283   \n",
            "2025-07-16       116.75       113.00        116.0       115.50   -0.021322   \n",
            "2025-07-17       117.25       116.75        113.0       116.00    0.015251   \n",
            "\n",
            "               lag_1     lag_2     lag_3     lag_4     lag_5        RSI  \\\n",
            "Date                                                                      \n",
            "2025-07-11  0.004329  0.008734 -0.037815 -0.022587 -0.012170  29.850746   \n",
            "2025-07-14 -0.025862  0.004329  0.008734 -0.037815 -0.022587  30.882353   \n",
            "2025-07-15  0.033186 -0.025862  0.004329  0.008734 -0.037815  35.937500   \n",
            "2025-07-16  0.004283  0.033186 -0.025862  0.004329  0.008734  36.507937   \n",
            "2025-07-17 -0.021322  0.004283  0.033186 -0.025862  0.004329  57.692308   \n",
            "\n",
            "                 ROC       PPO  PPO_Signal  PPO_Histogram     SMA       SMA21  \\\n",
            "Date                                                                            \n",
            "2025-07-11 -7.186858 -2.002006   -2.020767       0.018761  115.60  126.142857   \n",
            "2025-07-14 -1.890756 -1.497358   -1.846297       0.348939  115.15  124.738095   \n",
            "2025-07-15  2.401747 -1.070419   -1.587671       0.517252  115.70  123.464286   \n",
            "2025-07-16 -0.649351 -1.058986   -1.411443       0.352457  115.55  121.988095   \n",
            "2025-07-17  0.431034 -0.781060   -1.201315       0.420255  115.65  120.952381   \n",
            "\n",
            "                 SMA30  Volatility  Label    Return  Is_Earnings_Season  \\\n",
            "Date                                                                      \n",
            "2025-07-11  133.591667    9.273787      0 -0.026202                True   \n",
            "2025-07-14  131.925000    8.308168      1  0.032647                True   \n",
            "2025-07-15  130.525000    6.611593      1  0.004274                True   \n",
            "2025-07-16  129.183333    5.656331      0 -0.021553                True   \n",
            "2025-07-17  128.291667    5.071528      1  0.015135                True   \n",
            "\n",
            "            Is_Christmas_Rally  \n",
            "Date                            \n",
            "2025-07-11               False  \n",
            "2025-07-14               False  \n",
            "2025-07-15               False  \n",
            "2025-07-16               False  \n",
            "2025-07-17               False  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores hiperparámetros: {'subsample': 0.6, 'n_estimators': 900, 'max_depth': 5, 'learning_rate': 0.2, 'gamma': 0.1, 'colsample_bytree': 1.0}\n",
            "Mejor umbral: 0.2\n",
            "Escalando datos hasta 2025-07-14 00:00:00 para predecir 2025-07-15 00:00:00\n",
            "Escalando datos hasta 2025-07-15 00:00:00 para predecir 2025-07-16 00:00:00\n",
            "Escalando datos hasta 2025-07-16 00:00:00 para predecir 2025-07-17 00:00:00\n",
            "\n",
            "Resultados del backtesting (hasta 2025-07-20 ):\n",
            "Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\n",
            "                 Fecha Datos Predicción Resultado Real  Precio Cierre  \\\n",
            "Fecha Predicción                                                        \n",
            "2025-07-15        2025-07-14    Alcista        Alcista         117.25   \n",
            "2025-07-16        2025-07-15    Bajista        Bajista         114.75   \n",
            "2025-07-17        2025-07-16    Alcista        Alcista         116.50   \n",
            "\n",
            "                  Probabilidad Alcista Correcta  \n",
            "Fecha Predicción                                 \n",
            "2025-07-15                    0.972547       Sí  \n",
            "2025-07-16                    0.005845       Sí  \n",
            "2025-07-17                    0.998234       Sí  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_52f3a39a-4c6e-43e1-b46d-3d6aa437abd8\", \"backtesting_results_2025-07-20.csv\", 280)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Archivo 'backtesting_results_2025-07-20.csv' generado y descargado.\n",
            "Tamaño de y_train_full: 5542\n",
            "Tamaño de y_test: 518\n",
            "Distribución de clases en y_train_full:\n",
            "Label\n",
            "0    3218\n",
            "1    2324\n",
            "Name: count, dtype: int64\n",
            "Distribución de clases en y_test:\n",
            "Label\n",
            "1    273\n",
            "0    245\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ROC-AUC en el conjunto de entrenamiento: 1.0000\n",
            "1.0\n",
            "ROC-AUC en el conjunto de prueba: 0.9576\n",
            "\n",
            "Matriz de Confusión (prueba):\n",
            "[[237   8]\n",
            " [ 52 221]]\n",
            "\n",
            "Informe de Clasificación (prueba):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89       245\n",
            "           1       0.97      0.81      0.88       273\n",
            "\n",
            "    accuracy                           0.88       518\n",
            "   macro avg       0.89      0.89      0.88       518\n",
            "weighted avg       0.90      0.88      0.88       518\n",
            "\n",
            "\n",
            "Predicción para 2025-07-21 (basada en datos hasta 2025-07-17):\n",
            "Papel: COME.BA\n",
            "Precio actual: [116.5000]\n",
            "Precio esperado para el siguiente día (distribución log-normal): [116.7305]\n",
            "Probabilidad de que el precio predicho sea correcto: [0.7370]\n",
            "Corte: 2025-07-17 00:00:00\n",
            "\n",
            "Predicción para 2025-07-21: Alcista (Probabilidad Alcista: 73.70%)\n",
            "Pronóstico de dirección del activo (1: subida, -1: bajada): 1\n",
            "Acción sugerida por la estrategia de trading: BUY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMIENZA EL UMBRAL"
      ],
      "metadata": {
        "id": "xjiSoEl0ijkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "\n",
        "# Descargar datos (si no lo hiciste aún)\n",
        "end_date = dt.datetime(2025, 7, 20)\n",
        "df = yf.download(\"COME.BA\", start=dt.datetime(2001, 1, 1), end=end_date)\n",
        "\n",
        "# Definir umbral (por ejemplo, 2%)\n",
        "umbral = 0.02\n",
        "\n",
        "# Calcular la diferencia relativa y etiquetar\n",
        "df['Label'] = ((df['High'] - df['Open']) / df['Open'] > umbral).astype(int) * 2 - 1\n",
        "\n",
        "# Contar etiquetas y calcular porcentajes\n",
        "label_counts = df['Label'].value_counts()\n",
        "total_dias = len(df)\n",
        "percentages = (label_counts / total_dias) * 100\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Conteo de etiquetas:\")\n",
        "print(label_counts)\n",
        "print(\"\\nPorcentajes de cada clase (%):\")\n",
        "print(percentages.round(2))\n",
        "\n",
        "# Opcional: Ver los primeros días etiquetados\n",
        "print(\"\\nPrimeros días etiquetados:\")\n",
        "print(df[['Open', 'High', 'Label']].tail(20))\n",
        "print(\"mambral\")\n",
        "umbral = df['High'].sub(df['Open']).div(df['Open']).quantile(0.75)\n",
        "print(umbral)\n",
        "df['Label'] = ((df['High'] - df['Open']) / df['Open'] > umbral).astype(int) * 2 - 1\n",
        "print(df['Label'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Contar etiquetas y calcular porcentajes\n",
        "label_counts = df['Label'].value_counts()\n",
        "total_dias = len(df)\n",
        "percentages = (label_counts / total_dias) * 100\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Conteo de etiquetas:\")\n",
        "print(label_counts)\n",
        "print(\"\\nPorcentajes de cada clase (%):\")\n",
        "print(percentages.round(2))"
      ],
      "metadata": {
        "id": "-ItKP7EgLl9v",
        "outputId": "110c975b-2b1e-438b-f39f-31e42c78c6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-761599286.py:7: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(\"COME.BA\", start=dt.datetime(2001, 1, 1), end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteo de etiquetas:\n",
            "Label\n",
            "-1    3948\n",
            " 1    2151\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Porcentajes de cada clase (%):\n",
            "Label\n",
            "-1    64.73\n",
            " 1    35.27\n",
            "Name: count, dtype: float64\n",
            "\n",
            "Primeros días etiquetados:\n",
            "Price         Open    High Label\n",
            "Ticker     COME.BA COME.BA      \n",
            "Date                            \n",
            "2025-06-18  132.00  134.00    -1\n",
            "2025-06-19  130.00  132.25    -1\n",
            "2025-06-23  130.00  130.00    -1\n",
            "2025-06-24  124.00  129.50     1\n",
            "2025-06-25  126.00  127.50    -1\n",
            "2025-06-26  123.75  126.75     1\n",
            "2025-06-27  122.75  125.50     1\n",
            "2025-06-30  124.25  126.50    -1\n",
            "2025-07-01  118.25  122.00     1\n",
            "2025-07-02  121.25  123.50    -1\n",
            "2025-07-03  122.50  126.25     1\n",
            "2025-07-04  122.00  122.25    -1\n",
            "2025-07-07  118.25  118.50    -1\n",
            "2025-07-08  115.00  119.00     1\n",
            "2025-07-10  114.00  117.00     1\n",
            "2025-07-11  114.00  116.75     1\n",
            "2025-07-14  113.00  117.00     1\n",
            "2025-07-15  116.75  119.75     1\n",
            "2025-07-16  117.00  117.50    -1\n",
            "2025-07-17  114.75  118.25     1\n",
            "mambral\n",
            "Ticker\n",
            "COME.BA    0.02778\n",
            "Name: 0.75, dtype: float64\n",
            "Series([], Name: proportion, dtype: float64)\n",
            "Conteo de etiquetas:\n",
            "Series([], Name: count, dtype: int64)\n",
            "\n",
            "Porcentajes de cada clase (%):\n",
            "Series([], Name: count, dtype: float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "\n",
        "# Descargar datos\n",
        "end_date = dt.datetime(2025, 7, 17)\n",
        "df = yf.download(\"GGAL\", start=dt.datetime(2001, 1, 1), end=end_date)\n",
        "\n",
        "# Aplanar el MultiIndex a columnas simples\n",
        "df.columns = df.columns.map(lambda x: x[0])\n",
        "\n",
        "# Limpiar datos\n",
        "df = df.dropna(subset=['Open', 'High'])\n",
        "\n",
        "# Calcular umbral dinámico\n",
        "differences = (df['High'] - df['Open']) / df['Open']\n",
        "umbral = differences.quantile(0.6).item()\n",
        "print(f\"Umbral calculado: {umbral:.4f}\")\n",
        "\n",
        "# Calcular etiqueta sin desfase (para verificar)\n",
        "df['Label_raw'] = ((df['High'] - df['Open']) / df['Open'] > umbral).astype(int) * 2 - 1\n",
        "\n",
        "# Desplazar la etiqueta un día hacia atrás (target del día siguiente)\n",
        "df['Label'] = df['Label_raw'].shift(-1)\n",
        "\n",
        "# Eliminar la última fila (no tiene etiqueta para predecir)\n",
        "df = df.dropna(subset=['Label'])\n",
        "\n",
        "# Contar etiquetas y calcular porcentajes\n",
        "label_counts = df['Label'].value_counts()\n",
        "total_dias = len(df)\n",
        "percentages = (label_counts / total_dias) * 100\n",
        "\n",
        "print(\"\\nConteo de etiquetas (desfasadas):\")\n",
        "print(label_counts)\n",
        "print(\"\\nPorcentajes de cada clase (%):\")\n",
        "print(percentages.round(2))\n",
        "\n",
        "# Opcional: Ver los primeros días etiquetados\n",
        "print(\"\\nPrimeros días etiquetados (features del día anterior, label del día siguiente):\")\n",
        "print(df[['Open', 'High', 'Label']].tail(22))"
      ],
      "metadata": {
        "id": "BYoBb-mnRDDT",
        "outputId": "15709c95-ede1-415d-a7a9-f7caa2c196d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-28-1581792227.py:7: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(\"GGAL\", start=dt.datetime(2001, 1, 1), end=end_date)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Umbral calculado: 0.0233\n",
            "\n",
            "Conteo de etiquetas (desfasadas):\n",
            "Label\n",
            "-1.0    3701\n",
            " 1.0    2468\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Porcentajes de cada clase (%):\n",
            "Label\n",
            "-1.0    59.99\n",
            " 1.0    40.01\n",
            "Name: count, dtype: float64\n",
            "\n",
            "Primeros días etiquetados (features del día anterior, label del día siguiente):\n",
            "                 Open       High  Label\n",
            "Date                                   \n",
            "2025-06-12  55.400002  57.270000   -1.0\n",
            "2025-06-13  55.549999  56.000000   -1.0\n",
            "2025-06-16  55.080002  55.590000   -1.0\n",
            "2025-06-17  53.779999  54.970001   -1.0\n",
            "2025-06-18  54.290001  55.320000   -1.0\n",
            "2025-06-20  54.080002  54.080002   -1.0\n",
            "2025-06-23  51.480000  52.320000    1.0\n",
            "2025-06-24  51.000000  53.450001   -1.0\n",
            "2025-06-25  52.680000  53.220001    1.0\n",
            "2025-06-26  51.700001  52.910000   -1.0\n",
            "2025-06-27  51.880001  52.540001   -1.0\n",
            "2025-06-30  51.950001  52.650002    1.0\n",
            "2025-07-01  50.070000  51.619999   -1.0\n",
            "2025-07-02  49.799999  50.919998   -1.0\n",
            "2025-07-03  50.490002  51.099998   -1.0\n",
            "2025-07-07  50.669998  50.730000    1.0\n",
            "2025-07-08  48.590000  50.720001   -1.0\n",
            "2025-07-09  51.200001  51.709999   -1.0\n",
            "2025-07-10  49.200001  49.570000   -1.0\n",
            "2025-07-11  48.310001  48.580002    1.0\n",
            "2025-07-14  46.459999  47.580002   -1.0\n",
            "2025-07-15  46.810001  47.810001   -1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}