{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmdiegoar/Quant-code-t0/blob/main/XGB_Sentido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import files\n",
        "from scipy import stats\n",
        "import time\n",
        "\n",
        "\n",
        "# Functions for features\n",
        "def add_lagged_price_features(df, etiqueta=\"close_lag\", dato=\"Close\"):\n",
        "    for lag in range(1, 6):\n",
        "        df[f'{etiqueta}_{lag}'] = df[dato].shift(lag)\n",
        "    return df\n",
        "\n",
        "def calculate_RSI(series, period=7):\n",
        "    delta = series.diff(1)\n",
        "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def calculate_ROC(series, period=5):\n",
        "    return ((series - series.shift(period)) / series.shift(period)) * 100\n",
        "\n",
        "def calculate_PPO(series, fast_period=5, slow_period=9, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ppo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ppo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ppo - signal_line\n",
        "    return ppo, signal_line, histogram\n",
        "\n",
        "def calculate_EWO(series, fast_period=5, slow_period=35, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ewo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ewo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ewo - signal_line\n",
        "    return ewo, signal_line, histogram\n",
        "\n",
        "def calculate_volatility(series, window=20):\n",
        "    return series.rolling(window).std().round(6)\n",
        "\n",
        "def calculate_sma5(series, period=5):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma13(series, period=13):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma26(series, period=26):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma50(series, period=50):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma200(series, period=200):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "\n",
        "def create_features(df, umbral, n_days_high=1):\n",
        "    df = add_lagged_price_features(df, \"close_lag\", \"Close\")\n",
        "    df = add_lagged_price_features(df, \"open_lag\", \"Open\")\n",
        "    df = add_lagged_price_features(df, \"high_lag\", \"High\")\n",
        "    df['Pct_change'] = df['Close'].pct_change()\n",
        "    for lag in range(1, 6):\n",
        "        df[f'lag_change{lag}'] = df['Pct_change'].shift(lag)\n",
        "    df['RSI'] = calculate_RSI(df['Close'])\n",
        "    df['ROC'] = calculate_ROC(df['Close'])\n",
        "    df['PPO'], df['PPO_Signal'], df['PPO_Histogram'] = calculate_PPO(df['Close'])\n",
        "    df['EWO'], df['EWO_Signal'], df['EWO_Histogram'] = calculate_EWO(df['Close'])\n",
        "    df['SMA5'] = calculate_sma5(df['Close'])\n",
        "    df['SMA13'] = calculate_sma13(df['Close'])\n",
        "    df['SMA26'] = calculate_sma26(df['Close'])\n",
        "    df['SMA50'] = calculate_sma50(df['Close'])\n",
        "    df['SMA200'] = calculate_sma200(df['Close'])\n",
        "    df['Volatility'] = calculate_volatility(df['Close'])\n",
        "\n",
        "    # --- New Feature: Max Gain from Open over Past N Days ---\n",
        "    # Calculate the maximum High price over the *next N days* for *each historical day*.\n",
        "    # Use rolling().max() with min_periods=1 to handle ends of series.\n",
        "    # Then shift to align with the start of the N-day window (the current day's Open).\n",
        "    max_high_over_next_n_days_hist = df['High'].rolling(window=n_days_high, min_periods=1).max().shift(-n_days_high + 1)\n",
        "\n",
        "\n",
        "    # Calculate the potential max gain from Open for *each historical day*\n",
        "    # Using the Open price of that historical day\n",
        "    epsilon = 1e-9 # To prevent division by zero\n",
        "    df['Max_Gain_from_Open_Current'] = (max_high_over_next_n_days_hist - df['Open']) / (df['Open'] + epsilon)\n",
        "\n",
        "    # --- Add lagged versions of the new feature ---\n",
        "    for lag in range(1, 7): # Create lags from 1 to 6\n",
        "        df[f'Max_Gain_from_Open_Lag_{lag}'] = df['Max_Gain_from_Open_Current'].shift(lag)\n",
        "\n",
        "\n",
        "    # Calculate the target based on tomorrow's Open vs Max High over next n_days_high days\n",
        "    # Use rolling().max() with min_periods=1 for the target as well.\n",
        "    # Shift to align with the start of the N-day window for the target (tomorrow's Open).\n",
        "    max_high_next_n_days_target = df['High'].rolling(window=n_days_high, min_periods=1).max().shift(-n_days_high + 1)\n",
        "    open_next_day = df['Open'].shift(-1)\n",
        "    df['Label_raw'] = ((max_high_next_n_days_target - open_next_day) / (open_next_day + epsilon) > umbral).astype(int)\n",
        "    df['Label'] = df['Label_raw'].shift(-1) # Target for the next day\n",
        "\n",
        "\n",
        "    # Replace inf values with NaN before dropping\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Dropping NaNs here will remove rows where features or the target are still NaN (e.g., due to initial lags,\n",
        "    # or if min_periods=1 still results in NaN for very short series, although less likely now for the rolling max).\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Definir fecha de corte manualmente (cambiar diariamente)\n",
        "end_date = dt.datetime(2025, 9, 14)  # Ejemplo: cambiar a 2025-07-18 mañana\n",
        "\n",
        "tk =[ \"ALUA.BA\", \"BBAR.BA\", \"BMA.BA\", \"COME.BA\", \"CRES.BA\", \"EDN.BA\", \"GGAL.BA\", \"IRSA.BA\", \"LOMA.BA\", \"METR.BA\", \"PAMP.BA\", \"SUPV.BA\", \"TECO2.BA\", \"TGNO4.BA\", \"TGSU2.BA\", \"TRAN.BA\", \"TXAR.BA\", \"VALO.BA\", \"YPFD.BA\"]\n",
        "\n",
        "\n",
        "# results = [] # el del test, para que no lo reinicie - REMOVED\n",
        "resultsp = [] # las predicciones, para que no lo reinicie\n",
        "\n",
        "umbral = 0.029\n",
        "lapso = 1 # Lapso is no longer directly used for the target definition, but keeping it doesn't hurt\n",
        "n_days_high_target = 3 # Define the number of days for the High target (used for both target and new feature)\n",
        "\n",
        "# Define clipping bounds - adjust based on feature distributions\n",
        "lower_bound = -1e9\n",
        "upper_bound = 1e9\n",
        "\n",
        "\n",
        "for papel in tk:\n",
        "\n",
        "  symbol=papel\n",
        "  #symbol=\"COME.BA\"\n",
        "  # Fechas dinámicas\n",
        "  start_date = dt.datetime(2001, 1, 1)  # Inicio fijo\n",
        "  train_end = end_date - pd.Timedelta(days=780)  # 6 meses antes de end_date (ajustable)\n",
        "  next_day = end_date + pd.Timedelta(days=1)  # Predicción para el día siguiente\n",
        "\n",
        "\n",
        "  # Select features - Add the new feature and its lags\n",
        "  features = ['RSI', 'ROC', 'PPO', 'PPO_Signal', 'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'Volatility', 'SMA5', 'SMA13', 'SMA26', 'SMA50', 'SMA200' ] + [f'lag_change{i}' for i in range(1, 6)] + \\\n",
        "            [f'close_lag_{i}' for i in range(1, 6)] + [f'open_lag_{i}' for i in range(1, 6)]+ [f'high_lag_{i}' for i in range(1, 6)] + \\\n",
        "            ['Max_Gain_from_Open_Current'] + [f'Max_Gain_from_Open_Lag_{i}' for i in range(1, 7)]\n",
        "\n",
        "\n",
        "  # Download data for the current ticker inside the loop\n",
        "  print(f\"\\nDownloading data for {symbol}...\")\n",
        "  df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=False)\n",
        "\n",
        "  # Verify data download\n",
        "  if df.empty:\n",
        "      print(f\"Warning: No data downloaded for {symbol}. Skipping.\")\n",
        "      continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "  # Handle MultiIndex columns and ensure standard column names - More robust logic\n",
        "  required_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "  processed_df = None # Initialize processed_df\n",
        "\n",
        "  if isinstance(df.columns, pd.MultiIndex):\n",
        "      print(f\"MultiIndex columns detected for {symbol}.\")\n",
        "      try:\n",
        "          # Attempt to extract columns by looking for standard names in the last level\n",
        "          extracted_data = {}\n",
        "          for std_name in required_cols:\n",
        "              # Find the MultiIndex column tuple whose last level matches the standard name\n",
        "              matching_col_tuple = None\n",
        "              for col_tuple in df.columns:\n",
        "                  if col_tuple[-1] == std_name:\n",
        "                      matching_col_tuple = col_tuple\n",
        "                      break # Found the first match\n",
        "\n",
        "              if matching_col_tuple:\n",
        "                  extracted_data[std_name] = df[matching_col_tuple]\n",
        "              else:\n",
        "                  print(f\"Warning: Could not find standard column '{std_name}' in the last level of MultiIndex for {symbol}. Column missing.\")\n",
        "                  # Continue to look for other required columns, processed_df will be checked later\n",
        "\n",
        "          if len(extracted_data) == len(required_cols):\n",
        "              processed_df = pd.DataFrame(extracted_data)\n",
        "              processed_df.index = df.index # Preserve original index\n",
        "              print(f\"Successfully extracted and flattened MultiIndex columns for {symbol}.\")\n",
        "          else:\n",
        "              missing_cols = [name for name in required_cols if name not in extracted_data]\n",
        "              print(f\"Warning: Could not extract all required columns from MultiIndex for {symbol}. Missing: {missing_cols}. Skipping ticker.\")\n",
        "              continue # Skip to the next ticker\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Warning: An error occurred while processing MultiIndex columns for {symbol}: {e}. Skipping.\")\n",
        "          #print(f\"Original columns: {df.columns.tolist()}\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "  else: # If not MultiIndex columns, assume standard flat DataFrame is already present\n",
        "      print(f\"No MultiIndex columns detected for {symbol}. Checking for standard columns.\")\n",
        "      # Check if the required columns are directly present\n",
        "      if all(col in df.columns for col in required_cols):\n",
        "          processed_df = df[required_cols].copy() # Select required columns and make a copy\n",
        "          print(f\"Using existing standard columns for {symbol}.\")\n",
        "      else:\n",
        "          missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "          print(f\"Warning: Required standard columns not found in flat DataFrame for {symbol}. Missing: {missing_cols}. Skipping ticker.\")\n",
        "          #print(f\"Available columns: {df.columns.tolist()}\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "  # Ensure df is set to processed_df if successful\n",
        "  df = processed_df\n",
        "\n",
        "  # Handle MultiIndex index if present (less common with single ticker download but possible)\n",
        "  if isinstance(df.index, pd.MultiIndex):\n",
        "      print(f\"MultiIndex index detected for {symbol}. Attempting to flatten index.\")\n",
        "      try:\n",
        "          # Assuming the MultiIndex index structure is ('Ticker', 'Date')\n",
        "          if 'Ticker' in df.index.names:\n",
        "               df = df.xs(symbol, level='Ticker', axis=0)\n",
        "               print(f\"Índice aplanado para {symbol}.\")\n",
        "          else:\n",
        "               print(f\"Warning: MultiIndex index detected for {symbol} but 'Ticker' level not found. Skipping index flattening.\")\n",
        "               # If 'Ticker' level is not there, maybe it's just a date/time MultiIndex?\n",
        "               # Or a different structure. For now, proceed without flattening index if Ticker level is missing.\n",
        "\n",
        "\n",
        "      except KeyError:\n",
        "          print(f\"Warning: Could not select ticker from MultiIndex index for {symbol}. Skipping.\")\n",
        "          continue # Skip to the next ticker\n",
        "      except Exception as e:\n",
        "          print(f\"Warning: An error occurred while flattening MultiIndex index for {symbol}: {e}. Skipping.\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "  df.index = pd.to_datetime(df.index)\n",
        "  if not df.index.is_unique:\n",
        "      print(f\"Advertencia: Índice con fechas duplicadas para {symbol}. Eliminando duplicados...\")\n",
        "      df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after initial processing and cleaning for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  # Ensure numeric types and handle potential non-numeric data\n",
        "  for col in required_cols:\n",
        "      if col in df.columns: # Ensure column exists before processing\n",
        "          df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "      else:\n",
        "           # This should ideally not happen if previous checks passed, but as a safeguard:\n",
        "           print(f\"Error: Required column '{col}' not found in df for {symbol} before numeric conversion. Skipping ticker.\")\n",
        "           df = pd.DataFrame() # Set df to empty to skip further processing\n",
        "           break # Exit column processing loop\n",
        "\n",
        "\n",
        "  if df.empty: # Check again if df became empty due to missing columns\n",
        "       continue # Skip to the next ticker\n",
        "\n",
        "  # Drop rows where essential price data is missing after coercion\n",
        "  df.dropna(subset=['Open', 'High', 'Low', 'Close'], inplace=True)\n",
        "\n",
        "\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after dropping rows with missing price data for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  df['Open']= df['Open'].round(2)\n",
        "  df['High']= df['High'].round(2)\n",
        "  df['Low']= df['Low'].round(2)\n",
        "  df['Close']= df['Close'].round(2)\n",
        "  df['Adj Close']= df['Adj Close'].round(2)\n",
        "\n",
        "  print(\"Últimas filas del DataFrame antes de crear features:\")\n",
        "  print(df.tail())\n",
        "\n",
        "\n",
        "  # Crear features with the new target definition\n",
        "  df = create_features(df, umbral=umbral, n_days_high=n_days_high_target) # Pass n_days_high_target, removed lapso\n",
        "\n",
        "  # Verify data is not empty after feature creation and dropna\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after feature creation and dropna for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  # Verify data after creating features\n",
        "  print(\"\\nÚltimas filas del DataFrame después de crear features:\")\n",
        "  print(df.tail())\n",
        "  print(df.columns)\n",
        "\n",
        "  print(f\"Distribucion de etiquetas para {symbol}:\")\n",
        "  print(df[\"Label\"].value_counts(normalize=True))\n",
        "\n",
        "  # Check if there are samples from both classes in the target variable\n",
        "  if len(df[\"Label\"].unique()) < 2:\n",
        "      print(f\"Warning: Target variable 'Label' contains only one class for {symbol} after feature creation. Cannot train a classifier. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  correlation = df[features + [\"Label\"]].corr()[\"Label\"].sort_values(ascending=False)\n",
        "  print(f\"Correlacion con label para {symbol}:\")\n",
        "  print(correlation)\n",
        "\n",
        "\n",
        "  # Dividir datos en entrenamiento y prueba\n",
        "  X = df[features]\n",
        "  y = df['Label']\n",
        "  X_train_full = X[df.index <= train_end]\n",
        "  y_train_full = y[df.index <= train_end]\n",
        "  X_test = X[(df.index > train_end) & (df.index <= end_date)]  # Hasta end_date\n",
        "  y_test = y[(df.index > train_end) & (df.index <= end_date)]\n",
        "\n",
        "  # Verify training and test sets are not empty and have both classes\n",
        "  if X_train_full.empty or y_train_full.empty or len(y_train_full.unique()) < 2:\n",
        "      print(f\"Warning: Training data is insufficient or has only one class for {symbol}. Skipping model training and prediction.\")\n",
        "      continue\n",
        "\n",
        "  # Initialize test metrics before evaluation\n",
        "  precision_test_alcista = None\n",
        "  recall_test_alcista = None\n",
        "  f1_test_alcista = None\n",
        "  roc_auc_test = None\n",
        "  ratio_1_test = None\n",
        "  best_model = None # Initialize best_model to None\n",
        "  best_threshold = 0.5 # Initialize best_threshold to default\n",
        "\n",
        "\n",
        "  # Optimizar hiperparámetros con RandomizedSearchCV\n",
        "  print(f\"Optimizar hiperparámetros con RandomizedSearchCV para {symbol}\")\n",
        "  param_dist = {\n",
        "      'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "      'max_depth': [3, 5, 7, 9],\n",
        "      'n_estimators': [100, 500, 900],\n",
        "      'subsample': [0.6, 0.8, 1.0],\n",
        "      'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "      'gamma': [0, 0.1, 0.2],\n",
        "      'scale_pos_weight': [0.5, 1, 2, 5, 10, 20, 50, 100] # Incluir scale_pos_weight en la búsqueda\n",
        "  }\n",
        "\n",
        "  # Inicializar el clasificador XGBoost sin scale_pos_weight fijo (se tuneará)\n",
        "  xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "  # Usar TimeSeriesSplit para cross-validation\n",
        "  n_splits = 5  # Puedes ajustar el número de splits\n",
        "  tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "  # Definir scorer para maximizar Precision de la Clase 1\n",
        "  precision_scorer = make_scorer(precision_score, pos_label=1, zero_division=0) # zero_division=0 para manejar casos sin predicciones positivas\n",
        "\n",
        "  # Clean X_train_full and y_train_full before fitting RandomizedSearchCV\n",
        "  X_train_full_cleaned_for_tuning = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "  X_train_full_cleaned_for_tuning.dropna(inplace=True)\n",
        "  y_train_full_cleaned_for_tuning = y_train_full.loc[X_train_full_cleaned_for_tuning.index] # Ensure y matches cleaned X\n",
        "\n",
        "  # Explicit check, conversion, and fallback for non-finite values before fitting RandomizedSearchCV\n",
        "  X_train_full_cleaned_for_tuning = X_train_full_cleaned_for_tuning.astype(np.float64) # Ensure dtype\n",
        "  if not np.isfinite(X_train_full_cleaned_for_tuning).all().all():\n",
        "      print(f\"\\nWarning: Non-finite values detected in X_train_full_cleaned_for_tuning for {symbol} before RandomizedSearchCV fit. Attempting to fill with median.\")\n",
        "      for col in X_train_full_cleaned_for_tuning.columns:\n",
        "          finite_values = X_train_full_cleaned_for_tuning[col][np.isfinite(X_train_full_cleaned_for_tuning[col])]\n",
        "          if not finite_values.empty:\n",
        "              median_val = finite_values.median()\n",
        "              X_train_full_cleaned_for_tuning[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "              X_train_full_cleaned_for_tuning[col].fillna(median_val, inplace=True)\n",
        "          else:\n",
        "              print(f\"Warning: Column '{col}' in X_train_full_cleaned_for_tuning is all non-finite. Filling with 0.\")\n",
        "              X_train_full_cleaned_for_tuning[col].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "  # Perform RandomizedSearchCV - Add try-except block\n",
        "  # Ensure cleaned data for tuning is not empty and has more than one class\n",
        "  if not X_train_full_cleaned_for_tuning.empty and not y_train_full_cleaned_for_tuning.empty and len(y_train_full_cleaned_for_tuning.unique()) > 1:\n",
        "      try:\n",
        "          random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=20, cv=tscv, scoring=precision_scorer, n_jobs=-1, random_state=42) # Usar precision_scorer\n",
        "          random_search.fit(X_train_full_cleaned_for_tuning, y_train_full_cleaned_for_tuning)\n",
        "          print(f\"Mejores hiperparámetros para {symbol}:\", random_search.best_params_)\n",
        "\n",
        "          # Usar el mejor modelo encontrado por RandomizedSearchCV\n",
        "          best_model = random_search.best_estimator_\n",
        "\n",
        "          # Get and print feature importance\n",
        "          feature_importance = pd.Series(best_model.feature_importances_, index=features)\n",
        "          print(f\"\\nFeature Importance for {symbol}:\")\n",
        "          print(feature_importance.sort_values(ascending=False))\n",
        "\n",
        "          # Optimize the threshold for maximum Precision (Clase 1) on the full training set\n",
        "          X_train_full_cleaned_for_threshold = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "          X_train_full_cleaned_for_threshold.dropna(inplace=True)\n",
        "          y_train_full_cleaned_for_threshold = y_train_full.loc[X_train_full_cleaned_for_threshold.index]\n",
        "\n",
        "          if not X_train_full_cleaned_for_threshold.empty and not y_train_full_cleaned_for_threshold.empty and len(y_train_full_cleaned_for_threshold.unique()) > 1:\n",
        "              y_train_prob = best_model.predict_proba(X_train_full_cleaned_for_threshold)[:, 1]\n",
        "              thresholds = np.arange(0.01, 1.0, 0.01)\n",
        "              best_threshold = 0.5\n",
        "              best_precision = 0\n",
        "\n",
        "              print(f\"Optimizing threshold for maximum Precision (Clase 1) on training data for {symbol}...\")\n",
        "              if 1 in y_train_full_cleaned_for_threshold.unique():\n",
        "                  for threshold in thresholds:\n",
        "                      y_pred_threshold = (y_train_prob >= threshold).astype(int)\n",
        "                      if np.sum(y_pred_threshold) > 0:\n",
        "                           precision = precision_score(y_train_full_cleaned_for_threshold, y_pred_threshold, pos_label=1, zero_division=0)\n",
        "                           if precision > best_precision:\n",
        "                               best_precision = precision\n",
        "                               best_threshold = threshold\n",
        "                  print(f\"Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para {symbol}: {best_threshold:.4f} (Precision: {best_precision:.4f})\")\n",
        "              else:\n",
        "                  print(f\"\\nWarning: Training set for {symbol} contains no positive samples after cleaning for threshold optimization. Cannot optimize threshold for Precision (Clase 1). Using default threshold 0.5.\")\n",
        "                  best_threshold = 0.5\n",
        "          else:\n",
        "              print(f\"\\nWarning: Training data for threshold optimization is insufficient for {symbol}. Using default threshold 0.5.\")\n",
        "              best_threshold = 0.5\n",
        "\n",
        "\n",
        "          # Evaluar el modelo en el conjunto de prueba con el best threshold\n",
        "          if not X_test.empty and not y_test.empty and len(y_test.unique()) > 1:\n",
        "              print(f\"\\nEvaluating best model on test set for {symbol} with best threshold ({best_threshold:.4f}):\")\n",
        "\n",
        "              X_test_cleaned = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "              y_test_cleaned = y_test.loc[X_test_cleaned.index]\n",
        "\n",
        "              scaler = RobustScaler()\n",
        "              X_train_full_cleaned_for_scaler_eval = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "              X_train_full_cleaned_for_scaler_eval.dropna(inplace=True)\n",
        "              X_train_full_cleaned_for_scaler_eval = X_train_full_cleaned_for_scaler_eval.clip(lower=lower_bound, upper=upper_bound)\n",
        "              X_train_full_cleaned_for_scaler_eval = X_train_full_cleaned_for_scaler_eval.astype(np.float64)\n",
        "\n",
        "              if not np.isfinite(X_train_full_cleaned_for_scaler_eval).all().all():\n",
        "                  print(f\"\\nWarning: Non-finite values detected in X_train_full_cleaned_for_scaler_eval for {symbol} before scaler fit. Attempting to fill with median.\")\n",
        "                  for col in X_train_full_cleaned_for_scaler_eval.columns:\n",
        "                      finite_values = X_train_full_cleaned_for_scaler_eval[col][np.isfinite(X_train_full_cleaned_for_scaler_eval[col])]\n",
        "                      if not finite_values.empty:\n",
        "                          median_val = finite_values.median()\n",
        "                          X_train_full_cleaned_for_scaler_eval[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                          X_train_full_cleaned_for_scaler_eval[col].fillna(median_val, inplace=True)\n",
        "                      else:\n",
        "                          print(f\"Warning: Column '{col}' in X_train_full_cleaned_for_scaler_eval is all non-finite. Filling with 0.\")\n",
        "                          X_train_full_cleaned_for_scaler_eval[col].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "              if not X_train_full_cleaned_for_scaler_eval.empty and np.isfinite(X_train_full_cleaned_for_scaler_eval).all().all():\n",
        "                  scaler.fit(X_train_full_cleaned_for_scaler_eval)\n",
        "\n",
        "                  X_test_cleaned = X_test_cleaned.astype(np.float64)\n",
        "                  if not np.isfinite(X_test_cleaned).all().all():\n",
        "                       print(f\"\\nWarning: Non-finite values detected in X_test_cleaned for {symbol} before scaler transform. Attempting to fill with median (from train data).\")\n",
        "                       train_medians = X_train_full_cleaned_for_scaler_eval.median()\n",
        "                       for col in X_test_cleaned.columns:\n",
        "                           median_val = train_medians.get(col, 0)\n",
        "                           X_test_cleaned[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                           X_test_cleaned[col].fillna(median_val, inplace=True)\n",
        "                       if not np.isfinite(X_test_cleaned).all().all():\n",
        "                            print(f\"\\nERROR: Non-finite values STILL detected in X_test_cleaned for {symbol} after filling with median!\")\n",
        "\n",
        "\n",
        "                  if not X_test_cleaned.empty and np.isfinite(X_test_cleaned).all().all():\n",
        "                      X_test_scaled = scaler.transform(X_test_cleaned)\n",
        "\n",
        "                      y_test_pred_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "                      y_test_pred = (y_test_pred_prob >= best_threshold).astype(int)\n",
        "\n",
        "                      if len(y_test_cleaned.unique()) > 1:\n",
        "                          print(\"\\nClassification Report (Test Set):\")\n",
        "                          print(classification_report(y_test_cleaned, y_test_pred, zero_division=0))\n",
        "                          precision_test_alcista = precision_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "                          recall_test_alcista = recall_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "                          f1_test_alcista = f1_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "                          print(f\"Tamaño de y_test (cleaned): {y_test_cleaned.size}\")\n",
        "                          print(f\"Distribución de clases en y_test (cleaned) para {symbol}:\")\n",
        "                          print(y_test_cleaned.value_counts())\n",
        "                          if 1 in y_test_cleaned.value_counts():\n",
        "                              ratio_1_test=(y_test_cleaned.value_counts()[1]/y_test_cleaned.size).round(4)\n",
        "                          else:\n",
        "                              ratio_1_test = 0\n",
        "                          print(f\"% clase 1 test para {symbol}: {ratio_1_test} \")\n",
        "\n",
        "                          if len(y_test_cleaned.unique()) > 1:\n",
        "                               roc_auc_test = roc_auc_score(y_test_cleaned, y_test_pred_prob).round(6)\n",
        "                               print(f\"\\nROC-AUC (Test Set) para {symbol}: {roc_auc_test:.4f}\")\n",
        "                          else:\n",
        "                               roc_auc_test = None\n",
        "                               print(f\"\\nWarning: Test set for {symbol} contains only one class after cleaning. Cannot calculate ROC-AUC.\")\n",
        "\n",
        "                      else:\n",
        "                          print(f\"\\nWarning: Test set for {symbol} contains only one class after cleaning. Cannot generate full classification report.\")\n",
        "                          precision_test_alcista = None\n",
        "                          recall_test_alcista = None\n",
        "                          f1_test_alcista = None\n",
        "                          roc_auc_test = None\n",
        "                          ratio_1_test = None\n",
        "\n",
        "\n",
        "                  else:\n",
        "                      print(f\"\\nWarning: X_test became empty after cleaning or contains non-finite values for {symbol}. Skipping test evaluation.\")\n",
        "                      precision_test_alcista = None\n",
        "                      recall_test_alcista = None\n",
        "                      f1_test_alcista = None\n",
        "                      roc_auc_test = None\n",
        "                      ratio_1_test = None\n",
        "\n",
        "\n",
        "              else:\n",
        "                  print(f\"\\nWarning: Training data (X_train_full) became empty or contains non-finite values after cleaning for scaler fitting for evaluation for {symbol}. Skipping test evaluation.\")\n",
        "                  precision_test_alcista = None\n",
        "                  recall_test_alcista = None\n",
        "                  f1_test_alcista = None\n",
        "                  roc_auc_test = None\n",
        "                  ratio_1_test = None\n",
        "\n",
        "\n",
        "          else:\n",
        "              print(f\"\\nAdvertencia: Conjunto de prueba insuficiente o con una sola clase para evaluación para {symbol}.\")\n",
        "              precision_test_alcista = None\n",
        "              recall_test_alcista = None\n",
        "              f1_test_alcista = None\n",
        "              roc_auc_test = None\n",
        "              ratio_1_test = None\n",
        "\n",
        "          # Prediction for the next day is done only if model was trained successfully\n",
        "          last_features = df[features].iloc[-1:]\n",
        "          last_features_cleaned = None\n",
        "          last_features_scaled = None\n",
        "          future_pred_prob = None\n",
        "          future_pred = None\n",
        "\n",
        "          if not last_features.empty:\n",
        "              # Ensure last_features is a single row DataFrame before cleaning\n",
        "              if not isinstance(last_features, pd.DataFrame) or len(last_features) != 1:\n",
        "                   print(f\"\\nError: last_features is not a single row DataFrame for {symbol}. Skipping prediction.\")\n",
        "                   # Set prediction results to skipped\n",
        "                   last_data_date = df.index[-1] if not df.empty else None\n",
        "                   last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                   resultsp.append({\n",
        "                       'Papel': symbol,\n",
        "                       'Fecha Predicción': next_day,\n",
        "                       'Fecha Datos': last_data_date,\n",
        "                       'Predicción': 'Skipped (Prediction Data Error)',\n",
        "                       'Precio actual': last_close,\n",
        "                       'Probabilidad Alcista (Modelo)': None,\n",
        "                       'Umbral de Clasificación': None,\n",
        "                       'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Prediction Data Error)',\n",
        "                       'Precision Test (Alcista)': precision_test_alcista,\n",
        "                       'Recall Test (Alcista)': recall_test_alcista,\n",
        "                       'F1 Test (Alcista)': f1_test_alcista,\n",
        "                       'ROC-AUC Test': roc_auc_test,\n",
        "                       'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                       'Features Limpias (Predicción)': None,\n",
        "                       'Features Escaladas (Predicción)': None\n",
        "                   })\n",
        "                   continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "              last_features_cleaned = last_features.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "              last_features_cleaned = last_features_cleaned.clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "              if not last_features_cleaned.empty and np.isfinite(last_features_cleaned).all().all():\n",
        "                  # Ensure scaler is fitted on the *cleaned* full training data\n",
        "                  scaler = RobustScaler()\n",
        "                  X_train_full_cleaned_for_scaler_pred = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "                  X_train_full_cleaned_for_scaler_pred.dropna(inplace=True)\n",
        "                  X_train_full_cleaned_for_scaler_pred = X_train_full_cleaned_for_scaler_pred.clip(lower=lower_bound, upper=upper_bound)\n",
        "                  X_train_full_cleaned_for_scaler_pred = X_train_full_cleaned_for_scaler_pred.astype(np.float64)\n",
        "\n",
        "                  if not np.isfinite(X_train_full_cleaned_for_scaler_pred).all().all():\n",
        "                       print(f\"\\nWarning: Non-finite values detected in X_train_full_cleaned_for_scaler_pred for {symbol} before scaler fit. Attempting to fill with median.\")\n",
        "                       for col in X_train_full_cleaned_for_scaler_pred.columns:\n",
        "                           finite_values = X_train_full_cleaned_for_scaler_pred[col][np.isfinite(X_train_full_cleaned_for_scaler_pred[col])]\n",
        "                           if not finite_values.empty:\n",
        "                               median_val = finite_values.median()\n",
        "                               X_train_full_cleaned_for_scaler_pred[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                               X_train_full_cleaned_for_scaler_pred[col].fillna(median_val, inplace=True)\n",
        "                           else:\n",
        "                               print(f\"Warning: Column '{col}' in X_train_full_cleaned_for_scaler_pred is all non-finite. Filling with 0.\")\n",
        "                               X_train_full_cleaned_for_scaler_pred[col].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "                  if not X_train_full_cleaned_for_scaler_pred.empty and np.isfinite(X_train_full_cleaned_for_scaler_pred).all().all():\n",
        "                       scaler.fit(X_train_full_cleaned_for_scaler_pred)\n",
        "\n",
        "                       last_features_cleaned = last_features_cleaned.astype(np.float64)\n",
        "                       # Add explicit fallback for non-finite values AFTER dropna for prediction data\n",
        "                       if not np.isfinite(last_features_cleaned).all().all():\n",
        "                            print(f\"\\nWarning: Non-finite values STILL detected in last_features_cleaned for {symbol} AFTER dropna. Attempting to fill with median (from train data).\")\n",
        "                            train_medians = X_train_full_cleaned_for_scaler_pred.median()\n",
        "                            for col in last_features_cleaned.columns:\n",
        "                                median_val = train_medians.get(col, 0)\n",
        "                                last_features_cleaned[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                                last_features_cleaned[col].fillna(median_val, inplace=True)\n",
        "                            if not np.isfinite(last_features_cleaned).all().all():\n",
        "                                 print(f\"\\nERROR: Non-finite values STILL detected in last_features_cleaned for {symbol} after filling with median!\")\n",
        "\n",
        "\n",
        "                       if not last_features_cleaned.empty and np.isfinite(last_features_cleaned).all().all():\n",
        "                           last_features_scaled = scaler.transform(last_features_cleaned)\n",
        "\n",
        "                           future_pred_prob = best_model.predict_proba(last_features_scaled)[:, 1][0].round(4)\n",
        "                           future_pred = 1 if future_pred_prob >= best_threshold else 0\n",
        "\n",
        "                           last_close = None\n",
        "                           last_open = None\n",
        "                           last_max = None\n",
        "                           if not df.empty:\n",
        "                               last_close = df['Close'].iloc[-1]\n",
        "                               last_open = df['Open'].iloc[-1]\n",
        "                               last_max = df['High'].iloc[-1]\n",
        "                               last_data_date = df.index[-1]\n",
        "                        else:\n",
        "                               print(f\"Warning: DataFrame 'df' is empty for {symbol}. Cannot get last prices.\")\n",
        "                               last_data_date = None\n",
        "\n",
        "                           action = 'BUY' if future_pred == 1 else 'SELL'\n",
        "                           direction = 1 if future_pred == 1 else -1\n",
        "\n",
        "                           # Ensure output uses to_dict() and tolist() explicitly\n",
        "                           resultsp.append({\n",
        "                                       'Papel': symbol,\n",
        "                                       'Fecha Predicción': next_day,\n",
        "                                       'Fecha Datos': last_data_date,\n",
        "                                       'Predicción': 'Alcista' if future_pred == 1 else 'Bajista',\n",
        "                                       'Probabilidad Alcista (Modelo)': future_pred_prob,\n",
        "                                       'Umbral de Clasificación': best_threshold.round(4),\n",
        "                                       'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)', # Add check for best_model\n",
        "                                       'Precision Test (Alcista)': precision_test_alcista,\n",
        "                                       'Recall Test (Alcista)': recall_test_alcista,\n",
        "                                       'F1 Test (Alcista)': f1_test_alcista,\n",
        "                                       'ROC-AUC Test': roc_auc_test,\n",
        "                                       'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                                       'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None, # Add cleaned features using to_dict\n",
        "                                       'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None # Add scaled features as a list\n",
        "                               })\n",
        "                       else:\n",
        "                            print(f\"\\nWarning: last_features became empty or contains non-finite values after final filling for scaler transform. Skipping prediction for {symbol}.\")\n",
        "                            last_data_date = df.index[-1] if not df.empty else None\n",
        "                            last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                            resultsp.append({\n",
        "                                'Papel': symbol,\n",
        "                                'Fecha Predicción': next_day,\n",
        "                                'Fecha Datos': last_data_date,\n",
        "                                'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                                'Precio actual': last_close,\n",
        "                                'Probabilidad Alcista (Modelo)': None,\n",
        "                                'Umbral de Clasificación': None,\n",
        "                                'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                                'Precision Test (Alcista)': precision_test_alcista,\n",
        "                                'Recall Test (Alcista)': recall_test_alcista,\n",
        "                                'F1 Test (Alcista)': f1_test_alcista,\n",
        "                                'ROC-AUC Test': roc_auc_test,\n",
        "                                'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                                 'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                                 'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                            })\n",
        "\n",
        "\n",
        "                  else:\n",
        "                       print(f\"\\nWarning: Training data (X_train_full) became empty or contains non-finite values after final filling for scaler fitting for prediction. Skipping prediction for {symbol}.\")\n",
        "                       last_data_date = df.index[-1] if not df.empty else None\n",
        "                       last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                       resultsp.append({\n",
        "                           'Papel': symbol,\n",
        "                           'Fecha Predicción': next_day,\n",
        "                           'Fecha Datos': last_data_date,\n",
        "                           'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                           'Precio actual': last_close,\n",
        "                           'Probabilidad Alcista (Modelo)': None,\n",
        "                           'Umbral de Clasificación': None,\n",
        "                           'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                           'Precision Test (Alcista)': precision_test_alcista,\n",
        "                           'Recall Test (Alcista)': recall_test_alcista,\n",
        "                           'F1 Test (Alcista)': f1_test_alcista,\n",
        "                           'ROC-AUC Test': roc_auc_test,\n",
        "                           'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                            'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                            'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                       })\n",
        "\n",
        "\n",
        "              else:\n",
        "                  print(f\"\\nWarning: Could not make prediction for {symbol} as last_features became empty or contains non-finite values after cleaning.\")\n",
        "                  last_data_date = df.index[-1] if not df.empty else None\n",
        "                  last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                  resultsp.append({\n",
        "                      'Papel': symbol,\n",
        "                      'Fecha Predicción': next_day,\n",
        "                      'Fecha Datos': last_data_date,\n",
        "                      'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                      'Precio actual': last_close,\n",
        "                      'Probabilidad Alcista (Modelo)': None,\n",
        "                      'Umbral de Clasificación': None,\n",
        "                      'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                      'Precision Test (Alcista)': precision_test_alcista,\n",
        "                      'Recall Test (Alcista)': recall_test_alcista,\n",
        "                      'F1 Test (Alcista)': f1_test_alcista,\n",
        "                      'ROC-AUC Test': roc_auc_test,\n",
        "                      'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                       'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                       'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                  })\n",
        "\n",
        "\n",
        "          else:\n",
        "              print(f\"\\nWarning: Could not make prediction for {symbol} as last_features was initially empty.\")\n",
        "              last_data_date = df.index[-1] if not df.empty else None\n",
        "              last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "              resultsp.append({\n",
        "                  'Papel': symbol,\n",
        "                  'Fecha Predicción': next_day,\n",
        "                  'Fecha Datos': last_data_date,\n",
        "                  'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                  'Precio actual': last_close,\n",
        "                  'Probabilidad Alcista (Modelo)': None,\n",
        "                  'Umbral de Clasificación': None,\n",
        "                  'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                  'Precision Test (Alcista)': precision_test_alcista,\n",
        "                  'Recall Test (Alcista)': recall_test_alcista,\n",
        "                  'F1 Test (Alcista)': f1_test_alcista,\n",
        "                  'ROC-AUC Test': roc_auc_test,\n",
        "                  'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                   'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                   'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "              })\n",
        "\n",
        "\n",
        "      except ValueError as e:\n",
        "          # Catch the specific ValueError during RandomizedSearchCV fit\n",
        "          print(f\"\\nERROR: Failed to fit RandomizedSearchCV for {symbol} due to data issues: {e}. Skipping tuning, evaluation, and prediction for this ticker.\")\n",
        "          # Set results for this ticker to None or default values if the fit fails\n",
        "          best_model = None\n",
        "          best_threshold = 0.5 # Use default threshold if model not trained\n",
        "          precision_test_alcista = None\n",
        "          recall_test_alcista = None\n",
        "          f1_test_alcista = None\n",
        "          roc_auc_test = None\n",
        "          ratio_1_test = None\n",
        "\n",
        "          # Append a result entry indicating failure, if you still want a record\n",
        "          last_data_date = df.index[-1] if not df.empty else None\n",
        "          last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "          # Explicitly add None for feature columns if tuning failed\n",
        "          resultsp.append({\n",
        "                'Papel': symbol,\n",
        "                'Fecha Predicción': next_day,\n",
        "                'Fecha Datos': last_data_date,\n",
        "                'Predicción': 'Skipped (Tuning Error)', # More specific error message\n",
        "                'Precio actual': last_close,\n",
        "                'Probabilidad Alcista (Modelo)': None,\n",
        "                'Umbral de Clasificación': None,\n",
        "                'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Tuning Error)',\n",
        "                'Precision Test (Alcista)': precision_test_alcista,\n",
        "                'Recall Test (Alcista)': recall_test_alcista,\n",
        "                'F1 Test (Alcista)': f1_test_alcista,\n",
        "                'ROC-AUC Test': roc_auc_test,\n",
        "                'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                 'Features Limpias (Predicción)': None, # No prediction data if tuning failed\n",
        "                 'Features Escaladas (Predicción)': None # No prediction data if tuning failed\n",
        "          })\n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "          # Catch any other unexpected errors during tuning or evaluation\n",
        "          print(f\"\\nERROR: An unexpected error occurred during tuning or evaluation for {symbol}: {e}. Skipping evaluation and prediction for this ticker.\")\n",
        "          best_model = None\n",
        "          best_threshold = 0.5\n",
        "          precision_test_alcista = None\n",
        "          recall_test_alcista = None\n",
        "          f1_test_alcista = None\n",
        "          roc_auc_test = None\n",
        "          ratio_1_test = None\n",
        "\n",
        "          last_data_date = df.index[-1] if not df.empty else None\n",
        "          last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "          # Explicitly add None for feature columns if an unexpected error occurred\n",
        "          resultsp.append({\n",
        "                'Papel': symbol,\n",
        "                'Fecha Predicción': next_day,\n",
        "                'Fecha Datos': last_data_date,\n",
        "                'Predicción': 'Skipped (Error)',\n",
        "                'Precio actual': last_close,\n",
        "                'Probabilidad Alcista (Modelo)': None,\n",
        "                'Umbral de Clasificación': None,\n",
        "                'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Error)',\n",
        "                'Precision Test (Alcista)': precision_test_alcista,\n",
        "                'Recall Test (Alcista)': recall_test_alcista,\n",
        "                'F1 Test (Alcista)': f1_test_alcista,\n",
        "                'ROC-AUC Test': roc_auc_test,\n",
        "                'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                'Features Limpias (Predicción)': None, # No prediction data if error occurred\n",
        "                'Features Escaladas (Predicción)': None # No prediction data if error occurred\n",
        "          })\n",
        "\n",
        "\n",
        "  else:\n",
        "      print(f\"\\nWarning: Training data (X_train_full or y_train_full) is empty or has only one class after cleaning for tuning for {symbol}. Skipping model training and prediction.\")\n",
        "      # Append a result entry indicating skip due to insufficient training data\n",
        "      last_data_date = df.index[-1] if not df.empty else None\n",
        "      last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "      # Explicitly add None for feature columns if training data is insufficient\n",
        "      resultsp.append({\n",
        "            'Papel': symbol,\n",
        "            'Fecha Predicción': next_day,\n",
        "            'Fecha Datos': last_data_date,\n",
        "            'Predicción': 'Skipped (Insufficient Training Data)',\n",
        "            'Precio actual': last_close,\n",
        "            'Probabilidad Alcista (Modelo)': None,\n",
        "            'Umbral de Clasificación': None,\n",
        "            'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Insufficient Training Data)',\n",
        "            'Precision Test (Alcista)': precision_test_alcista,\n",
        "            'Recall Test (Alcista)': recall_test_alcista,\n",
        "            'F1 Test (Alcista)': f1_test_alcista,\n",
        "            'ROC-AUC Test': roc_auc_test,\n",
        "            'clase 1 en test (cleaned)': ratio_1_test,\n",
        "            'Features Limpias (Predicción)': None, # No prediction data if training data is insufficient\n",
        "            'Features Escaladas (Predicción)': None # No prediction data if training data is insufficient\n",
        "      })\n",
        "\n",
        "\n",
        "# Crear tabla de resultados de predicción\n",
        "resultsp_df = pd.DataFrame(resultsp)\n",
        "print(resultsp_df)\n",
        "if not resultsp_df.empty:\n",
        "    resultsp_df.set_index('Fecha Predicción', inplace=True)\n",
        "\n",
        "    # Mostrar resultados de predicción\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    #pd.set_option('display.max_rows', None) # Optional: display all rows\n",
        "    pd.set_option('display.max_colwidth', None) # Optional: display full content of columns\n",
        "\n",
        "    print(\"\\nPrediccion para el proximo dia (hasta\", next_day.strftime('%Y-%m-%d'), \"):\")\n",
        "    print(\"Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\")\n",
        "    display(resultsp_df) # Use display for better formatting\n",
        "\n",
        "    # Guardar y descargar el CSV de predicciones\n",
        "    resultsp_df.to_csv(f\"Predic_results_{end_date.strftime('%Y-%m-%d')}.csv\", sep=\";\")\n",
        "    files.download(f\"Predic_results_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "    print(f\"\\nArchivo 'Predic_results_{end_date.strftime('%Y-%m-%d')}.csv' generado y descargado.\")\n",
        "else:\n",
        "    print(\"\\nNo hay resultados de predicción para mostrar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "fcd3a4b9-c8ac-42b2-e412-b0aa76a3ae0a",
        "id": "aT2togrtm8-3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 609)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m609\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LA MEJORA DE GK"
      ],
      "metadata": {
        "id": "oqaw_AHkEbnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mas listo que ayer"
      ],
      "metadata": {
        "id": "6x9IIbsCpVUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import files  # Para descargar el CSV en Colab\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "# Funciones de features\n",
        "def add_lagged_price_features(df):\n",
        "    for lag in range(1, 6):\n",
        "        df[f'close_lag_{lag}'] = df['Close'].shift(lag)\n",
        "    return df\n",
        "\n",
        "def add_lagged_price_features(df, etiqueta=\"close_lag\", dato=\"Close\"):\n",
        "    for lag in range(1, 6):\n",
        "        df[f'{etiqueta}_{lag}'] = df[dato].shift(lag)\n",
        "    return df\n",
        "\n",
        "\n",
        "def calculate_RSI(series, period=7):\n",
        "    delta = series.diff(1)\n",
        "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def calculate_ROC(series, period=5):\n",
        "    return ((series - series.shift(period)) / series.shift(period)) * 100\n",
        "\n",
        "def calculate_PPO(series, fast_period=5, slow_period=9, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ppo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ppo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ppo - signal_line\n",
        "    return ppo, signal_line, histogram\n",
        "\n",
        "def calculate_EWO(series, fast_period=5, slow_period=35, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ewo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ewo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ewo - signal_line\n",
        "    return ewo, signal_line, histogram\n",
        "\n",
        "def calculate_volatility(series, window=20):\n",
        "    return series.rolling(window).std().round(6)\n",
        "\n",
        "def calculate_sma5(series, period=5):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma13(series, period=13):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma26(series, period=26):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma50(series, period=50):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma200(series, period=200):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "\n",
        "#def calculate_earnings_season(df):\n",
        "#    df['Is_Earnings_Season'] = df.index.month.isin([1, 4, 7, 10])\n",
        "#    return df\n",
        "\n",
        "#def calculate_christmas_rally(df):\n",
        "#    df['Is_Christmas_Rally'] = df.index.month.isin([11, 12])\n",
        "#    return df\n",
        "\n",
        "def create_features(df):\n",
        "    df = add_lagged_price_features(df, \"close_lag\", \"Close\")\n",
        "    df = add_lagged_price_features(df, \"open_lag\", \"Open\")\n",
        "    df = add_lagged_price_features(df, \"high_lag\", \"High\")\n",
        "    df['Pct_change'] = df['Close'].pct_change()\n",
        "    for lag in range(1, 6):\n",
        "        df[f'lag_change{lag}'] = df['Pct_change'].shift(lag)\n",
        "    df['RSI'] = calculate_RSI(df['Close'])\n",
        "    df['ROC'] = calculate_ROC(df['Close'])\n",
        "    df['PPO'], df['PPO_Signal'], df['PPO_Histogram'] = calculate_PPO(df['Close'])\n",
        "    df['EWO'], df['EWO_Signal'], df['EWO_Histogram'] = calculate_EWO(df['Close'])\n",
        "    df['SMA5'] = calculate_sma5(df['Close'])\n",
        "    df['SMA13'] = calculate_sma13(df['Close'])\n",
        "    df['SMA26'] = calculate_sma26(df['Close'])\n",
        "    df['SMA50'] = calculate_sma50(df['Close'])\n",
        "    df['SMA200'] = calculate_sma200(df['Close'])\n",
        "    df['Volatility'] = calculate_volatility(df['Close'])\n",
        "    df['Label'] = (df['Pct_change'] > 0).astype(int)\n",
        "    df['Return'] = np.log(df['Close'] / df['Close'].shift())\n",
        "    #df = calculate_earnings_season(df)\n",
        "    #df = calculate_christmas_rally(df)\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "# Definir fecha de corte manualmente (cambiar diariamente)\n",
        "end_date = dt.datetime(2025, 7, 23)  # Ejemplo: cambiar a 2025-07-18 mañana\n",
        "\n",
        "tk =[ \"ALUA.BA\", \"BBAR.BA\", \"BMA.BA\", \"COME.BA\", \"CRES.BA\", \"EDN.BA\", \"GGAL.BA\", \"IRSA.BA\", \"LOMA.BA\", \"METR.BA\", \"PAMP.BA\", \"SUPV.BA\", \"TECO2.BA\", \"TGNO4.BA\", \"TGSU2.BA\", \"TRAN.BA\", \"TXAR.BA\", \"VALO.BA\", \"YPFD.BA\"]\n",
        "\n",
        "tk =[ \"ALUA.BA\", \"BBAR.BA\",  \"PAMP.BA\",  \"YPFD.BA\"]\n",
        "\n",
        "# pinchas = \"BYMA.BA\" start_date dt.datetime(2021, 1, 1),  \"CEPU.BA\" start_date  dt.datetime(2018, 1, 1)\n",
        "\n",
        "results = [] # el del test, para que no lo reinicie\n",
        "resultsp = [] # las predicciones, para que no lo reinicie\n",
        "\n",
        "for papel in tk:\n",
        "\n",
        "  symbol=papel\n",
        "  #symbol=\"COME.BA\"\n",
        "  # Fechas dinámicas\n",
        "  start_date = dt.datetime(2001, 1, 1)  # Inicio fijo\n",
        "  train_end = end_date - pd.Timedelta(days=780)  # 6 meses antes de end_date (ajustable)\n",
        "  next_day = end_date + pd.Timedelta(days=1)  # Predicción para el día siguiente\n",
        "  backtest_start = end_date - pd.Timedelta(days=2)  # Inicio del backtesting 6 meses antes de end_date (ajustable)\n",
        "\n",
        "  # Descargar datos\n",
        "  df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=False)\n",
        "\n",
        "  # Verificar datos\n",
        "\n",
        "  for intentos in range(1, 20):\n",
        "    if df.empty:\n",
        "      print(\"No se pudieron descargar datos. Verifica el símbolo, las fechas o la conexión.\")\n",
        "      print(f\"\\n Reintentando {symbol}: {intentos} de 20\")\n",
        "      df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=False)\n",
        "      intentos +=1\n",
        "      time.sleep(8)\n",
        "    else:\n",
        "      print(f\"\\n Datos descargados en {intentos} vueltas: {symbol} , seguimos\")\n",
        "\n",
        "\n",
        "  # Aplanar MultiIndex si existe\n",
        "  if isinstance(df.columns, pd.MultiIndex):\n",
        "      print(\"MultiIndex detectado en columnas. Aplanando...\")\n",
        "      df.columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "      print(\"Columnas asignadas después de aplanamiento:\", df.columns.tolist())\n",
        "      print(\"Últimas filas antes de corrección:\", df.tail())\n",
        "\n",
        "      # Corregir el orden de las columnas según tu mapeo\n",
        "      columns = df.columns.tolist()\n",
        "      df = df[[columns[4], columns[2], columns[3], columns[0], columns[5], columns[1]]]  # Reordenar\n",
        "      df.columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']  # Asignar nombres correctos\n",
        "      print(\"Últimas filas después de corrección:\", df.tail())\n",
        "\n",
        "  if isinstance(df.index, pd.MultiIndex):\n",
        "      print(\"MultiIndex detectado en índice. Seleccionando ticker...\")\n",
        "      df = df.xs(symbol, level='Ticker', axis=0)\n",
        "  df.index = pd.to_datetime(df.index)  # Asegurar índice datetime\n",
        "  if not df.index.is_unique:\n",
        "      print(\"Advertencia: Índice con fechas duplicadas. Eliminando duplicados...\")\n",
        "      df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "  # Verificar columnas\n",
        "  print(\"Columnas del DataFrame después de descargar y corregir:\")\n",
        "  print(df.columns)\n",
        "\n",
        "  df['Open']= df['Open'].round(2)\n",
        "  df['High']= df['High'].round(2)\n",
        "  df['Low']= df['Low'].round(2)\n",
        "  df['Close']= df['Close'].round(2)\n",
        "  df['Adj Close']= df['Adj Close'].round(2)\n",
        "\n",
        "  print(\"Últimas filas del DataFrame antes de crear features:\")\n",
        "  print(df.tail())\n",
        "\n",
        "  # Crear features\n",
        "  df = create_features(df)\n",
        "\n",
        "  # Verificar datos después de crear features\n",
        "  print(\"\\nÚltimas filas del DataFrame después de crear features:\")\n",
        "  print(df.tail())\n",
        "  # Verificar datos después de crear features\n",
        "  print(\"\\nÚltimas filas del DataFrame después de crear features:\")\n",
        "  print(df.tail())\n",
        "  print(df.columns)\n",
        "\n",
        "  print(\"Distribucion de etiquetas\")\n",
        "  print(df[\"Label\"].value_counts(normalize=True))\n",
        "  correlation = df[features + [\"Label\"]].corr()[\"Label\"].sort_values(ascending=False)\n",
        "  print(\"Correlacion con label\")\n",
        "  print(correlation)\n",
        "\n",
        "  # Seleccionar features\n",
        "  features = ['RSI', 'ROC', 'PPO', 'PPO_Signal', 'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'Volatility', 'SMA5', 'SMA13', 'SMA26', 'SMA50', 'SMA200' ] + [f'lag_change{i}' for i in range(1, 6)] + \\\n",
        "            [f'close_lag_{i}' for i in range(1, 6)] + [f'open_lag_{i}' for i in range(1, 6)]+ [f'high_lag_{i}' for i in range(1, 6)]\n",
        "\n",
        "  #features = ['RSI', 'ROC', 'PPO', 'PPO_Signal', 'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'Volatility', 'SMA5', 'SMA13', 'SMA26', 'SMA50', 'SMA200' ] + [f'lag_change{i}' for i in range(1, 6)] + \\\n",
        "  #          [f'close_lag_{i}' for i in range(1, 6)] + [f'open_lag_{i}' for i in range(1, 6)]+ [f'high_lag_{i}' for i in range(1, 6)]\n",
        "  X = df[features]\n",
        "  y = df['Label']\n",
        "\n",
        "  # Dividir datos en entrenamiento y prueba\n",
        "  X_train_full = X[df.index <= train_end]\n",
        "  y_train_full = y[df.index <= train_end]\n",
        "  X_test = X[(df.index > train_end) & (df.index <= end_date)]  # Hasta end_date\n",
        "  y_test = y[(df.index > train_end) & (df.index <= end_date)]\n",
        "\n",
        "  # Optimizar hiperparámetros con RandomizedSearchCV\n",
        "  print(\"Optimizar hiperparámetros con RandomizedSearchCV\")\n",
        "  param_dist = {\n",
        "      'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "      'max_depth': [3, 5, 7, 9],\n",
        "      'n_estimators': [100, 500, 900],\n",
        "      'subsample': [0.6, 0.8, 1.0],\n",
        "      'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "      'gamma': [0, 0.1, 0.2]\n",
        "  }\n",
        "  xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "  random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=20, cv=5, scoring='f1', n_jobs=-1, random_state=42)\n",
        "  random_search.fit(X_train_full, y_train_full)\n",
        "  print(\"Mejores hiperparámetros:\", random_search.best_params_)\n",
        "\n",
        "  # Usar el mejor modelo\n",
        "  best_model = random_search.best_estimator_\n",
        "\n",
        "  # Optimizar el umbral\n",
        "  y_train_prob = best_model.predict_proba(X_train_full)[:, 1]\n",
        "  thresholds = np.arange(0.48, 0.80, 0.01) # de 0.48 a 0.80  con pasos de 0.01????\n",
        "  best_threshold = 0.5\n",
        "  best_f1 = 0\n",
        "  for threshold in thresholds:\n",
        "      y_pred_threshold = (y_train_prob >= threshold).astype(int)\n",
        "      f1 = f1_score(y_train_full, y_pred_threshold)\n",
        "      if f1 > best_f1:\n",
        "          best_f1 = f1\n",
        "          best_threshold = threshold\n",
        "  best_threshold.round(2)\n",
        "  print(\"Mejor umbral:\", best_threshold)\n",
        "\n",
        "\n",
        "\n",
        "  # Backtesting con escalado dinámico para evitar data leak\n",
        "  dates = df[(df.index >= backtest_start) & (df.index <= end_date)].index\n",
        "  #results = []\n",
        "\n",
        "  for test_date in dates:\n",
        "      train_data = df[df.index < test_date].copy()\n",
        "      if train_data.empty or train_data['Label'].isna().all():\n",
        "          continue\n",
        "      train_data = train_data.dropna()\n",
        "\n",
        "      X_train_loop = train_data[features]\n",
        "      y_train_loop = train_data['Label']\n",
        "\n",
        "      scaler = StandardScaler()  # Reinicio dinámico del escalador\n",
        "      X_train_scaled = scaler.fit_transform(X_train_loop)\n",
        "      print(f\"Escalando datos hasta {train_data.index[-1]} para predecir {test_date}\")\n",
        "\n",
        "      best_model.fit(X_train_scaled, y_train_loop)\n",
        "\n",
        "      if test_date in df.index:\n",
        "          test_row = df.loc[[test_date]][features]\n",
        "          if test_row.empty:\n",
        "              continue\n",
        "          test_row_scaled = scaler.transform(test_row)\n",
        "\n",
        "          prediction_prob = best_model.predict_proba(test_row_scaled)[0][1].round(4)\n",
        "          prediction = 1 if prediction_prob >= best_threshold else 0\n",
        "\n",
        "          real_direction = df.loc[test_date, 'Label'] if pd.notna(df.loc[test_date, 'Label']) else None\n",
        "          close_price = df.loc[test_date, 'Close']\n",
        "\n",
        "          is_correct = int(prediction == real_direction) if real_direction is not None else None\n",
        "          data_date = df.index[df.index < test_date][-1] if not df[df.index < test_date].empty else None\n",
        "\n",
        "          results.append({\n",
        "              'Papel': papel,\n",
        "              'Fecha Predicción': test_date,\n",
        "              'Fecha Datos': data_date,\n",
        "              'Predicción': 'Alcista' if prediction == 1 else 'Bajista',\n",
        "              'Resultado Real': 'Alcista' if real_direction == 1 else 'Bajista' if real_direction == 0 else None,\n",
        "              'Precio Cierre': close_price,\n",
        "              'Probabilidad Alcista': prediction_prob,\n",
        "              'Correcta': 'Sí' if is_correct == 1 else 'No' if is_correct == 0 else None\n",
        "          })\n",
        "\n",
        "  # Crear tabla de resultados\n",
        "  results_df = pd.DataFrame(results)\n",
        "  results_df.set_index('Fecha Predicción', inplace=True)\n",
        "\n",
        "  # Mostrar resultados\n",
        "  pd.set_option('display.max_columns', None)\n",
        "  print(\"\\nResultados del backtesting (hasta\", end_date.strftime('%Y-%m-%d'), \"):\")\n",
        "  print(\"Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\")\n",
        "  print(results_df)\n",
        "\n",
        "  # Guardar y descargar el CSV\n",
        "  #results_df.to_csv(f\"backtesting_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv\", sep=\";\")\n",
        "  #files.download(f\"backtesting_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "  #print(f\"\\nArchivo 'backtesting_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv' generado y descargado.\")\n",
        "\n",
        "  # Métricas del backtesting\n",
        "  #if results_df['Correcta'].notna().sum() > 0:\n",
        "  #    accuracy = (results_df['Correcta'] == 'Sí').sum() / results_df['Correcta'].notna().sum()\n",
        "  #    print(f\"\\nAccuracy del backtesting: {accuracy:.2%}\")\n",
        "\n",
        "  #    valid_results = results_df[results_df['Correcta'].notna()]\n",
        "  #    y_true = [1 if r == 'Alcista' else 0 for r in valid_results['Resultado Real']]\n",
        "  #    y_pred = [1 if p == 'Alcista' else 0 for p in valid_results['Predicción']]\n",
        "  #    print(\"\\nMatriz de Confusión:\")\n",
        "  #    print(confusion_matrix(y_true, y_pred))\n",
        "  #    print(\"\\nInforme de Clasificación:\")\n",
        "  #    print(classification_report(y_true, y_pred))\n",
        "\n",
        "  # ROC-AUC para entrenamiento y prueba\n",
        "  if not X_train_full.empty and not X_test.empty:\n",
        "      X_train_scaled = StandardScaler().fit_transform(X_train_full)\n",
        "      X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "      best_model.fit(X_train_scaled, y_train_full)\n",
        "      train_pred_proba = best_model.predict_proba(X_train_scaled)[:, 1]\n",
        "      test_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "      roc_auc_train = roc_auc_score(y_train_full, train_pred_proba)\n",
        "      roc_auc_test = roc_auc_score(y_test, test_pred_proba).round(6)\n",
        "      # Verificar tamaños de las muestras\n",
        "      print(f\"Tamaño de y_train_full: {y_train_full.size}\")\n",
        "      print(f\"Tamaño de y_test: {y_test.size}\")\n",
        "      print(\"Distribución de clases en y_train_full:\")\n",
        "      print(y_train_full.value_counts())\n",
        "      ratio_1_train=(y_train_full.value_counts()[1]/y_train_full.size).round(4)\n",
        "      print(f\"% clase 1 train: {ratio_1_train} \")\n",
        "\n",
        "      print(\"Distribución de clases en y_test:\")\n",
        "      print(y_test.value_counts())\n",
        "      ratio_1_test=(y_test.value_counts()[1]/y_test.size).round(4)\n",
        "      print(f\"% clase 1 test: {ratio_1_test} \")\n",
        "\n",
        "      print(f\"\\nROC-AUC en el conjunto de entrenamiento: {roc_auc_train:.4f}\")\n",
        "      print(roc_auc_train)\n",
        "      print(f\"ROC-AUC en el conjunto de prueba: {roc_auc_test:.4f}\")\n",
        "      y_pred_test = (best_model.predict_proba(X_test_scaled)[:, 1] >= 0.3).astype(int)\n",
        "      print(\"\\nMatriz de Confusión (prueba):\")\n",
        "      print(confusion_matrix(y_test, y_pred_test))\n",
        "      print(\"\\nInforme de Clasificación (prueba):\")\n",
        "      print(classification_report(y_test, y_pred_test))\n",
        "  else:\n",
        "      print(\"\\nAdvertencia: Conjunto de prueba o entrenamiento insuficiente. No se calculó ROC-AUC.\")\n",
        "\n",
        "  print(\"Mejores hiperparámetros:\", random_search.best_params_)\n",
        "  print(\"Mejor umbral:\", best_threshold)\n",
        "\n",
        "\n",
        "  # Predicción para el día siguiente\n",
        "  last_features = df[features].iloc[-1:]\n",
        "  scaler = StandardScaler()\n",
        "  last_features_scaled = scaler.fit_transform(last_features)\n",
        "  future_pred_prob = best_model.predict_proba(last_features_scaled)[0][1].round(4)\n",
        "  future_pred = 1 if future_pred_prob >= best_threshold else 0\n",
        "\n",
        "  returns = df['Return'].dropna()\n",
        "  mean_return = returns.mean()\n",
        "  std_return = returns.std()\n",
        "  last_close = df['Close'].iloc[-1]\n",
        "  expected_price = last_close * np.exp(mean_return + 0.5 * std_return**2)\n",
        "  price_prob = future_pred_prob if future_pred == 1 else 1 - future_pred_prob\n",
        "\n",
        "  action = 'BUY' if future_pred == 1 else 'SELL'\n",
        "  direction = 1 if future_pred == 1 else -1\n",
        "\n",
        "  resultsp.append({\n",
        "              'Papel': papel,\n",
        "              'Fecha Predicción': next_day,\n",
        "              'Fecha Datos': df.index[-1],\n",
        "              'Predicción': 'Alcista' if future_pred == 1 else 'Bajista',\n",
        "              'Resultado Real': \"Veremos\",\n",
        "              'Precio actual': last_close,\n",
        "              'Precio Cierre': \"futuro\",\n",
        "              'Correcta': \"verificar\",\n",
        "              'Probabilidad Alcista': future_pred_prob,\n",
        "              'Umbral': best_threshold,\n",
        "              'ROC-AUC prueba': roc_auc_test ,\n",
        "              'clase 1 en train': str(ratio_1_train),\n",
        "              'clase 1 en test': str(ratio_1_test),\n",
        "              'Mejores hiperparámetros': str(random_search.best_params_),\n",
        "              'Matrix prueba': str(classification_report(y_test, y_pred_test))\n",
        "              #si la pasas a tolist() perdes los titulos\n",
        "              #'Matrix prueba': str((classification_report(y_test, y_pred_test)).tolist())\n",
        "\n",
        "          })\n",
        "  # Crear tabla de resultados\n",
        "  resultsp_df = pd.DataFrame(resultsp)\n",
        "  resultsp_df.set_index('Fecha Predicción', inplace=True)\n",
        "\n",
        "  # Mostrar resultados\n",
        "  pd.set_option('display.max_columns', None)\n",
        "  print(\"\\nPrediccion para el proximo dia (hasta\", next_day.strftime('%Y-%m-%d'), \"):\")\n",
        "  print(\"Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\")\n",
        "  print(resultsp_df)\n",
        "\n",
        "  print(f\"\\nPredicción para {next_day.strftime('%Y-%m-%d')} (basada en datos hasta {df.index[-1].strftime('%Y-%m-%d')}):\")\n",
        "  print(f\"Papel: {symbol}\")\n",
        "  print(f\"Precio actual: [{last_close:.4f}]\")\n",
        "  print(f\"Precio esperado para el siguiente día (distribución log-normal): [{expected_price:.4f}]\")\n",
        "  print(f\"Probabilidad de que el precio predicho sea correcto: [{price_prob:.4f}]\")\n",
        "  print(f\"Corte: {df.index[-1]}\")\n",
        "  print(f\"\\nPredicción para {next_day.strftime('%Y-%m-%d')}: {'Alcista' if future_pred == 1 else 'Bajista'} (Probabilidad Alcista: {future_pred_prob:.2%})\")\n",
        "  print(f\"Pronóstico de dirección del activo (1: subida, -1: bajada): {direction}\")\n",
        "  print(f\"Acción sugerida por la estrategia de trading: {action}\")\n",
        "\n",
        "  print(f\"\\n {symbol}, {next_day.strftime('%d-%m-%y')}, {df.index[-1].strftime('%d-%m-%y')}, {action}, , ,{future_pred_prob:.4}\")\n",
        "\n",
        "\n",
        "# Guardar y descargar el CSV\n",
        "results_df.to_csv(f\"backtesting_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv\", sep=\";\")\n",
        "files.download(f\"backtesting_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "print(f\"\\nArchivo 'backtesting_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv' generado y descargado.\")\n",
        "import time\n",
        "time.sleep(6)\n",
        "\n",
        "resultsp_df.to_csv(f\"Predic_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv\", sep=\";\")\n",
        "files.download(f\"Predic_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "print(f\"\\nArchivo 'Predic_results_{symbol}_{end_date.strftime('%Y-%m-%d')}.csv' generado y descargado.\")"
      ],
      "metadata": {
        "id": "OReUSMZapafA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a23e45c6-7d71-4c3e-82b8-caec6ee6f49a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Datos descargados en 1 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 2 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 3 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 4 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 5 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 6 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 7 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 8 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 9 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 10 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 11 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 12 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 13 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 14 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 15 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 16 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 17 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 18 vueltas: ALUA.BA , seguimos\n",
            "\n",
            " Datos descargados en 19 vueltas: ALUA.BA , seguimos\n",
            "MultiIndex detectado en columnas. Aplanando...\n",
            "Columnas asignadas después de aplanamiento: ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
            "Últimas filas antes de corrección:              Open   High    Low  Close  Volume  Adj Close\n",
            "Date                                                     \n",
            "2025-07-16  706.0  706.0  725.0  694.0   725.0     500054\n",
            "2025-07-17  699.0  699.0  715.0  696.0   708.0     858480\n",
            "2025-07-18  723.0  723.0  726.0  686.0   702.0     567030\n",
            "2025-07-21  708.0  708.0  735.0  705.0   711.0     548377\n",
            "2025-07-22  689.0  689.0  715.0  680.0   708.0     627483\n",
            "Últimas filas después de corrección:              Open   High    Low  Close  Volume  Adj Close\n",
            "Date                                                     \n",
            "2025-07-16  725.0  725.0  694.0  706.0  500054      706.0\n",
            "2025-07-17  708.0  715.0  696.0  699.0  858480      699.0\n",
            "2025-07-18  702.0  726.0  686.0  723.0  567030      723.0\n",
            "2025-07-21  711.0  735.0  705.0  708.0  548377      708.0\n",
            "2025-07-22  708.0  715.0  680.0  689.0  627483      689.0\n",
            "Columnas del DataFrame después de descargar y corregir:\n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'], dtype='object')\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "             Open   High    Low  Close  Volume  Adj Close\n",
            "Date                                                     \n",
            "2025-07-16  725.0  725.0  694.0  706.0  500054      706.0\n",
            "2025-07-17  708.0  715.0  696.0  699.0  858480      699.0\n",
            "2025-07-18  702.0  726.0  686.0  723.0  567030      723.0\n",
            "2025-07-21  711.0  735.0  705.0  708.0  548377      708.0\n",
            "2025-07-22  708.0  715.0  680.0  689.0  627483      689.0\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "             Open   High    Low  Close  Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-07-16  725.0  725.0  694.0  706.0  500054      706.0        717.0   \n",
            "2025-07-17  708.0  715.0  696.0  699.0  858480      699.0        706.0   \n",
            "2025-07-18  702.0  726.0  686.0  723.0  567030      723.0        699.0   \n",
            "2025-07-21  711.0  735.0  705.0  708.0  548377      708.0        723.0   \n",
            "2025-07-22  708.0  715.0  680.0  689.0  627483      689.0        708.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  ...  EWO_Signal  \\\n",
            "Date                                               ...               \n",
            "2025-07-16        729.0        683.0        683.0  ...    0.314669   \n",
            "2025-07-17        717.0        729.0        683.0  ...    0.242494   \n",
            "2025-07-18        706.0        717.0        729.0  ...    0.422993   \n",
            "2025-07-21        699.0        706.0        717.0  ...    0.485628   \n",
            "2025-07-22        723.0        699.0        706.0  ...    0.237972   \n",
            "\n",
            "            EWO_Histogram   SMA5     SMA13     SMA26   SMA50    SMA200  \\\n",
            "Date                                                                     \n",
            "2025-07-16       0.191698  703.6  712.0769  684.8077  704.54  811.6996   \n",
            "2025-07-17      -0.144350  706.8  711.5385  684.5000  705.34  810.6953   \n",
            "2025-07-18       0.360997  714.8  711.8462  686.2308  706.22  809.8659   \n",
            "2025-07-21       0.125270  710.6  711.2308  686.9231  707.12  809.0364   \n",
            "2025-07-22      -0.495313  705.0  707.6154  687.0385  707.92  808.0619   \n",
            "\n",
            "            Volatility  Label    Return  \n",
            "Date                                     \n",
            "2025-07-16   44.147957      0 -0.015461  \n",
            "2025-07-17   42.431214      0 -0.009964  \n",
            "2025-07-18   40.609825      1  0.033758  \n",
            "2025-07-21   37.097453      0 -0.020965  \n",
            "2025-07-22   25.984763      0 -0.027203  \n",
            "\n",
            "[5 rows x 43 columns]\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "             Open   High    Low  Close  Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-07-16  725.0  725.0  694.0  706.0  500054      706.0        717.0   \n",
            "2025-07-17  708.0  715.0  696.0  699.0  858480      699.0        706.0   \n",
            "2025-07-18  702.0  726.0  686.0  723.0  567030      723.0        699.0   \n",
            "2025-07-21  711.0  735.0  705.0  708.0  548377      708.0        723.0   \n",
            "2025-07-22  708.0  715.0  680.0  689.0  627483      689.0        708.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  ...  EWO_Signal  \\\n",
            "Date                                               ...               \n",
            "2025-07-16        729.0        683.0        683.0  ...    0.314669   \n",
            "2025-07-17        717.0        729.0        683.0  ...    0.242494   \n",
            "2025-07-18        706.0        717.0        729.0  ...    0.422993   \n",
            "2025-07-21        699.0        706.0        717.0  ...    0.485628   \n",
            "2025-07-22        723.0        699.0        706.0  ...    0.237972   \n",
            "\n",
            "            EWO_Histogram   SMA5     SMA13     SMA26   SMA50    SMA200  \\\n",
            "Date                                                                     \n",
            "2025-07-16       0.191698  703.6  712.0769  684.8077  704.54  811.6996   \n",
            "2025-07-17      -0.144350  706.8  711.5385  684.5000  705.34  810.6953   \n",
            "2025-07-18       0.360997  714.8  711.8462  686.2308  706.22  809.8659   \n",
            "2025-07-21       0.125270  710.6  711.2308  686.9231  707.12  809.0364   \n",
            "2025-07-22      -0.495313  705.0  707.6154  687.0385  707.92  808.0619   \n",
            "\n",
            "            Volatility  Label    Return  \n",
            "Date                                     \n",
            "2025-07-16   44.147957      0 -0.015461  \n",
            "2025-07-17   42.431214      0 -0.009964  \n",
            "2025-07-18   40.609825      1  0.033758  \n",
            "2025-07-21   37.097453      0 -0.020965  \n",
            "2025-07-22   25.984763      0 -0.027203  \n",
            "\n",
            "[5 rows x 43 columns]\n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Label', 'Return'],\n",
            "      dtype='object')\n",
            "Distribucion de etiquetas\n",
            "Label\n",
            "0    0.55173\n",
            "1    0.44827\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Max_Gain_from_Open_Current', 'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2', 'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4', 'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-688964401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Distribucion de etiquetas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m   \u001b[0mcorrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correlacion con label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Max_Gain_from_Open_Current', 'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2', 'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4', 'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YIHUxFvhthtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMIENZA EL UMBRAL"
      ],
      "metadata": {
        "id": "xjiSoEl0ijkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "\n",
        "# Descargar datos (si no lo hiciste aún)\n",
        "end_date = dt.datetime(2025, 7, 20)\n",
        "df = yf.download(\"COME.BA\", start=dt.datetime(2001, 1, 1), end=end_date)\n",
        "\n",
        "# Definir umbral (por ejemplo, 2%)\n",
        "umbral = 0.02\n",
        "\n",
        "# Calcular la diferencia relativa y etiquetar\n",
        "df['Label'] = ((df['High'] - df['Open']) / df['Open'] > umbral).astype(int) * 2 - 1\n",
        "\n",
        "# Contar etiquetas y calcular porcentajes\n",
        "label_counts = df['Label'].value_counts()\n",
        "total_dias = len(df)\n",
        "percentages = (label_counts / total_dias) * 100\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Conteo de etiquetas:\")\n",
        "print(label_counts)\n",
        "print(\"\\nPorcentajes de cada clase (%):\")\n",
        "print(percentages.round(2))\n",
        "\n",
        "# Opcional: Ver los primeros días etiquetados\n",
        "print(\"\\nPrimeros días etiquetados:\")\n",
        "print(df[['Open', 'High', 'Label']].tail(20))\n",
        "print(\"mambral\")\n",
        "umbral = df['High'].sub(df['Open']).div(df['Open']).quantile(0.75)\n",
        "print(umbral)\n",
        "df['Label'] = ((df['High'] - df['Open']) / df['Open'] > umbral).astype(int) * 2 - 1\n",
        "print(df['Label'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Contar etiquetas y calcular porcentajes\n",
        "label_counts = df['Label'].value_counts()\n",
        "total_dias = len(df)\n",
        "percentages = (label_counts / total_dias) * 100\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Conteo de etiquetas:\")\n",
        "print(label_counts)\n",
        "print(\"\\nPorcentajes de cada clase (%):\")\n",
        "print(percentages.round(2))"
      ],
      "metadata": {
        "id": "-ItKP7EgLl9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "\n",
        "# Descargar datos\n",
        "end_date = dt.datetime(2025, 7, 30)\n",
        "df = yf.download(\"GGAL\", start=dt.datetime(2001, 1, 1), end=end_date)\n",
        "\n",
        "# Aplanar el MultiIndex a columnas simples\n",
        "df.columns = df.columns.map(lambda x: x[0])\n",
        "\n",
        "# Limpiar datos\n",
        "df = df.dropna(subset=['Open', 'High'])\n",
        "\n",
        "# Calcular umbral dinámico\n",
        "#differences = (df['High'] - df['Open']) / df['Open']\n",
        "#umbral = differences.quantile(0.6).item()\n",
        "#print(f\"Umbral calculado: {umbral:.4f}\")\n",
        "umbral = 0.019\n",
        "lapso = 2\n",
        "\n",
        "# Calcular etiqueta sin desfase (para verificar)\n",
        "df['Label_raw'] = ((df['High'] - df['Open']) / df['Open'] > umbral).astype(int) * 2 - 1\n",
        "\n",
        "# Desplazar la etiqueta un día hacia atrás (target del día \"lapso\")\n",
        "df['Label'] = df['Label_raw'].shift(-lapso)\n",
        "\n",
        "# Eliminar la última fila (no tiene etiqueta para predecir)\n",
        "df = df.dropna(subset=['Label'])\n",
        "print(df.tail(33))\n",
        "# Contar etiquetas y calcular porcentajes\n",
        "label_counts = df['Label'].value_counts()\n",
        "total_dias = len(df)\n",
        "percentages = (label_counts / total_dias) * 100\n",
        "\n",
        "print(\"\\nConteo de etiquetas (desfasadas):\")\n",
        "print(label_counts)\n",
        "print(\"\\nPorcentajes de cada clase (%):\")\n",
        "print(percentages.round(2))\n",
        "\n",
        "# Opcional: Ver los primeros días etiquetados\n",
        "print(\"\\nPrimeros días etiquetados (features del día anterior, label del día siguiente):\")\n",
        "print(df[['Open', 'High', 'Label']].tail(22))"
      ],
      "metadata": {
        "id": "BYoBb-mnRDDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00cf7f03-710f-4dc4-c0ef-c792b4aae169"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4277981074.py:7: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(\"GGAL\", start=dt.datetime(2001, 1, 1), end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Close       High        Low       Open   Volume  Label_raw  \\\n",
            "Date                                                                         \n",
            "2025-06-09  53.657017  55.156869  53.508023  54.997944   973800         -1   \n",
            "2025-06-10  56.944775  57.530807  53.885469  54.153655  1459600          1   \n",
            "2025-06-11  55.822369  55.901829  52.743197  54.630431  7670800          1   \n",
            "2025-06-12  55.762772  56.885180  54.382112  55.027746  2270100          1   \n",
            "2025-06-13  54.302647  55.623712  53.716615  55.176735  1772100         -1   \n",
            "2025-06-16  54.133789  55.216465  53.885469  54.709894  1057500         -1   \n",
            "2025-06-17  53.984795  54.600631  52.465077  53.418625  1329000          1   \n",
            "2025-06-18  53.786144  54.948281  53.329232  53.925203   979700         -1   \n",
            "2025-06-20  51.650589  53.716614  51.581060  53.716614  1124700         -1   \n",
            "2025-06-23  50.031540  51.968438  49.723625  51.134082  1593000         -1   \n",
            "2025-06-24  52.326019  53.090846  50.657308  50.657308  1284100          1   \n",
            "2025-06-25  51.322803  52.862391  51.153948  52.326019  1152700         -1   \n",
            "2025-06-26  51.600925  52.554474  51.203612  51.352605  1170200          1   \n",
            "2025-06-27  51.322803  52.186960  50.865895  51.531395   896100         -1   \n",
            "2025-06-30  50.051403  52.296219  48.928995  51.600922  2046900         -1   \n",
            "2025-07-01  49.654095  51.273139  49.256781  49.733555  1600400          1   \n",
            "2025-07-02  50.041473  50.577842  49.326310  49.465369  1632500          1   \n",
            "2025-07-03  50.667236  50.756632  49.991809  50.150734   461300         -1   \n",
            "2025-07-07  48.025112  50.389121  47.280152  50.329523  1573900         -1   \n",
            "2025-07-08  50.349392  50.379193  47.478812  48.263504  1699700          1   \n",
            "2025-07-09  49.644161  51.362536  49.554766  50.855965  1527000         -1   \n",
            "2025-07-10  48.382694  49.236916  47.866188  48.869403  1254000         -1   \n",
            "2025-07-11  46.783512  48.253571  46.515330  47.985384  1267600         -1   \n",
            "2025-07-14  46.475597  47.260290  45.780300  46.147813   852900          1   \n",
            "2025-07-15  47.141094  47.488745  45.571713  46.495464  1103900          1   \n",
            "2025-07-16  46.068352  47.478808  45.710770  47.399348  1449500         -1   \n",
            "2025-07-17  47.389416  47.905922  45.929296  46.187547  1514900          1   \n",
            "2025-07-18  46.902710  48.621085  46.813315  47.945654   871000         -1   \n",
            "2025-07-21  46.763653  47.935720  46.187548  46.982172  1033100          1   \n",
            "2025-07-22  47.488743  48.233703  46.386201  46.763649  1375300          1   \n",
            "2025-07-23  48.919067  49.226986  47.895990  48.233705  1594600          1   \n",
            "2025-07-24  50.716904  50.875828  48.283366  48.770071  1747900          1   \n",
            "2025-07-25  51.422134  52.753130  50.905628  51.442000  1403400          1   \n",
            "\n",
            "            Label  \n",
            "Date               \n",
            "2025-06-09    1.0  \n",
            "2025-06-10    1.0  \n",
            "2025-06-11   -1.0  \n",
            "2025-06-12   -1.0  \n",
            "2025-06-13    1.0  \n",
            "2025-06-16   -1.0  \n",
            "2025-06-17   -1.0  \n",
            "2025-06-18   -1.0  \n",
            "2025-06-20    1.0  \n",
            "2025-06-23   -1.0  \n",
            "2025-06-24    1.0  \n",
            "2025-06-25   -1.0  \n",
            "2025-06-26   -1.0  \n",
            "2025-06-27    1.0  \n",
            "2025-06-30    1.0  \n",
            "2025-07-01   -1.0  \n",
            "2025-07-02   -1.0  \n",
            "2025-07-03    1.0  \n",
            "2025-07-07   -1.0  \n",
            "2025-07-08   -1.0  \n",
            "2025-07-09   -1.0  \n",
            "2025-07-10    1.0  \n",
            "2025-07-11    1.0  \n",
            "2025-07-14   -1.0  \n",
            "2025-07-15    1.0  \n",
            "2025-07-16   -1.0  \n",
            "2025-07-17    1.0  \n",
            "2025-07-18    1.0  \n",
            "2025-07-21    1.0  \n",
            "2025-07-22    1.0  \n",
            "2025-07-23    1.0  \n",
            "2025-07-24   -1.0  \n",
            "2025-07-25    1.0  \n",
            "\n",
            "Conteo de etiquetas (desfasadas):\n",
            "Label\n",
            "-1.0    3200\n",
            " 1.0    2977\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Porcentajes de cada clase (%):\n",
            "Label\n",
            "-1.0    51.81\n",
            " 1.0    48.19\n",
            "Name: count, dtype: float64\n",
            "\n",
            "Primeros días etiquetados (features del día anterior, label del día siguiente):\n",
            "                 Open       High  Label\n",
            "Date                                   \n",
            "2025-06-25  52.326019  52.862391   -1.0\n",
            "2025-06-26  51.352605  52.554474   -1.0\n",
            "2025-06-27  51.531395  52.186960    1.0\n",
            "2025-06-30  51.600922  52.296219    1.0\n",
            "2025-07-01  49.733555  51.273139   -1.0\n",
            "2025-07-02  49.465369  50.577842   -1.0\n",
            "2025-07-03  50.150734  50.756632    1.0\n",
            "2025-07-07  50.329523  50.389121   -1.0\n",
            "2025-07-08  48.263504  50.379193   -1.0\n",
            "2025-07-09  50.855965  51.362536   -1.0\n",
            "2025-07-10  48.869403  49.236916    1.0\n",
            "2025-07-11  47.985384  48.253571    1.0\n",
            "2025-07-14  46.147813  47.260290   -1.0\n",
            "2025-07-15  46.495464  47.488745    1.0\n",
            "2025-07-16  47.399348  47.478808   -1.0\n",
            "2025-07-17  46.187547  47.905922    1.0\n",
            "2025-07-18  47.945654  48.621085    1.0\n",
            "2025-07-21  46.982172  47.935720    1.0\n",
            "2025-07-22  46.763649  48.233703    1.0\n",
            "2025-07-23  48.233705  49.226986    1.0\n",
            "2025-07-24  48.770071  50.875828   -1.0\n",
            "2025-07-25  51.442000  52.753130    1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hasta aca llegaste"
      ],
      "metadata": {
        "id": "4Iv_tFlc_3zZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**apruebas**"
      ],
      "metadata": {
        "id": "j2LNBCdg3z79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import files\n",
        "from scipy import stats\n",
        "import time\n",
        "\n",
        "\n",
        "# Functions for features\n",
        "def add_lagged_price_features(df, etiqueta=\"close_lag\", dato=\"Close\"):\n",
        "    for lag in range(1, 6):\n",
        "        df[f'{etiqueta}_{lag}'] = df[dato].shift(lag)\n",
        "    return df\n",
        "\n",
        "def calculate_RSI(series, period=7):\n",
        "    delta = series.diff(1)\n",
        "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def calculate_ROC(series, period=5):\n",
        "    return ((series - series.shift(period)) / series.shift(period)) * 100\n",
        "\n",
        "def calculate_PPO(series, fast_period=5, slow_period=9, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ppo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ppo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ppo - signal_line\n",
        "    return ppo, signal_line, histogram\n",
        "\n",
        "def calculate_EWO(series, fast_period=5, slow_period=35, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ewo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ewo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ewo - signal_line\n",
        "    return ewo, signal_line, histogram\n",
        "\n",
        "def calculate_volatility(series, window=20):\n",
        "    return series.rolling(window).std().round(6)\n",
        "\n",
        "def calculate_sma5(series, period=5):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma13(series, period=13):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma26(series, period=26):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma50(series, period=50):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma200(series, period=200):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "\n",
        "def create_features(df, umbral, n_days_high=1):\n",
        "    df = add_lagged_price_features(df, \"close_lag\", \"Close\")\n",
        "    df = add_lagged_price_features(df, \"open_lag\", \"Open\")\n",
        "    df = add_lagged_price_features(df, \"high_lag\", \"High\")\n",
        "    df['Pct_change'] = df['Close'].pct_change()\n",
        "    for lag in range(1, 6):\n",
        "        df[f'lag_change{lag}'] = df['Pct_change'].shift(lag)\n",
        "    df['RSI'] = calculate_RSI(df['Close'])\n",
        "    df['ROC'] = calculate_ROC(df['Close'])\n",
        "    df['PPO'], df['PPO_Signal'], df['PPO_Histogram'] = calculate_PPO(df['Close'])\n",
        "    df['EWO'], df['EWO_Signal'], df['EWO_Histogram'] = calculate_EWO(df['Close'])\n",
        "    df['SMA5'] = calculate_sma5(df['Close'])\n",
        "    df['SMA13'] = calculate_sma13(df['Close'])\n",
        "    df['SMA26'] = calculate_sma26(df['Close'])\n",
        "    df['SMA50'] = calculate_sma50(df['Close'])\n",
        "    df['SMA200'] = calculate_sma200(df['Close'])\n",
        "    df['Volatility'] = calculate_volatility(df['Close'])\n",
        "\n",
        "    # --- New Feature: Max Gain from Open over Past N Days ---\n",
        "    # Calculate the maximum High price over the *next N days* for *each historical day*.\n",
        "    # Use rolling().max() with min_periods=1 to handle ends of series.\n",
        "    # Then shift to align with the start of the N-day window (the current day's Open).\n",
        "    max_high_over_next_n_days_hist = df['High'].rolling(window=n_days_high, min_periods=1).max().shift(-n_days_high + 1)\n",
        "\n",
        "\n",
        "    # Calculate the potential max gain from Open for *each historical day*\n",
        "    # Using the Open price of that historical day\n",
        "    epsilon = 1e-9 # To prevent division by zero\n",
        "    df['Max_Gain_from_Open_Current'] = (max_high_over_next_n_days_hist - df['Open']) / (df['Open'] + epsilon)\n",
        "\n",
        "    # --- Add lagged versions of the new feature ---\n",
        "    for lag in range(1, 7): # Create lags from 1 to 6\n",
        "        df[f'Max_Gain_from_Open_Lag_{lag}'] = df['Max_Gain_from_Open_Current'].shift(lag)\n",
        "\n",
        "\n",
        "    # Calculate the target based on tomorrow's Open vs Max High over next n_days_high days\n",
        "    # Use rolling().max() with min_periods=1 for the target as well.\n",
        "    # Shift to align with the start of the N-day window for the target (tomorrow's Open).\n",
        "    max_high_next_n_days_target = df['High'].rolling(window=n_days_high, min_periods=1).max().shift(-n_days_high + 1)\n",
        "    open_next_day = df['Open'].shift(-1)\n",
        "    df['Label_raw'] = ((max_high_next_n_days_target - open_next_day) / (open_next_day + epsilon) > umbral).astype(int)\n",
        "    df['Label'] = df['Label_raw'].shift(-1) # Target for the next day\n",
        "\n",
        "\n",
        "    # Replace inf values with NaN before dropping\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Dropping NaNs here will remove rows where features or the target are still NaN (e.g., due to initial lags,\n",
        "    # or if min_periods=1 still results in NaN for very short series, although less likely now for the rolling max).\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Definir fecha de corte manualmente (cambiar diariamente)\n",
        "end_date = dt.datetime(2025, 9, 14)  # Ejemplo: cambiar a 2025-07-18 mañana\n",
        "\n",
        "tk =[ \"ALUA.BA\", \"BBAR.BA\", \"BMA.BA\", \"COME.BA\", \"CRES.BA\", \"EDN.BA\", \"GGAL.BA\", \"IRSA.BA\", \"LOMA.BA\", \"METR.BA\", \"PAMP.BA\", \"SUPV.BA\", \"TECO2.BA\", \"TGNO4.BA\", \"TGSU2.BA\", \"TRAN.BA\", \"TXAR.BA\", \"VALO.BA\", \"YPFD.BA\"]\n",
        "\n",
        "tk =[ \"ALUA.BA\", \"BBAR.BA\", \"METR.BA\", \"PAMP.BA\", \"TRAN.BA\",  \"YPFD.BA\"]\n",
        "\n",
        "\n",
        "# results = [] # el del test, para que no lo reinicie - REMOVED\n",
        "resultsp = [] # las predicciones, para que no lo reinicie\n",
        "\n",
        "umbral = 0.019\n",
        "lapso = 1 # Lapso is no longer directly used for the target definition, but keeping it doesn't hurt\n",
        "n_days_high_target = 3 # Define the number of days for the High target (used for both target and new feature)\n",
        "\n",
        "# Define clipping bounds - adjust based on feature distributions\n",
        "lower_bound = -1e9\n",
        "upper_bound = 1e9\n",
        "\n",
        "\n",
        "for papel in tk:\n",
        "\n",
        "  symbol=papel\n",
        "  #symbol=\"COME.BA\"\n",
        "  # Fechas dinámicas\n",
        "  start_date = dt.datetime(2001, 1, 1)  # Inicio fijo\n",
        "  train_end = end_date - pd.Timedelta(days=780)  # 6 meses antes de end_date (ajustable)\n",
        "  next_day = end_date + pd.Timedelta(days=1)  # Predicción para el día siguiente\n",
        "\n",
        "\n",
        "  # Select features - Add the new feature and its lags\n",
        "  features = ['RSI', 'ROC', 'PPO', 'PPO_Signal', 'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'Volatility', 'SMA5', 'SMA13', 'SMA26', 'SMA50', 'SMA200' ] + [f'lag_change{i}' for i in range(1, 6)] + \\\n",
        "            [f'close_lag_{i}' for i in range(1, 6)] + [f'open_lag_{i}' for i in range(1, 6)]+ [f'high_lag_{i}' for i in range(1, 6)] + \\\n",
        "            ['Max_Gain_from_Open_Current'] + [f'Max_Gain_from_Open_Lag_{i}' for i in range(1, 7)]\n",
        "\n",
        "\n",
        "  # Download data for the current ticker inside the loop\n",
        "  print(f\"\\nDownloading data for {symbol}...\")\n",
        "  df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=False)\n",
        "\n",
        "  # Verify data download\n",
        "  if df.empty:\n",
        "      print(f\"Warning: No data downloaded for {symbol}. Skipping.\")\n",
        "      continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "  # Handle MultiIndex columns and ensure standard column names - More robust logic\n",
        "  required_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "  processed_df = None # Initialize processed_df\n",
        "\n",
        "  if isinstance(df.columns, pd.MultiIndex):\n",
        "      print(f\"MultiIndex columns detected for {symbol}.\")\n",
        "      try:\n",
        "          # Attempt to extract columns by looking for standard names in ANY level of the MultiIndex tuple\n",
        "          extracted_data = {}\n",
        "          for std_name in required_cols:\n",
        "              matching_col_tuple = None\n",
        "              # Iterate through all column tuples\n",
        "              for col_tuple in df.columns:\n",
        "                  # Check if the standard name exists in ANY level of the current tuple\n",
        "                  if std_name in col_tuple:\n",
        "                       matching_col_tuple = col_tuple\n",
        "                       break # Found a match in this tuple\n",
        "\n",
        "              if matching_col_tuple:\n",
        "                  extracted_data[std_name] = df[matching_col_tuple]\n",
        "              else:\n",
        "                  print(f\"Warning: Could not find standard column '{std_name}' in any level of MultiIndex for {symbol}. Column missing.\")\n",
        "                  # Continue to look for other required columns, processed_df will be checked later\n",
        "\n",
        "          if len(extracted_data) == len(required_cols):\n",
        "              processed_df = pd.DataFrame(extracted_data)\n",
        "              processed_df.index = df.index # Preserve original index\n",
        "              print(f\"Successfully extracted and flattened MultiIndex columns for {symbol}.\")\n",
        "          else:\n",
        "              missing_cols = [name for name in required_cols if name not in extracted_data]\n",
        "              print(f\"Warning: Could not extract all required columns from MultiIndex for {symbol}. Missing: {missing_cols}. Skipping ticker.\")\n",
        "              continue # Skip to the next ticker\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Warning: An error occurred while processing MultiIndex columns for {symbol}: {e}. Skipping.\")\n",
        "          #print(f\"Original columns: {df.columns.tolist()}\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "  else: # If not MultiIndex columns, assume standard flat DataFrame is already present\n",
        "      print(f\"No MultiIndex columns detected for {symbol}. Checking for standard columns.\")\n",
        "      # Check if the required columns are directly present\n",
        "      if all(col in df.columns for col in required_cols):\n",
        "          processed_df = df[required_cols].copy() # Select required columns and make a copy\n",
        "          print(f\"Using existing standard columns for {symbol}.\")\n",
        "      else:\n",
        "          missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "          print(f\"Warning: Required standard columns not found in flat DataFrame for {symbol}. Missing: {missing_cols}. Skipping ticker.\")\n",
        "          #print(f\"Available columns: {df.columns.tolist()}\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "  # Ensure df is set to processed_df if successful\n",
        "  df = processed_df\n",
        "\n",
        "  # Handle MultiIndex index if present (less common with single ticker download but possible)\n",
        "  if isinstance(df.index, pd.MultiIndex):\n",
        "      print(f\"MultiIndex index detected for {symbol}. Attempting to flatten index.\")\n",
        "      try:\n",
        "          # Assuming the MultiIndex index structure is ('Ticker', 'Date')\n",
        "          if 'Ticker' in df.index.names:\n",
        "               df = df.xs(symbol, level='Ticker', axis=0)\n",
        "               print(f\"Índice aplanado para {symbol}.\")\n",
        "          else:\n",
        "               print(f\"Warning: MultiIndex index detected for {symbol} but 'Ticker' level not found. Skipping index flattening.\")\n",
        "               # If 'Ticker' level is not there, maybe it's just a date/time MultiIndex?\n",
        "               # Or a different structure. For now, proceed without flattening index if Ticker level is missing.\n",
        "\n",
        "\n",
        "      except KeyError:\n",
        "          print(f\"Warning: Could not select ticker from MultiIndex index for {symbol}. Skipping.\")\n",
        "          continue # Skip to the next ticker\n",
        "      except Exception as e:\n",
        "          print(f\"Warning: An error occurred while flattening MultiIndex index for {symbol}: {e}. Skipping.\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "  df.index = pd.to_datetime(df.index)\n",
        "  if not df.index.is_unique:\n",
        "      print(f\"Advertencia: Índice con fechas duplicadas para {symbol}. Eliminando duplicados...\")\n",
        "      df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after initial processing and cleaning for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  # Ensure numeric types and handle potential non-numeric data\n",
        "  for col in required_cols:\n",
        "      if col in df.columns: # Ensure column exists before processing\n",
        "          df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "      else:\n",
        "           # This should ideally not happen if previous checks passed, but as a safeguard:\n",
        "           print(f\"Error: Required column '{col}' not found in df for {symbol} before numeric conversion. Skipping ticker.\")\n",
        "           df = pd.DataFrame() # Set df to empty to skip further processing\n",
        "           break # Exit column processing loop\n",
        "\n",
        "\n",
        "  if df.empty: # Check again if df became empty due to missing columns\n",
        "       continue # Skip to the next ticker\n",
        "\n",
        "  # Drop rows where essential price data is missing after coercion\n",
        "  df.dropna(subset=['Open', 'High', 'Low', 'Close'], inplace=True)\n",
        "\n",
        "\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after dropping rows with missing price data for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  df['Open']= df['Open'].round(2)\n",
        "  df['High']= df['High'].round(2)\n",
        "  df['Low']= df['Low'].round(2)\n",
        "  df['Close']= df['Close'].round(2)\n",
        "  df['Adj Close']= df['Adj Close'].round(2)\n",
        "\n",
        "  print(\"Últimas filas del DataFrame antes de crear features:\")\n",
        "  print(df.tail())\n",
        "\n",
        "\n",
        "  # Crear features with the new target definition\n",
        "  df = create_features(df, umbral=umbral, n_days_high=n_days_high_target) # Pass n_days_high_target, removed lapso\n",
        "\n",
        "  # Verify data is not empty after feature creation and dropna\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after feature creation and dropna for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  # Verify data after creating features\n",
        "  print(\"\\nÚltimas filas del DataFrame después de crear features:\")\n",
        "  print(df.tail())\n",
        "  print(df.columns)\n",
        "\n",
        "  print(f\"Distribucion de etiquetas para {symbol}:\")\n",
        "  print(df[\"Label\"].value_counts(normalize=True))\n",
        "\n",
        "  # Check if there are samples from both classes in the target variable\n",
        "  if len(df[\"Label\"].unique()) < 2:\n",
        "      print(f\"Warning: Target variable 'Label' contains only one class for {symbol} after feature creation. Cannot train a classifier. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  correlation = df[features + [\"Label\"]].corr()[\"Label\"].sort_values(ascending=False)\n",
        "  print(f\"Correlacion con label para {symbol}:\")\n",
        "  print(correlation)\n",
        "\n",
        "\n",
        "  # Dividir datos en entrenamiento y prueba\n",
        "  X = df[features]\n",
        "  y = df['Label']\n",
        "  X_train_full = X[df.index <= train_end]\n",
        "  y_train_full = y[df.index <= train_end]\n",
        "  X_test = X[(df.index > train_end) & (df.index <= end_date)]  # Hasta end_date\n",
        "  y_test = y[(df.index > train_end) & (df.index <= end_date)]\n",
        "\n",
        "  # Verify training and test sets are not empty and have both classes\n",
        "  if X_train_full.empty or y_train_full.empty or len(y_train_full.unique()) < 2:\n",
        "      print(f\"Warning: Training data is insufficient or has only one class for {symbol}. Skipping model training and prediction.\")\n",
        "      continue\n",
        "\n",
        "  # Initialize test metrics before evaluation\n",
        "  precision_test_alcista = None\n",
        "  recall_test_alcista = None\n",
        "  f1_test_alcista = None\n",
        "  roc_auc_test = None\n",
        "  ratio_1_test = None\n",
        "  best_model = None # Initialize best_model to None\n",
        "  best_threshold = 0.5 # Initialize best_threshold to default\n",
        "\n",
        "\n",
        "  # Optimizar hiperparámetros con RandomizedSearchCV\n",
        "  print(f\"Optimizar hiperparámetros con RandomizedSearchCV para {symbol}\")\n",
        "  param_dist = {\n",
        "      'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "      'max_depth': [3, 5, 7, 9],\n",
        "      'n_estimators': [100, 500, 900],\n",
        "      'subsample': [0.6, 0.8, 1.0],\n",
        "      'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "      'gamma': [0, 0.1, 0.2],\n",
        "      'scale_pos_weight': [0.5, 1, 2, 5, 10, 20, 50, 100] # Incluir scale_pos_weight en la búsqueda\n",
        "  }\n",
        "\n",
        "  # Inicializar el clasificador XGBoost sin scale_pos_weight fijo (se tuneará)\n",
        "  xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "  # Usar TimeSeriesSplit para cross-validation\n",
        "  n_splits = 5  # Puedes ajustar el número de splits\n",
        "  tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "  # Definir scorer para maximizar Precision de la Clase 1\n",
        "  precision_scorer = make_scorer(precision_score, pos_label=1, zero_division=0) # zero_division=0 para manejar casos sin predicciones positivas\n",
        "\n",
        "  # Clean X_train_full and y_train_full before fitting RandomizedSearchCV\n",
        "  X_train_full_cleaned_for_tuning = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "  X_train_full_cleaned_for_tuning.dropna(inplace=True)\n",
        "  y_train_full_cleaned_for_tuning = y_train_full.loc[X_train_full_cleaned_for_tuning.index] # Ensure y matches cleaned X\n",
        "\n",
        "  # Explicit check, conversion, and fallback for non-finite values before fitting RandomizedSearchCV\n",
        "  X_train_full_cleaned_for_tuning = X_train_full_cleaned_for_tuning.astype(np.float64) # Ensure dtype\n",
        "  if not np.isfinite(X_train_full_cleaned_for_tuning).all().all():\n",
        "      print(f\"\\nWarning: Non-finite values detected in X_train_full_cleaned_for_tuning for {symbol} before RandomizedSearchCV fit. Attempting to fill with median.\")\n",
        "      for col in X_train_full_cleaned_for_tuning.columns:\n",
        "          finite_values = X_train_full_cleaned_for_tuning[col][np.isfinite(X_train_full_cleaned_for_tuning[col])]\n",
        "          if not finite_values.empty:\n",
        "              median_val = finite_values.median()\n",
        "              X_train_full_cleaned_for_tuning[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "              X_train_full_cleaned_for_tuning[col].fillna(median_val, inplace=True)\n",
        "          else:\n",
        "              print(f\"Warning: Column '{col}' in X_train_full_cleaned_for_tuning is all non-finite. Filling with 0.\")\n",
        "              X_train_full_cleaned_for_tuning[col].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "  # Perform tuning, evaluation, and prediction within a general try-except block\n",
        "  # to prevent script crash on problematic tickers\n",
        "  if not X_train_full_cleaned_for_tuning.empty and not y_train_full_cleaned_for_tuning.empty and len(y_train_full_cleaned_for_tuning.unique()) > 1:\n",
        "      try:\n",
        "          random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=20, cv=tscv, scoring=precision_scorer, n_jobs=-1, random_state=42) # Usar precision_scorer\n",
        "          random_search.fit(X_train_full_cleaned_for_tuning, y_train_full_cleaned_for_tuning)\n",
        "          print(f\"Mejores hiperparámetros para {symbol}:\", random_search.best_params_)\n",
        "\n",
        "          # Usar el mejor modelo encontrado por RandomizedSearchCV\n",
        "          best_model = random_search.best_estimator_\n",
        "\n",
        "          # Get and print feature importance\n",
        "          feature_importance = pd.Series(best_model.feature_importances_, index=features)\n",
        "          print(f\"\\nFeature Importance for {symbol}:\")\n",
        "          print(feature_importance.sort_values(ascending=False))\n",
        "\n",
        "          # Optimize the threshold for maximum Precision (Clase 1) on the full training set\n",
        "          X_train_full_cleaned_for_threshold = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "          X_train_full_cleaned_for_threshold.dropna(inplace=True)\n",
        "          y_train_full_cleaned_for_threshold = y_train_full.loc[X_train_full_cleaned_for_threshold.index]\n",
        "\n",
        "          if not X_train_full_cleaned_for_threshold.empty and not y_train_full_cleaned_for_threshold.empty and len(y_train_full_cleaned_for_threshold.unique()) > 1:\n",
        "              y_train_prob = best_model.predict_proba(X_train_full_cleaned_for_threshold)[:, 1]\n",
        "              thresholds = np.arange(0.01, 1.0, 0.01)\n",
        "              best_threshold = 0.5\n",
        "              best_precision = 0\n",
        "\n",
        "              print(f\"Optimizing threshold for maximum Precision (Clase 1) on training data for {symbol}...\")\n",
        "              if 1 in y_train_full_cleaned_for_threshold.unique():\n",
        "                  for threshold in thresholds:\n",
        "                      y_pred_threshold = (y_train_prob >= threshold).astype(int)\n",
        "                      if np.sum(y_pred_threshold) > 0:\n",
        "                           precision = precision_score(y_train_full_cleaned_for_threshold, y_pred_threshold, pos_label=1, zero_division=0)\n",
        "                           if precision > best_precision:\n",
        "                               best_precision = precision\n",
        "                               best_threshold = threshold\n",
        "                  print(f\"Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para {symbol}: {best_threshold:.4f} (Precision: {best_precision:.4f})\")\n",
        "              else:\n",
        "                  print(f\"\\nWarning: Training set for {symbol} contains no positive samples after cleaning for threshold optimization. Cannot optimize threshold for Precision (Clase 1). Using default threshold 0.5.\")\n",
        "                  best_threshold = 0.5\n",
        "          else:\n",
        "              print(f\"\\nWarning: Training data for threshold optimization is insufficient for {symbol}. Using default threshold 0.5.\")\n",
        "              best_threshold = 0.5\n",
        "\n",
        "\n",
        "          # Evaluar el modelo en el conjunto de prueba con el best threshold\n",
        "          if not X_test.empty and not y_test.empty and len(y_test.unique()) > 1:\n",
        "              print(f\"\\nEvaluating best model on test set for {symbol} with best threshold ({best_threshold:.4f}):\")\n",
        "\n",
        "              X_test_cleaned = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "              y_test_cleaned = y_test.loc[X_test_cleaned.index]\n",
        "\n",
        "              scaler = RobustScaler()\n",
        "              X_train_full_cleaned_for_scaler_eval = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "              X_train_full_cleaned_for_scaler_eval.dropna(inplace=True)\n",
        "              X_train_full_cleaned_for_scaler_eval = X_train_full_cleaned_for_scaler_eval.clip(lower=lower_bound, upper=upper_bound)\n",
        "              X_train_full_cleaned_for_scaler_eval = X_train_full_cleaned_for_scaler_eval.astype(np.float64)\n",
        "\n",
        "              if not np.isfinite(X_train_full_cleaned_for_scaler_eval).all().all():\n",
        "                  print(f\"\\nWarning: Non-finite values detected in X_train_full_cleaned_for_scaler_eval for {symbol} before scaler fit. Attempting to fill with median.\")\n",
        "                  for col in X_train_full_cleaned_for_scaler_eval.columns:\n",
        "                      finite_values = X_train_full_cleaned_for_scaler_eval[col][np.isfinite(X_train_full_cleaned_for_scaler_eval[col])]\n",
        "                      if not finite_values.empty:\n",
        "                          median_val = finite_values.median()\n",
        "                          X_train_full_cleaned_for_scaler_eval[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                          X_train_full_cleaned_for_scaler_eval[col].fillna(median_val, inplace=True)\n",
        "                      else:\n",
        "                          print(f\"Warning: Column '{col}' in X_train_full_cleaned_for_scaler_eval is all non-finite. Filling with 0.\")\n",
        "                          X_train_full_cleaned_for_scaler_eval[col].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "              if not X_train_full_cleaned_for_scaler_eval.empty and np.isfinite(X_train_full_cleaned_for_scaler_eval).all().all():\n",
        "                  scaler.fit(X_train_full_cleaned_for_scaler_eval)\n",
        "\n",
        "                  X_test_cleaned = X_test_cleaned.astype(np.float64)\n",
        "                  if not np.isfinite(X_test_cleaned).all().all():\n",
        "                       print(f\"\\nWarning: Non-finite values detected in X_test_cleaned for {symbol} before scaler transform. Attempting to fill with median (from train data).\")\n",
        "                       train_medians = X_train_full_cleaned_for_scaler_eval.median()\n",
        "                       for col in X_test_cleaned.columns:\n",
        "                           median_val = train_medians.get(col, 0)\n",
        "                           X_test_cleaned[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                           X_test_cleaned[col].fillna(median_val, inplace=True)\n",
        "                       if not np.isfinite(X_test_cleaned).all().all():\n",
        "                            print(f\"\\nERROR: Non-finite values STILL detected in X_test_cleaned for {symbol} after filling with median!\")\n",
        "\n",
        "\n",
        "                  if not X_test_cleaned.empty and np.isfinite(X_test_cleaned).all().all():\n",
        "                      X_test_scaled = scaler.transform(X_test_cleaned)\n",
        "\n",
        "                      y_test_pred_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "                      y_test_pred = (y_test_pred_prob >= best_threshold).astype(int)\n",
        "\n",
        "                      if len(y_test_cleaned.unique()) > 1:\n",
        "                          print(\"\\nClassification Report (Test Set):\")\n",
        "                          print(classification_report(y_test_cleaned, y_test_pred, zero_division=0))\n",
        "                          precision_test_alcista = precision_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "                          recall_test_alcista = recall_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "                          f1_test_alcista = f1_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "                          print(f\"Tamaño de y_test (cleaned): {y_test_cleaned.size}\")\n",
        "                          print(f\"Distribución de clases en y_test (cleaned) para {symbol}:\")\n",
        "                          print(y_test_cleaned.value_counts())\n",
        "                          if 1 in y_test_cleaned.value_counts():\n",
        "                              ratio_1_test=(y_test_cleaned.value_counts()[1]/y_test_cleaned.size).round(4)\n",
        "                          else:\n",
        "                              ratio_1_test = 0\n",
        "                          print(f\"% clase 1 test para {symbol}: {ratio_1_test} \")\n",
        "\n",
        "                          if len(y_test_cleaned.unique()) > 1:\n",
        "                               roc_auc_test = roc_auc_score(y_test_cleaned, y_test_pred_prob).round(6)\n",
        "                               print(f\"\\nROC-AUC (Test Set) para {symbol}: {roc_auc_test:.4f}\")\n",
        "                          else:\n",
        "                               roc_auc_test = None\n",
        "                               print(f\"\\nWarning: Test set for {symbol} contains only one class after cleaning. Cannot calculate ROC-AUC.\")\n",
        "\n",
        "                      else:\n",
        "                          print(f\"\\nWarning: Test set for {symbol} contains only one class after cleaning. Cannot generate full classification report.\")\n",
        "                          precision_test_alcista = None\n",
        "                          recall_test_alcista = None\n",
        "                          f1_test_alcista = None\n",
        "                          roc_auc_test = None\n",
        "                          ratio_1_test = None\n",
        "\n",
        "\n",
        "                  else:\n",
        "                      print(f\"\\nWarning: X_test became empty after cleaning or contains non-finite values for {symbol}. Skipping test evaluation.\")\n",
        "                      precision_test_alcista = None\n",
        "                      recall_test_alcista = None\n",
        "                      f1_test_alcista = None\n",
        "                      roc_auc_test = None\n",
        "                      ratio_1_test = None\n",
        "\n",
        "\n",
        "              else:\n",
        "                  print(f\"\\nWarning: Training data (X_train_full) became empty or contains non-finite values after cleaning for scaler fitting for evaluation for {symbol}. Skipping test evaluation.\")\n",
        "                  precision_test_alcista = None\n",
        "                  recall_test_alcista = None\n",
        "                  f1_test_alcista = None\n",
        "                  roc_auc_test = None\n",
        "                  ratio_1_test = None\n",
        "\n",
        "\n",
        "          else:\n",
        "              print(f\"\\nAdvertencia: Conjunto de prueba insuficiente o con una sola clase para evaluación para {symbol}.\")\n",
        "              precision_test_alcista = None\n",
        "              recall_test_alcista = None\n",
        "              f1_test_alcista = None\n",
        "              roc_auc_test = None\n",
        "              ratio_1_test = None\n",
        "\n",
        "          # Prediction for the next day is done only if model was trained successfully\n",
        "          last_features = df[features].iloc[-1:]\n",
        "          last_features_cleaned = None\n",
        "          last_features_scaled = None\n",
        "          future_pred_prob = None\n",
        "          future_pred = None\n",
        "\n",
        "          if not last_features.empty:\n",
        "              # Ensure last_features is a single row DataFrame before cleaning\n",
        "              if not isinstance(last_features, pd.DataFrame) or len(last_features) != 1:\n",
        "                   print(f\"\\nError: last_features is not a single row DataFrame for {symbol}. Skipping prediction.\")\n",
        "                   # Set prediction results to skipped\n",
        "                   last_data_date = df.index[-1] if not df.empty else None\n",
        "                   last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                   resultsp.append({\n",
        "                       'Papel': symbol,\n",
        "                       'Fecha Predicción': next_day,\n",
        "                       'Fecha Datos': last_data_date,\n",
        "                       'Predicción': 'Skipped (Prediction Data Error)',\n",
        "                       'Precio actual': last_close,\n",
        "                       'Probabilidad Alcista (Modelo)': None,\n",
        "                       'Umbral de Clasificación': None,\n",
        "                       'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Prediction Data Error)',\n",
        "                       'Precision Test (Alcista)': precision_test_alcista,\n",
        "                       'Recall Test (Alcista)': recall_test_alcista,\n",
        "                       'F1 Test (Alcista)': f1_test_alcista,\n",
        "                       'ROC-AUC Test': roc_auc_test,\n",
        "                       'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                       'Features Limpias (Predicción)': None,\n",
        "                       'Features Escaladas (Predicción)': None\n",
        "                   })\n",
        "                   # No need to continue here, the append is done and we move to the next ticker\n",
        "                   continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "              last_features_cleaned = last_features.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "              last_features_cleaned = last_features_cleaned.clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "              # Add checks for NaN, Inf, and Zero in cleaned features BEFORE scaling\n",
        "              has_nan_cleaned = last_features_cleaned.isna().any().any()\n",
        "              has_inf_cleaned = np.isinf(last_features_cleaned).any().any()\n",
        "              has_zero_cleaned = (last_features_cleaned == 0).any().any()\n",
        "\n",
        "              if has_nan_cleaned:\n",
        "                  print(f\"\\nDEBUG: NaN values detected in last_features_cleaned for {symbol}.\")\n",
        "              if has_inf_cleaned:\n",
        "                  print(f\"\\nDEBUG: Inf values detected in last_features_cleaned for {symbol}.\")\n",
        "              if has_zero_cleaned:\n",
        "                   print(f\"\\nDEBUG: Zero values detected in last_features_cleaned for {symbol}.\")\n",
        "\n",
        "\n",
        "              if not last_features_cleaned.empty and np.isfinite(last_features_cleaned).all().all():\n",
        "                  # Ensure scaler is fitted on the *cleaned* full training data\n",
        "                  scaler = RobustScaler()\n",
        "                  X_train_full_cleaned_for_scaler_pred = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "                  X_train_full_cleaned_for_scaler_pred.dropna(inplace=True)\n",
        "                  X_train_full_cleaned_for_scaler_pred = X_train_full_cleaned_for_scaler_pred.clip(lower=lower_bound, upper=upper_bound)\n",
        "                  X_train_full_cleaned_for_scaler_pred = X_train_full_cleaned_for_scaler_pred.astype(np.float64)\n",
        "\n",
        "                  if not np.isfinite(X_train_full_cleaned_for_scaler_pred).all().all():\n",
        "                       print(f\"\\nWarning: Non-finite values detected in X_train_full_cleaned_for_scaler_pred for {symbol} before scaler fit. Attempting to fill with median.\")\n",
        "                       for col in X_train_full_cleaned_for_scaler_pred.columns:\n",
        "                           finite_values = X_train_full_cleaned_for_scaler_pred[col][np.isfinite(X_train_full_cleaned_for_scaler_pred[col])]\n",
        "                           if not finite_values.empty:\n",
        "                               median_val = finite_values.median()\n",
        "                               X_train_full_cleaned_for_scaler_pred[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                               X_train_full_cleaned_for_scaler_pred[col].fillna(median_val, inplace=True)\n",
        "                           else:\n",
        "                               print(f\"Warning: Column '{col}' in X_train_full_cleaned_for_scaler_pred is all non-finite. Filling with 0.\")\n",
        "                               X_train_full_cleaned_for_scaler_pred[col].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "                  if not X_train_full_cleaned_for_scaler_pred.empty and np.isfinite(X_train_full_cleaned_for_scaler_pred).all().all():\n",
        "                       scaler.fit(X_train_full_cleaned_for_scaler_pred)\n",
        "\n",
        "                       last_features_cleaned = last_features_cleaned.astype(np.float64)\n",
        "                       # Add explicit fallback for non-finite values AFTER dropna for prediction data\n",
        "                       # This fallback is actually redundant if dropna() was called just above and np.isfinite checked,\n",
        "                       # but keeping it for safety if flow changes. The main checks should be BEFORE scaling.\n",
        "                       # Let's keep the checks BEFORE scaling.\n",
        "                       # if not np.isfinite(last_features_cleaned).all().all():\n",
        "                       #      print(f\"\\nWarning: Non-finite values STILL detected in last_features_cleaned for {symbol} AFTER dropna. Attempting to fill with median (from train data).\")\n",
        "                       #      train_medians = X_train_full_cleaned_for_scaler_pred.median()\n",
        "                       #      for col in last_features_cleaned.columns:\n",
        "                       #          median_val = train_medians.get(col, 0)\n",
        "                       #          last_features_cleaned[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                       #          last_features_cleaned[col].fillna(median_val, inplace=True)\n",
        "                       #      if not np.isfinite(last_features_cleaned).all().all():\n",
        "                       #           print(f\"\\nERROR: Non-finite values STILL detected in last_features_cleaned for {symbol} after filling with median!\")\n",
        "\n",
        "\n",
        "                       if not last_features_cleaned.empty and np.isfinite(last_features_cleaned).all().all():\n",
        "                           last_features_scaled = scaler.transform(last_features_cleaned)\n",
        "\n",
        "                           # Add checks for NaN, Inf, and Zero in scaled features BEFORE prediction\n",
        "                           has_nan_scaled = np.isnan(last_features_scaled).any()\n",
        "                           has_inf_scaled = np.isinf(last_features_scaled).any()\n",
        "                           has_zero_scaled = (last_features_scaled == 0).any()\n",
        "\n",
        "                           if has_nan_scaled:\n",
        "                               print(f\"\\nDEBUG: NaN values detected in last_features_scaled for {symbol} BEFORE prediction.\")\n",
        "                           if has_inf_scaled:\n",
        "                               print(f\"\\nDEBUG: Inf values detected in last_features_scaled for {symbol} BEFORE prediction.\")\n",
        "                           if has_zero_scaled:\n",
        "                                print(f\"\\nDEBUG: Zero values detected in last_features_scaled for {symbol} BEFORE prediction.\")\n",
        "\n",
        "\n",
        "                           future_pred_prob = best_model.predict_proba(last_features_scaled)[:, 1][0].round(4)\n",
        "                           future_pred = 1 if future_pred_prob >= best_threshold else 0\n",
        "\n",
        "                           last_close = None\n",
        "                           last_open = None\n",
        "                           last_max = None\n",
        "                           if not df.empty:\n",
        "                               last_close = df['Close'].iloc[-1]\n",
        "                               last_open = df['Open'].iloc[-1]\n",
        "                               last_max = df['High'].iloc[-1]\n",
        "                               last_data_date = df.index[-1]\n",
        "                           else:\n",
        "                               print(f\"Warning: DataFrame 'df' is empty for {symbol}. Cannot get last prices.\")\n",
        "                               last_data_date = None\n",
        "\n",
        "                           action = 'BUY' if future_pred == 1 else 'SELL'\n",
        "                           direction = 1 if future_pred == 1 else -1\n",
        "\n",
        "                           # Explicitly use to_dict() and tolist()\n",
        "                           cleaned_features_dict = last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None\n",
        "                           scaled_features_list = last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "\n",
        "\n",
        "                           resultsp.append({\n",
        "                                       'Papel': symbol,\n",
        "                                       'Fecha Predicción': next_day,\n",
        "                                       'Fecha Datos': last_data_date,\n",
        "                                       'Predicción': 'Alcista' if future_pred == 1 else 'Bajista',\n",
        "                                       'Probabilidad Alcista (Modelo)': future_pred_prob,\n",
        "                                       'Umbral de Clasificación': best_threshold.round(4),\n",
        "                                       'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)', # Add check for best_model\n",
        "                                       'Precision Test (Alcista)': precision_test_alcista,\n",
        "                                       'Recall Test (Alcista)': recall_test_alcista,\n",
        "                                       'F1 Test (Alcista)': f1_test_alcista,\n",
        "                                       'ROC-AUC Test': roc_auc_test,\n",
        "                                       'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                                       'Features Limpias (Predicción)': cleaned_features_dict, # Add cleaned features using to_dict\n",
        "                                       'Features Escaladas (Predicción)': scaled_features_list # Add scaled features as a list\n",
        "                               })\n",
        "                       else:\n",
        "                            print(f\"\\nWarning: last_features became empty or contains non-finite values after final filling for scaler transform. Skipping prediction for {symbol}.\")\n",
        "                            last_data_date = df.index[-1] if not df.empty else None\n",
        "                            last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                            # Explicitly use None for feature columns if prediction skipped due to data issues\n",
        "                            resultsp.append({\n",
        "                                'Papel': symbol,\n",
        "                                'Fecha Predicción': next_day,\n",
        "                                'Fecha Datos': last_data_date,\n",
        "                                'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                                'Precio actual': last_close,\n",
        "                                'Probabilidad Alcista (Modelo)': None,\n",
        "                                'Umbral de Clasificación': None,\n",
        "                                'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                                'Precision Test (Alcista)': precision_test_alcista,\n",
        "                                'Recall Test (Alcista)': recall_test_alcista,\n",
        "                                'F1 Test (Alcista)': f1_test_alcista,\n",
        "                                'ROC-AUC Test': roc_auc_test,\n",
        "                                'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                                 'Features Limpias (Predicción)': None,\n",
        "                                 'Features Escaladas (Predicción)': None\n",
        "                            })\n",
        "\n",
        "\n",
        "                  else:\n",
        "                       print(f\"\\nWarning: Training data (X_train_full) became empty or contains non-finite values after final filling for scaler fitting for prediction. Skipping prediction for {symbol}.\")\n",
        "                       last_data_date = df.index[-1] if not df.empty else None\n",
        "                       last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                       # Explicitly use None for feature columns if prediction skipped due to data issues\n",
        "                       resultsp.append({\n",
        "                           'Papel': symbol,\n",
        "                           'Fecha Predicción': next_day,\n",
        "                           'Fecha Datos': last_data_date,\n",
        "                           'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                           'Precio actual': last_close,\n",
        "                           'Probabilidad Alcista (Modelo)': None,\n",
        "                           'Umbral de Clasificación': None,\n",
        "                           'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                           'Precision Test (Alcista)': precision_test_alcista,\n",
        "                           'Recall Test (Alcista)': recall_test_alcista,\n",
        "                           'F1 Test (Alcista)': f1_test_alcista,\n",
        "                           'ROC-AUC Test': roc_auc_test,\n",
        "                           'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                            'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                            'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                       })\n",
        "\n",
        "\n",
        "              else:\n",
        "                  print(f\"\\nWarning: Could not make prediction for {symbol} as last_features became empty or contains non-finite values after cleaning.\")\n",
        "                  last_data_date = df.index[-1] if not df.empty else None\n",
        "                  last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                  # Explicitly use None for feature columns if prediction skipped due to data issues\n",
        "                  resultsp.append({\n",
        "                      'Papel': symbol,\n",
        "                      'Fecha Predicción': next_day,\n",
        "                      'Fecha Datos': last_data_date,\n",
        "                      'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                      'Precio actual': last_close,\n",
        "                      'Probabilidad Alcista (Modelo)': None,\n",
        "                      'Umbral de Clasificación': None,\n",
        "                      'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                      'Precision Test (Alcista)': precision_test_alcista,\n",
        "                      'Recall Test (Alcista)': recall_test_alcista,\n",
        "                      'F1 Test (Alcista)': f1_test_alcista,\n",
        "                      'ROC-AUC Test': roc_auc_test,\n",
        "                      'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                       'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                       'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                  })\n",
        "\n",
        "\n",
        "          else:\n",
        "              print(f\"\\nWarning: Could not make prediction for {symbol} as last_features was initially empty.\")\n",
        "              last_data_date = df.index[-1] if not df.empty else None\n",
        "              last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "              # Explicitly use None for feature columns if prediction skipped due to data issues\n",
        "              resultsp.append({\n",
        "                  'Papel': symbol,\n",
        "                  'Fecha Predicción': next_day,\n",
        "                  'Fecha Datos': last_data_date,\n",
        "                  'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                  'Precio actual': last_close,\n",
        "                  'Probabilidad Alcista (Modelo)': None,\n",
        "                  'Umbral de Clasificación': None,\n",
        "                  'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                  'Precision Test (Alcista)': precision_test_alcista,\n",
        "                  'Recall Test (Alcista)': recall_test_alcista,\n",
        "                  'F1 Test (Alcista)': f1_test_alcista,\n",
        "                  'ROC-AUC Test': roc_auc_test,\n",
        "                  'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                   'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                   'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "              })\n",
        "\n",
        "\n",
        "      # Catch a general Exception during tuning/evaluation/prediction to prevent script crash\n",
        "      except Exception as e:\n",
        "          print(f\"\\nERROR: An error occurred during tuning, evaluation, or prediction for {symbol}: {e}. Skipping this ticker.\")\n",
        "          best_model = None\n",
        "          best_threshold = 0.5\n",
        "          precision_test_alcista = None\n",
        "          recall_test_alcista = None\n",
        "          f1_test_alcista = None\n",
        "          roc_auc_test = None\n",
        "          ratio_1_test = None\n",
        "\n",
        "          last_data_date = df.index[-1] if not df.empty else None\n",
        "          last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "          # Append entry indicating skip due to general error, explicitly add None for feature columns\n",
        "          resultsp.append({\n",
        "                'Papel': symbol,\n",
        "                'Fecha Predicción': next_day,\n",
        "                'Fecha Datos': last_data_date,\n",
        "                'Predicción': 'Skipped (Error)',\n",
        "                'Precio actual': last_close,\n",
        "                'Probabilidad Alcista (Modelo)': None,\n",
        "                'Umbral de Clasificación': None,\n",
        "                'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Error)',\n",
        "                'Precision Test (Alcista)': precision_test_alcista,\n",
        "                'Recall Test (Alcista)': recall_test_alcista,\n",
        "                'F1 Test (Alcista)': f1_test_alcista,\n",
        "                'ROC-AUC Test': roc_auc_test,\n",
        "                'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                'Features Limpias (Predicción)': None,\n",
        "                'Features Escaladas (Predicción)': None\n",
        "          })\n",
        "\n",
        "\n",
        "  else:\n",
        "      print(f\"\\nWarning: Training data (X_train_full or y_train_full) is empty or has only one class after cleaning for tuning for {symbol}. Skipping model training and prediction.\")\n",
        "      # Append a result entry indicating skip due to insufficient training data, explicitly add None for feature columns\n",
        "      last_data_date = df.index[-1] if not df.empty else None\n",
        "      last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "      resultsp.append({\n",
        "            'Papel': symbol,\n",
        "            'Fecha Predicción': next_day,\n",
        "            'Fecha Datos': last_data_date,\n",
        "            'Predicción': 'Skipped (Insufficient Training Data)',\n",
        "            'Precio actual': last_close,\n",
        "            'Probabilidad Alcista (Modelo)': None,\n",
        "            'Umbral de Clasificación': None,\n",
        "            'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Insufficient Training Data)',\n",
        "            'Precision Test (Alcista)': precision_test_alcista,\n",
        "            'Recall Test (Alcista)': recall_test_alcista,\n",
        "            'F1 Test (Alcista)': f1_test_alcista,\n",
        "            'ROC-AUC Test': roc_auc_test,\n",
        "            'clase 1 en test (cleaned)': ratio_1_test,\n",
        "            'Features Limpias (Predicción)': None,\n",
        "            'Features Escaladas (Predicción)': None\n",
        "      })\n",
        "\n",
        "\n",
        "# Crear tabla de resultados de predicción\n",
        "resultsp_df = pd.DataFrame(resultsp)\n",
        "print(resultsp_df)\n",
        "if not resultsp_df.empty:\n",
        "    resultsp_df.set_index('Fecha Predicción', inplace=True)\n",
        "\n",
        "    # Mostrar resultados de predicción\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    #pd.set_option('display.max_rows', None) # Optional: display all rows\n",
        "    pd.set_option('display.max_colwidth', None) # Optional: display full content of columns\n",
        "\n",
        "    print(\"\\nPrediccion para el proximo dia (hasta\", next_day.strftime('%Y-%m-%d'), \"):\")\n",
        "    print(\"Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\")\n",
        "    display(resultsp_df) # Use display for better formatting\n",
        "\n",
        "    # Guardar y descargar el CSV de predicciones\n",
        "    resultsp_df.to_csv(f\"Predic_results_{end_date.strftime('%Y-%m-%d')}.csv\", sep=\";\")\n",
        "    files.download(f\"Predic_results_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "    print(f\"\\nArchivo 'Predic_results_{end_date.strftime('%Y-%m-%d')}.csv' generado y descargado.\")\n",
        "else:\n",
        "    print(\"\\nNo hay resultados de predicción para mostrar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8lhyC8K6_53G",
        "outputId": "28286917-095a-4f72-ed29-b92100a9a673"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading data for ALUA.BA...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiIndex columns detected for ALUA.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for ALUA.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "             Open   High    Low  Close   Volume  Adj Close\n",
            "Date                                                      \n",
            "2025-09-08  670.0  705.0  600.0  696.5  1572445      696.5\n",
            "2025-09-09  700.0  713.0  678.5  694.0  1217950      694.0\n",
            "2025-09-10  700.0  716.5  691.5  702.0   641358      702.0\n",
            "2025-09-11  702.0  713.0  676.0  682.0  1443135      682.0\n",
            "2025-09-12  686.0  702.0  660.0  666.0   420245      666.0\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "             Open   High    Low  Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                      \n",
            "2025-09-04  710.0  717.0  685.0  696.0   949242      696.0        700.0   \n",
            "2025-09-05  680.0  696.0  664.0  686.0  2029661      686.0        696.0   \n",
            "2025-09-08  670.0  705.0  600.0  696.5  1572445      696.5        686.0   \n",
            "2025-09-09  700.0  713.0  678.5  694.0  1217950      694.0        696.5   \n",
            "2025-09-10  700.0  716.5  691.5  702.0   641358      702.0        694.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04        738.0        749.0        723.0        697.0       735.0   \n",
            "2025-09-05        700.0        738.0        749.0        723.0       710.0   \n",
            "2025-09-08        696.0        700.0        738.0        749.0       680.0   \n",
            "2025-09-09        686.0        696.0        700.0        738.0       670.0   \n",
            "2025-09-10        696.5        686.0        696.0        700.0       700.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04       751.0       710.0       700.0       737.0       742.0   \n",
            "2025-09-05       735.0       751.0       710.0       700.0       717.0   \n",
            "2025-09-08       710.0       735.0       751.0       710.0       696.0   \n",
            "2025-09-09       680.0       710.0       735.0       751.0       705.0   \n",
            "2025-09-10       670.0       680.0       710.0       735.0       713.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04       754.0       752.0       727.0       744.0   -0.005714   \n",
            "2025-09-05       742.0       754.0       752.0       727.0   -0.014368   \n",
            "2025-09-08       717.0       742.0       754.0       752.0    0.015306   \n",
            "2025-09-09       696.0       717.0       742.0       754.0   -0.003589   \n",
            "2025-09-10       705.0       696.0       717.0       742.0    0.011527   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.051491    -0.014686     0.035961     0.037303    -0.054274   \n",
            "2025-09-05    -0.005714    -0.051491    -0.014686     0.035961     0.037303   \n",
            "2025-09-08    -0.014368    -0.005714    -0.051491    -0.014686     0.035961   \n",
            "2025-09-09     0.015306    -0.014368    -0.005714    -0.051491    -0.014686   \n",
            "2025-09-10    -0.003589     0.015306    -0.014368    -0.005714    -0.051491   \n",
            "\n",
            "                  RSI       ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                   \n",
            "2025-09-04  40.764331 -0.143472 -0.267917    0.217375      -0.485293   \n",
            "2025-09-05  33.548387 -5.117566 -0.705336   -0.090195      -0.615141   \n",
            "2025-09-08  49.800797 -7.009346 -0.695150   -0.291847      -0.403303   \n",
            "2025-09-09  35.784314 -5.962060 -0.691674   -0.425122      -0.266552   \n",
            "2025-09-10  22.023810  0.285714 -0.491059   -0.447101      -0.043958   \n",
            "\n",
            "                 EWO  EWO_Signal  EWO_Histogram   SMA5     SMA13     SMA26  \\\n",
            "Date                                                                         \n",
            "2025-09-04 -0.277641    0.440168      -0.717810  721.2  708.3846  720.7308   \n",
            "2025-09-05 -1.276330   -0.131998      -1.144332  713.8  708.6154  718.2692   \n",
            "2025-09-08 -1.473545   -0.579180      -0.894365  703.3  709.9615  714.7885   \n",
            "2025-09-09 -1.669313   -0.942558      -0.726756  694.5  711.1923  711.7115   \n",
            "2025-09-10 -1.448619   -1.111245      -0.337374  694.9  711.9615  710.0577   \n",
            "\n",
            "             SMA50    SMA200  Volatility  Max_Gain_from_Open_Current  \\\n",
            "Date                                                                   \n",
            "2025-09-04  713.70  787.4300   20.275147                    0.009859   \n",
            "2025-09-05  714.30  786.6500   20.709520                    0.048529   \n",
            "2025-09-08  714.43  786.1225   20.323874                    0.069403   \n",
            "2025-09-09  714.19  785.5375   20.500497                    0.023571   \n",
            "2025-09-10  713.85  784.9925   20.122830                    0.023571   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_1  Max_Gain_from_Open_Lag_2  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.009524                  0.003995   \n",
            "2025-09-05                  0.009859                  0.009524   \n",
            "2025-09-08                  0.048529                  0.009859   \n",
            "2025-09-09                  0.069403                  0.048529   \n",
            "2025-09-10                  0.023571                  0.069403   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_3  Max_Gain_from_Open_Lag_4  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.061972                  0.077143   \n",
            "2025-09-05                  0.003995                  0.061972   \n",
            "2025-09-08                  0.009524                  0.003995   \n",
            "2025-09-09                  0.009859                  0.009524   \n",
            "2025-09-10                  0.048529                  0.009859   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_5  Max_Gain_from_Open_Lag_6  Label_raw  \\\n",
            "Date                                                                        \n",
            "2025-09-04                  0.020353                  0.027586          1   \n",
            "2025-09-05                  0.077143                  0.020353          1   \n",
            "2025-09-08                  0.061972                  0.077143          1   \n",
            "2025-09-09                  0.003995                  0.061972          1   \n",
            "2025-09-10                  0.009524                  0.003995          1   \n",
            "\n",
            "            Label  \n",
            "Date               \n",
            "2025-09-04    1.0  \n",
            "2025-09-05    1.0  \n",
            "2025-09-08    1.0  \n",
            "2025-09-09    1.0  \n",
            "2025-09-10    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "Distribucion de etiquetas para ALUA.BA:\n",
            "Label\n",
            "1.0    0.588778\n",
            "0.0    0.411222\n",
            "Name: proportion, dtype: float64\n",
            "Correlacion con label para ALUA.BA:\n",
            "Label                         1.000000\n",
            "Max_Gain_from_Open_Current    0.176044\n",
            "Volatility                    0.137457\n",
            "high_lag_1                    0.133648\n",
            "high_lag_2                    0.133553\n",
            "open_lag_1                    0.133132\n",
            "close_lag_2                   0.133121\n",
            "open_lag_2                    0.133050\n",
            "close_lag_1                   0.132892\n",
            "close_lag_3                   0.132868\n",
            "high_lag_3                    0.132730\n",
            "high_lag_4                    0.132608\n",
            "high_lag_5                    0.132543\n",
            "SMA5                          0.132482\n",
            "open_lag_4                    0.132300\n",
            "SMA13                         0.132219\n",
            "close_lag_5                   0.132119\n",
            "open_lag_3                    0.132067\n",
            "open_lag_5                    0.131868\n",
            "close_lag_4                   0.131611\n",
            "Max_Gain_from_Open_Lag_3      0.131285\n",
            "SMA26                         0.131199\n",
            "SMA50                         0.128918\n",
            "Max_Gain_from_Open_Lag_5      0.122891\n",
            "Max_Gain_from_Open_Lag_6      0.120744\n",
            "Max_Gain_from_Open_Lag_1      0.117974\n",
            "Max_Gain_from_Open_Lag_4      0.116613\n",
            "SMA200                        0.112518\n",
            "Max_Gain_from_Open_Lag_2      0.105624\n",
            "EWO_Signal                    0.039022\n",
            "EWO                           0.035932\n",
            "lag_change3                   0.030163\n",
            "PPO_Signal                    0.021733\n",
            "lag_change5                   0.016503\n",
            "PPO                           0.013751\n",
            "ROC                           0.007542\n",
            "lag_change2                   0.007511\n",
            "RSI                           0.004974\n",
            "lag_change1                  -0.001266\n",
            "lag_change4                  -0.003333\n",
            "EWO_Histogram                -0.007945\n",
            "PPO_Histogram                -0.016057\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para ALUA.BA\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros para ALUA.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for ALUA.BA:\n",
            "Volatility                    0.041578\n",
            "open_lag_2                    0.039338\n",
            "close_lag_4                   0.035814\n",
            "high_lag_4                    0.032640\n",
            "Max_Gain_from_Open_Current    0.032418\n",
            "open_lag_4                    0.031670\n",
            "high_lag_1                    0.028877\n",
            "close_lag_2                   0.027192\n",
            "EWO_Signal                    0.025644\n",
            "SMA13                         0.025469\n",
            "close_lag_3                   0.025339\n",
            "high_lag_5                    0.025300\n",
            "SMA50                         0.024932\n",
            "open_lag_5                    0.024742\n",
            "SMA26                         0.024704\n",
            "high_lag_3                    0.024433\n",
            "open_lag_3                    0.024176\n",
            "close_lag_1                   0.023360\n",
            "close_lag_5                   0.023272\n",
            "open_lag_1                    0.023239\n",
            "PPO_Histogram                 0.023059\n",
            "ROC                           0.022421\n",
            "lag_change4                   0.022061\n",
            "EWO                           0.021837\n",
            "Max_Gain_from_Open_Lag_3      0.021553\n",
            "Max_Gain_from_Open_Lag_5      0.021490\n",
            "SMA200                        0.021379\n",
            "SMA5                          0.021297\n",
            "Max_Gain_from_Open_Lag_2      0.021191\n",
            "EWO_Histogram                 0.021034\n",
            "high_lag_2                    0.020980\n",
            "lag_change3                   0.020810\n",
            "Max_Gain_from_Open_Lag_6      0.020792\n",
            "lag_change1                   0.020269\n",
            "PPO_Signal                    0.020116\n",
            "PPO                           0.019981\n",
            "Max_Gain_from_Open_Lag_1      0.019608\n",
            "lag_change5                   0.019569\n",
            "RSI                           0.019568\n",
            "Max_Gain_from_Open_Lag_4      0.018509\n",
            "lag_change2                   0.018339\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum Precision (Clase 1) on training data for ALUA.BA...\n",
            "Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para ALUA.BA: 0.5300 (Precision: 1.0000)\n",
            "\n",
            "Evaluating best model on test set for ALUA.BA with best threshold (0.5300):\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.34      0.11      0.16       120\n",
            "         1.0       0.78      0.94      0.85       398\n",
            "\n",
            "    accuracy                           0.75       518\n",
            "   macro avg       0.56      0.52      0.51       518\n",
            "weighted avg       0.68      0.75      0.69       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para ALUA.BA:\n",
            "Label\n",
            "1.0    398\n",
            "0.0    120\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para ALUA.BA: 0.7683 \n",
            "\n",
            "ROC-AUC (Test Set) para ALUA.BA: 0.5738\n",
            "\n",
            "Downloading data for BBAR.BA...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiIndex columns detected for BBAR.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for BBAR.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-09-08  5175.0  5175.0  4482.5  4507.5  1397504     4507.5\n",
            "2025-09-09  4600.0  4650.0  4385.0  4400.0   761818     4400.0\n",
            "2025-09-10  4550.0  4710.0  4475.0  4655.0   206731     4655.0\n",
            "2025-09-11  4695.0  4750.0  4542.5  4592.5   266476     4592.5\n",
            "2025-09-12  4680.0  4680.0  4310.0  4447.5   368480     4447.5\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-09-04  5580.0  5850.0  5510.0  5720.0   276714     5720.0       5540.0   \n",
            "2025-09-05  5840.0  5840.0  5410.0  5640.0   596771     5640.0       5720.0   \n",
            "2025-09-08  5175.0  5175.0  4482.5  4507.5  1397504     4507.5       5640.0   \n",
            "2025-09-09  4600.0  4650.0  4385.0  4400.0   761818     4400.0       4507.5   \n",
            "2025-09-10  4550.0  4710.0  4475.0  4655.0   206731     4655.0       4400.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       5620.0       5380.0       5520.0       5610.0      5650.0   \n",
            "2025-09-05       5540.0       5620.0       5380.0       5520.0      5580.0   \n",
            "2025-09-08       5720.0       5540.0       5620.0       5380.0      5840.0   \n",
            "2025-09-09       5640.0       5720.0       5540.0       5620.0      5175.0   \n",
            "2025-09-10       4507.5       5640.0       5720.0       5540.0      4600.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      5390.0      5650.0      5610.0      5620.0      5690.0   \n",
            "2025-09-05      5650.0      5390.0      5650.0      5610.0      5850.0   \n",
            "2025-09-08      5580.0      5650.0      5390.0      5650.0      5840.0   \n",
            "2025-09-09      5840.0      5580.0      5650.0      5390.0      5175.0   \n",
            "2025-09-10      5175.0      5840.0      5580.0      5650.0      4650.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      5650.0      5650.0      5680.0      5780.0    0.032491   \n",
            "2025-09-05      5690.0      5650.0      5650.0      5680.0   -0.013986   \n",
            "2025-09-08      5850.0      5690.0      5650.0      5650.0   -0.200798   \n",
            "2025-09-09      5840.0      5850.0      5690.0      5650.0   -0.023849   \n",
            "2025-09-10      5175.0      5840.0      5850.0      5690.0    0.057955   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.014235     0.044610    -0.025362    -0.016043     0.016304   \n",
            "2025-09-05     0.032491    -0.014235     0.044610    -0.025362    -0.016043   \n",
            "2025-09-08    -0.013986     0.032491    -0.014235     0.044610    -0.025362   \n",
            "2025-09-09    -0.200798    -0.013986     0.032491    -0.014235     0.044610   \n",
            "2025-09-10    -0.023849    -0.200798    -0.013986     0.032491    -0.014235   \n",
            "\n",
            "                  RSI        ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                    \n",
            "2025-09-04  47.663551   1.960784 -1.936610   -2.960132       1.023522   \n",
            "2025-09-05  56.666667   2.173913 -1.528495   -2.482919       0.954424   \n",
            "2025-09-08  21.621622 -16.217472 -4.015444   -2.993761      -1.021683   \n",
            "2025-09-09  21.428571 -21.708185 -5.516746   -3.834756      -1.681990   \n",
            "2025-09-10  32.530120 -15.974729 -5.338977   -4.336163      -1.002814   \n",
            "\n",
            "                  EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13  \\\n",
            "Date                                                                  \n",
            "2025-09-04 -11.661127  -12.282763       0.621637  5556.0  5836.1538   \n",
            "2025-09-05 -11.034682  -11.866736       0.832054  5580.0  5770.0000   \n",
            "2025-09-08 -15.607353  -13.113608      -2.493744  5405.5  5615.9615   \n",
            "2025-09-09 -18.871697  -15.032971      -3.838726  5161.5  5476.7308   \n",
            "2025-09-10 -19.519353  -16.528432      -2.990921  4984.5  5360.9615   \n",
            "\n",
            "                SMA26    SMA50     SMA200  Volatility  \\\n",
            "Date                                                    \n",
            "2025-09-04  6534.6154  6558.40  7388.4000  750.249081   \n",
            "2025-09-05  6475.0000  6535.60  7386.0000  722.840887   \n",
            "2025-09-08  6371.8269  6489.95  7379.0375  772.329983   \n",
            "2025-09-09  6273.7500  6443.35  7371.1375  799.949947   \n",
            "2025-09-10  6177.7885  6404.85  7363.8125  773.324792   \n",
            "\n",
            "            Max_Gain_from_Open_Current  Max_Gain_from_Open_Lag_1  \\\n",
            "Date                                                               \n",
            "2025-09-04                    0.048387                  0.035398   \n",
            "2025-09-05                    0.000000                  0.048387   \n",
            "2025-09-08                    0.000000                  0.000000   \n",
            "2025-09-09                    0.032609                  0.000000   \n",
            "2025-09-10                    0.043956                  0.032609   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_2  Max_Gain_from_Open_Lag_3  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.085343                  0.007080   \n",
            "2025-09-05                  0.035398                  0.085343   \n",
            "2025-09-08                  0.048387                  0.035398   \n",
            "2025-09-09                  0.000000                  0.048387   \n",
            "2025-09-10                  0.000000                  0.000000   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_4  Max_Gain_from_Open_Lag_5  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.012478                  0.028470   \n",
            "2025-09-05                  0.007080                  0.012478   \n",
            "2025-09-08                  0.085343                  0.007080   \n",
            "2025-09-09                  0.035398                  0.085343   \n",
            "2025-09-10                  0.048387                  0.035398   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_6  Label_raw  Label  \n",
            "Date                                                    \n",
            "2025-09-04                  0.010381          0    1.0  \n",
            "2025-09-05                  0.028470          1    1.0  \n",
            "2025-09-08                  0.012478          1    1.0  \n",
            "2025-09-09                  0.007080          1    0.0  \n",
            "2025-09-10                  0.085343          0    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "Distribucion de etiquetas para BBAR.BA:\n",
            "Label\n",
            "1.0    0.69197\n",
            "0.0    0.30803\n",
            "Name: proportion, dtype: float64\n",
            "Correlacion con label para BBAR.BA:\n",
            "Label                         1.000000\n",
            "high_lag_1                    0.102475\n",
            "close_lag_1                   0.102424\n",
            "open_lag_1                    0.102082\n",
            "high_lag_2                    0.101677\n",
            "close_lag_2                   0.101671\n",
            "SMA5                          0.101554\n",
            "SMA13                         0.101335\n",
            "open_lag_5                    0.101233\n",
            "high_lag_3                    0.101142\n",
            "close_lag_5                   0.101098\n",
            "high_lag_4                    0.101062\n",
            "open_lag_2                    0.101042\n",
            "open_lag_3                    0.101000\n",
            "high_lag_5                    0.100923\n",
            "close_lag_4                   0.100823\n",
            "open_lag_4                    0.100819\n",
            "close_lag_3                   0.100795\n",
            "SMA26                         0.100699\n",
            "SMA50                         0.100206\n",
            "SMA200                        0.097080\n",
            "Volatility                    0.091043\n",
            "Max_Gain_from_Open_Lag_4      0.072055\n",
            "Max_Gain_from_Open_Lag_3      0.063872\n",
            "Max_Gain_from_Open_Lag_2      0.063385\n",
            "Max_Gain_from_Open_Lag_1      0.051232\n",
            "Max_Gain_from_Open_Current    0.044586\n",
            "Max_Gain_from_Open_Lag_6      0.034693\n",
            "Max_Gain_from_Open_Lag_5      0.024498\n",
            "lag_change1                   0.022015\n",
            "ROC                           0.020367\n",
            "EWO                           0.015259\n",
            "lag_change4                   0.014911\n",
            "EWO_Signal                    0.014308\n",
            "lag_change5                   0.010871\n",
            "PPO_Histogram                 0.009744\n",
            "RSI                           0.008424\n",
            "EWO_Histogram                 0.006730\n",
            "PPO                           0.006562\n",
            "PPO_Signal                    0.003473\n",
            "lag_change2                   0.002250\n",
            "lag_change3                  -0.000996\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para BBAR.BA\n",
            "Mejores hiperparámetros para BBAR.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for BBAR.BA:\n",
            "open_lag_2                    0.047716\n",
            "open_lag_3                    0.038723\n",
            "SMA200                        0.036906\n",
            "SMA13                         0.031514\n",
            "Volatility                    0.029661\n",
            "Max_Gain_from_Open_Current    0.029118\n",
            "close_lag_2                   0.028021\n",
            "high_lag_5                    0.027920\n",
            "high_lag_1                    0.027003\n",
            "high_lag_3                    0.026235\n",
            "close_lag_3                   0.024641\n",
            "open_lag_1                    0.024607\n",
            "SMA50                         0.024397\n",
            "PPO_Signal                    0.023964\n",
            "high_lag_4                    0.023850\n",
            "close_lag_4                   0.023539\n",
            "close_lag_1                   0.023124\n",
            "SMA26                         0.023012\n",
            "Max_Gain_from_Open_Lag_1      0.022743\n",
            "close_lag_5                   0.022645\n",
            "high_lag_2                    0.022424\n",
            "open_lag_5                    0.022199\n",
            "EWO_Histogram                 0.022126\n",
            "Max_Gain_from_Open_Lag_6      0.022118\n",
            "PPO                           0.022116\n",
            "EWO_Signal                    0.022020\n",
            "Max_Gain_from_Open_Lag_5      0.021966\n",
            "RSI                           0.021917\n",
            "Max_Gain_from_Open_Lag_2      0.021834\n",
            "ROC                           0.021553\n",
            "lag_change1                   0.021457\n",
            "EWO                           0.021399\n",
            "lag_change2                   0.021398\n",
            "Max_Gain_from_Open_Lag_4      0.020961\n",
            "Max_Gain_from_Open_Lag_3      0.020490\n",
            "lag_change4                   0.020230\n",
            "lag_change3                   0.020193\n",
            "PPO_Histogram                 0.020002\n",
            "lag_change5                   0.019910\n",
            "open_lag_4                    0.017236\n",
            "SMA5                          0.017113\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum Precision (Clase 1) on training data for BBAR.BA...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para BBAR.BA: 0.5700 (Precision: 1.0000)\n",
            "\n",
            "Evaluating best model on test set for BBAR.BA with best threshold (0.5700):\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        70\n",
            "         1.0       0.86      1.00      0.93       448\n",
            "\n",
            "    accuracy                           0.86       518\n",
            "   macro avg       0.43      0.50      0.46       518\n",
            "weighted avg       0.75      0.86      0.80       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para BBAR.BA:\n",
            "Label\n",
            "1.0    448\n",
            "0.0     70\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para BBAR.BA: 0.8649 \n",
            "\n",
            "ROC-AUC (Test Set) para BBAR.BA: 0.4410\n",
            "\n",
            "DEBUG: Zero values detected in last_features_cleaned for BBAR.BA.\n",
            "\n",
            "Downloading data for METR.BA...\n",
            "MultiIndex columns detected for METR.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for METR.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-09-08  1360.0  1405.0  1200.0  1280.0  1671480     1280.0\n",
            "2025-09-09  1310.0  1330.0  1220.0  1236.0  1428948     1236.0\n",
            "2025-09-10  1270.0  1387.0  1251.0  1376.0   878597     1376.0\n",
            "2025-09-11  1409.0  1418.0  1336.0  1347.0   844769     1347.0\n",
            "2025-09-12  1357.0  1357.0  1250.0  1268.0  1161341     1268.0\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-09-04  1455.0  1515.0  1445.0  1475.0  1207202     1475.0       1455.0   \n",
            "2025-09-05  1500.0  1550.0  1445.0  1520.0  1061235     1520.0       1475.0   \n",
            "2025-09-08  1360.0  1405.0  1200.0  1280.0  1671480     1280.0       1520.0   \n",
            "2025-09-09  1310.0  1330.0  1220.0  1236.0  1428948     1236.0       1280.0   \n",
            "2025-09-10  1270.0  1387.0  1251.0  1376.0   878597     1376.0       1236.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       1510.0       1550.0       1600.0       1650.0      1520.0   \n",
            "2025-09-05       1455.0       1510.0       1550.0       1600.0      1455.0   \n",
            "2025-09-08       1475.0       1455.0       1510.0       1550.0      1500.0   \n",
            "2025-09-09       1520.0       1475.0       1455.0       1510.0      1360.0   \n",
            "2025-09-10       1280.0       1520.0       1475.0       1455.0      1310.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      1560.0      1650.0      1665.0      1660.0      1550.0   \n",
            "2025-09-05      1520.0      1560.0      1650.0      1665.0      1515.0   \n",
            "2025-09-08      1455.0      1520.0      1560.0      1650.0      1550.0   \n",
            "2025-09-09      1500.0      1455.0      1520.0      1560.0      1405.0   \n",
            "2025-09-10      1360.0      1500.0      1455.0      1520.0      1330.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      1580.0      1650.0      1675.0      1725.0    0.013746   \n",
            "2025-09-05      1550.0      1580.0      1650.0      1675.0    0.030508   \n",
            "2025-09-08      1515.0      1550.0      1580.0      1650.0   -0.157895   \n",
            "2025-09-09      1550.0      1515.0      1550.0      1580.0   -0.034375   \n",
            "2025-09-10      1405.0      1550.0      1515.0      1550.0    0.113269   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.036424    -0.025806    -0.031250    -0.030303     0.003040   \n",
            "2025-09-05     0.013746    -0.036424    -0.025806    -0.031250    -0.030303   \n",
            "2025-09-08     0.030508     0.013746    -0.036424    -0.025806    -0.031250   \n",
            "2025-09-09    -0.157895     0.030508     0.013746    -0.036424    -0.025806   \n",
            "2025-09-10    -0.034375    -0.157895     0.030508     0.013746    -0.036424   \n",
            "\n",
            "                  RSI        ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                    \n",
            "2025-09-04   8.064516 -10.606061 -4.826070   -4.736157      -0.089913   \n",
            "2025-09-05  26.415094  -5.000000 -3.935185   -4.469166       0.533981   \n",
            "2025-09-08  13.000000 -17.419355 -5.397840   -4.778724      -0.619116   \n",
            "2025-09-09  13.157895 -18.145695 -6.359381   -5.305609      -1.053771   \n",
            "2025-09-10  35.102740  -5.429553 -5.125488   -5.245569       0.120081   \n",
            "\n",
            "                  EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13  \\\n",
            "Date                                                                  \n",
            "2025-09-04 -17.791943  -15.795310      -1.996633  1518.0  1688.4615   \n",
            "2025-09-05 -17.035754  -16.208791      -0.826962  1502.0  1656.1538   \n",
            "2025-09-08 -20.101066  -17.506216      -2.594850  1448.0  1610.7692   \n",
            "2025-09-09 -22.547386  -19.186606      -3.360780  1393.2  1558.5385   \n",
            "2025-09-10 -21.518899  -19.964037      -1.554862  1377.4  1519.7692   \n",
            "\n",
            "                SMA26    SMA50    SMA200  Volatility  \\\n",
            "Date                                                   \n",
            "2025-09-04  1921.1538  1935.30  2195.175  255.818989   \n",
            "2025-09-05  1895.7692  1927.30  2194.300  243.218009   \n",
            "2025-09-08  1861.7308  1913.90  2192.450  250.845282   \n",
            "2025-09-09  1829.0769  1899.32  2190.080  259.335913   \n",
            "2025-09-10  1799.3077  1889.84  2188.235  249.501376   \n",
            "\n",
            "            Max_Gain_from_Open_Current  Max_Gain_from_Open_Lag_1  \\\n",
            "Date                                                               \n",
            "2025-09-04                    0.065292                  0.019737   \n",
            "2025-09-05                    0.033333                  0.065292   \n",
            "2025-09-08                    0.033088                  0.033333   \n",
            "2025-09-09                    0.082443                  0.033088   \n",
            "2025-09-10                    0.116535                  0.082443   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_2  Max_Gain_from_Open_Lag_3  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.012821                  0.000000   \n",
            "2025-09-05                  0.019737                  0.012821   \n",
            "2025-09-08                  0.065292                  0.019737   \n",
            "2025-09-09                  0.033333                  0.065292   \n",
            "2025-09-10                  0.033088                  0.033333   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_4  Max_Gain_from_Open_Lag_5  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.006006                  0.039157   \n",
            "2025-09-05                  0.000000                  0.006006   \n",
            "2025-09-08                  0.012821                  0.000000   \n",
            "2025-09-09                  0.019737                  0.012821   \n",
            "2025-09-10                  0.065292                  0.019737   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_6  Label_raw  Label  \n",
            "Date                                                    \n",
            "2025-09-04                  0.002882          1    1.0  \n",
            "2025-09-05                  0.039157          1    1.0  \n",
            "2025-09-08                  0.006006          1    1.0  \n",
            "2025-09-09                  0.000000          1    0.0  \n",
            "2025-09-10                  0.012821          0    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "Distribucion de etiquetas para METR.BA:\n",
            "Label\n",
            "1.0    0.663329\n",
            "0.0    0.336671\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlacion con label para METR.BA:\n",
            "Label                         1.000000\n",
            "high_lag_1                    0.116599\n",
            "open_lag_1                    0.116282\n",
            "close_lag_1                   0.116013\n",
            "close_lag_2                   0.115993\n",
            "high_lag_2                    0.115975\n",
            "Volatility                    0.115687\n",
            "SMA5                          0.115661\n",
            "open_lag_2                    0.115555\n",
            "close_lag_3                   0.115381\n",
            "high_lag_3                    0.115134\n",
            "open_lag_3                    0.114637\n",
            "close_lag_4                   0.114507\n",
            "SMA13                         0.114335\n",
            "high_lag_4                    0.114288\n",
            "close_lag_5                   0.113902\n",
            "open_lag_4                    0.113855\n",
            "high_lag_5                    0.113644\n",
            "SMA26                         0.113356\n",
            "open_lag_5                    0.113030\n",
            "SMA50                         0.112896\n",
            "SMA200                        0.107125\n",
            "EWO                           0.093745\n",
            "EWO_Signal                    0.089646\n",
            "PPO_Signal                    0.075236\n",
            "PPO                           0.074938\n",
            "RSI                           0.068908\n",
            "ROC                           0.068327\n",
            "Max_Gain_from_Open_Lag_1      0.038919\n",
            "lag_change3                   0.037890\n",
            "Max_Gain_from_Open_Current    0.037857\n",
            "Max_Gain_from_Open_Lag_2      0.036913\n",
            "lag_change2                   0.035407\n",
            "EWO_Histogram                 0.034532\n",
            "lag_change1                   0.030724\n",
            "lag_change4                   0.030626\n",
            "Max_Gain_from_Open_Lag_6      0.027627\n",
            "Max_Gain_from_Open_Lag_5      0.026113\n",
            "Max_Gain_from_Open_Lag_4      0.025666\n",
            "lag_change5                   0.025351\n",
            "PPO_Histogram                 0.020014\n",
            "Max_Gain_from_Open_Lag_3      0.009619\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para METR.BA\n",
            "Mejores hiperparámetros para METR.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for METR.BA:\n",
            "Max_Gain_from_Open_Current    0.039010\n",
            "high_lag_1                    0.036757\n",
            "Volatility                    0.035349\n",
            "high_lag_3                    0.032200\n",
            "high_lag_4                    0.030067\n",
            "close_lag_1                   0.029567\n",
            "close_lag_4                   0.028983\n",
            "SMA50                         0.028334\n",
            "open_lag_1                    0.027802\n",
            "EWO                           0.026740\n",
            "close_lag_5                   0.026607\n",
            "close_lag_3                   0.025958\n",
            "open_lag_3                    0.025683\n",
            "open_lag_5                    0.025169\n",
            "EWO_Signal                    0.024680\n",
            "high_lag_5                    0.023803\n",
            "SMA26                         0.023385\n",
            "PPO                           0.023016\n",
            "open_lag_2                    0.023005\n",
            "close_lag_2                   0.022840\n",
            "SMA200                        0.022591\n",
            "EWO_Histogram                 0.022559\n",
            "PPO_Signal                    0.022390\n",
            "lag_change4                   0.022045\n",
            "Max_Gain_from_Open_Lag_5      0.021918\n",
            "SMA13                         0.021828\n",
            "Max_Gain_from_Open_Lag_2      0.021788\n",
            "high_lag_2                    0.021629\n",
            "lag_change5                   0.021581\n",
            "Max_Gain_from_Open_Lag_3      0.021566\n",
            "open_lag_4                    0.021472\n",
            "lag_change3                   0.020961\n",
            "lag_change1                   0.020703\n",
            "ROC                           0.020487\n",
            "PPO_Histogram                 0.020302\n",
            "Max_Gain_from_Open_Lag_1      0.020173\n",
            "Max_Gain_from_Open_Lag_4      0.019667\n",
            "Max_Gain_from_Open_Lag_6      0.019645\n",
            "RSI                           0.019439\n",
            "SMA5                          0.019198\n",
            "lag_change2                   0.019104\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum Precision (Clase 1) on training data for METR.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para METR.BA: 0.6300 (Precision: 1.0000)\n",
            "\n",
            "Evaluating best model on test set for METR.BA with best threshold (0.6300):\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.18      0.21        71\n",
            "         1.0       0.88      0.92      0.90       447\n",
            "\n",
            "    accuracy                           0.82       518\n",
            "   macro avg       0.57      0.55      0.56       518\n",
            "weighted avg       0.79      0.82      0.80       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para METR.BA:\n",
            "Label\n",
            "1.0    447\n",
            "0.0     71\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para METR.BA: 0.8629 \n",
            "\n",
            "ROC-AUC (Test Set) para METR.BA: 0.5490\n",
            "\n",
            "Downloading data for PAMP.BA...\n",
            "MultiIndex columns detected for PAMP.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for PAMP.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-09-08  3452.5  3452.5  3205.0  3267.5  6312048     3267.5\n",
            "2025-09-09  3320.0  3440.0  3297.5  3372.5  3954211     3372.5\n",
            "2025-09-10  3370.0  3625.0  3370.0  3580.0  2738737     3580.0\n",
            "2025-09-11  3615.0  3635.0  3510.0  3587.5  1639119     3587.5\n",
            "2025-09-12  3600.0  3630.0  3455.0  3512.5  2029321     3512.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-09-04  3610.0  3755.0  3565.0  3725.0  1803914     3725.0       3610.0   \n",
            "2025-09-05  3680.0  3850.0  3630.0  3760.0  2310446     3760.0       3725.0   \n",
            "2025-09-08  3452.5  3452.5  3205.0  3267.5  6312048     3267.5       3760.0   \n",
            "2025-09-09  3320.0  3440.0  3297.5  3372.5  3954211     3372.5       3267.5   \n",
            "2025-09-10  3370.0  3625.0  3370.0  3580.0  2738737     3580.0       3372.5   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       3610.0       3535.0       3645.0       3675.0      3520.0   \n",
            "2025-09-05       3610.0       3610.0       3535.0       3645.0      3610.0   \n",
            "2025-09-08       3725.0       3610.0       3610.0       3535.0      3680.0   \n",
            "2025-09-09       3760.0       3725.0       3610.0       3610.0      3452.5   \n",
            "2025-09-10       3267.5       3760.0       3725.0       3610.0      3320.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      3565.0      3600.0      3675.0      3580.0      3680.0   \n",
            "2025-09-05      3520.0      3565.0      3600.0      3675.0      3755.0   \n",
            "2025-09-08      3610.0      3520.0      3565.0      3600.0      3850.0   \n",
            "2025-09-09      3680.0      3610.0      3520.0      3565.0      3452.5   \n",
            "2025-09-10      3452.5      3680.0      3610.0      3520.0      3440.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      3635.0      3670.0      3675.0      3780.0    0.031856   \n",
            "2025-09-05      3680.0      3635.0      3670.0      3675.0    0.009396   \n",
            "2025-09-08      3755.0      3680.0      3635.0      3670.0   -0.130984   \n",
            "2025-09-09      3850.0      3755.0      3680.0      3635.0    0.032135   \n",
            "2025-09-10      3452.5      3850.0      3755.0      3680.0    0.061527   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04     0.000000     0.021216    -0.030178    -0.008163     0.023677   \n",
            "2025-09-05     0.031856     0.000000     0.021216    -0.030178    -0.008163   \n",
            "2025-09-08     0.009396     0.031856     0.000000     0.021216    -0.030178   \n",
            "2025-09-09    -0.130984     0.009396     0.031856     0.000000     0.021216   \n",
            "2025-09-10     0.032135    -0.130984     0.009396     0.031856     0.000000   \n",
            "\n",
            "                  RSI       ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                   \n",
            "2025-09-04  53.921569  1.360544 -0.388125   -0.951935       0.563810   \n",
            "2025-09-05  68.888889  3.155007  0.083731   -0.606713       0.690444   \n",
            "2025-09-08  26.239067 -7.567185 -1.487124   -0.900183      -0.586941   \n",
            "2025-09-09  35.388740 -6.578947 -1.861685   -1.220684      -0.641001   \n",
            "2025-09-10  52.184466 -0.831025 -1.147399   -1.196256       0.048857   \n",
            "\n",
            "                 EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13      SMA26  \\\n",
            "Date                                                                            \n",
            "2025-09-04 -2.749206   -3.282591       0.533384  3625.0  3661.9231  3865.7692   \n",
            "2025-09-05 -1.793610   -2.786264       0.992654  3648.0  3666.5385  3852.3077   \n",
            "2025-09-08 -4.837024   -3.469851      -1.367173  3594.5  3632.1154  3819.7115   \n",
            "2025-09-09 -5.904360   -4.281354      -1.623006  3547.0  3602.6923  3793.0769   \n",
            "2025-09-10 -4.905881   -4.489529      -0.416351  3541.0  3589.6154  3775.0000   \n",
            "\n",
            "              SMA50     SMA200  Volatility  Max_Gain_from_Open_Current  \\\n",
            "Date                                                                     \n",
            "2025-09-04  3743.90  3815.8250  179.871848                    0.066482   \n",
            "2025-09-05  3752.10  3818.3750  159.316798                    0.046196   \n",
            "2025-09-08  3749.85  3818.4875  185.410773                    0.049964   \n",
            "2025-09-09  3749.50  3818.8500  189.626711                    0.094880   \n",
            "2025-09-10  3754.20  3819.9500  172.085696                    0.078635   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_1  Max_Gain_from_Open_Lag_2  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.093750                  0.053296   \n",
            "2025-09-05                  0.066482                  0.093750   \n",
            "2025-09-08                  0.046196                  0.066482   \n",
            "2025-09-09                  0.049964                  0.046196   \n",
            "2025-09-10                  0.094880                  0.049964   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_3  Max_Gain_from_Open_Lag_4  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.022222                  0.000000   \n",
            "2025-09-05                  0.053296                  0.022222   \n",
            "2025-09-08                  0.093750                  0.053296   \n",
            "2025-09-09                  0.066482                  0.093750   \n",
            "2025-09-10                  0.046196                  0.066482   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_5  Max_Gain_from_Open_Lag_6  Label_raw  \\\n",
            "Date                                                                        \n",
            "2025-09-04                  0.055866                  0.025780          1   \n",
            "2025-09-05                  0.000000                  0.055866          1   \n",
            "2025-09-08                  0.022222                  0.000000          1   \n",
            "2025-09-09                  0.053296                  0.022222          1   \n",
            "2025-09-10                  0.093750                  0.053296          0   \n",
            "\n",
            "            Label  \n",
            "Date               \n",
            "2025-09-04    1.0  \n",
            "2025-09-05    1.0  \n",
            "2025-09-08    1.0  \n",
            "2025-09-09    0.0  \n",
            "2025-09-10    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "Distribucion de etiquetas para PAMP.BA:\n",
            "Label\n",
            "1.0    0.67077\n",
            "0.0    0.32923\n",
            "Name: proportion, dtype: float64\n",
            "Correlacion con label para PAMP.BA:\n",
            "Label                         1.000000\n",
            "Max_Gain_from_Open_Current    0.134698\n",
            "Volatility                    0.108181\n",
            "high_lag_2                    0.092795\n",
            "high_lag_1                    0.092737\n",
            "open_lag_1                    0.092325\n",
            "open_lag_2                    0.092324\n",
            "high_lag_3                    0.092304\n",
            "high_lag_4                    0.092201\n",
            "close_lag_2                   0.092159\n",
            "close_lag_1                   0.092141\n",
            "high_lag_5                    0.092042\n",
            "open_lag_3                    0.092038\n",
            "SMA5                          0.092022\n",
            "close_lag_3                   0.091991\n",
            "SMA13                         0.091986\n",
            "close_lag_5                   0.091954\n",
            "open_lag_4                    0.091952\n",
            "open_lag_5                    0.091835\n",
            "close_lag_4                   0.091826\n",
            "SMA26                         0.091293\n",
            "SMA50                         0.089597\n",
            "SMA200                        0.082959\n",
            "Max_Gain_from_Open_Lag_1      0.050449\n",
            "Max_Gain_from_Open_Lag_2      0.050318\n",
            "Max_Gain_from_Open_Lag_3      0.045866\n",
            "Max_Gain_from_Open_Lag_6      0.040572\n",
            "EWO_Signal                    0.028677\n",
            "EWO                           0.028384\n",
            "Max_Gain_from_Open_Lag_5      0.026919\n",
            "RSI                           0.026747\n",
            "PPO_Signal                    0.025181\n",
            "PPO                           0.022916\n",
            "Max_Gain_from_Open_Lag_4      0.019575\n",
            "lag_change5                   0.015429\n",
            "lag_change2                   0.014301\n",
            "lag_change4                   0.010065\n",
            "ROC                           0.008089\n",
            "EWO_Histogram                 0.005231\n",
            "PPO_Histogram                 0.001579\n",
            "lag_change1                  -0.000173\n",
            "lag_change3                  -0.015717\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para PAMP.BA\n",
            "Mejores hiperparámetros para PAMP.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for PAMP.BA:\n",
            "high_lag_2                    0.047732\n",
            "Volatility                    0.042665\n",
            "SMA50                         0.035573\n",
            "SMA200                        0.030529\n",
            "open_lag_2                    0.028949\n",
            "Max_Gain_from_Open_Current    0.028879\n",
            "high_lag_5                    0.028681\n",
            "close_lag_4                   0.028579\n",
            "open_lag_3                    0.026951\n",
            "close_lag_5                   0.026562\n",
            "open_lag_5                    0.026162\n",
            "high_lag_4                    0.025792\n",
            "close_lag_3                   0.025613\n",
            "open_lag_1                    0.025158\n",
            "high_lag_3                    0.024161\n",
            "open_lag_4                    0.023722\n",
            "PPO_Signal                    0.023409\n",
            "PPO                           0.023002\n",
            "SMA13                         0.022942\n",
            "Max_Gain_from_Open_Lag_6      0.022927\n",
            "SMA26                         0.021923\n",
            "lag_change2                   0.021917\n",
            "close_lag_2                   0.021776\n",
            "EWO                           0.021521\n",
            "EWO_Signal                    0.021459\n",
            "Max_Gain_from_Open_Lag_3      0.021223\n",
            "Max_Gain_from_Open_Lag_2      0.021118\n",
            "lag_change5                   0.020907\n",
            "close_lag_1                   0.020862\n",
            "lag_change3                   0.020849\n",
            "high_lag_1                    0.020747\n",
            "lag_change4                   0.020531\n",
            "lag_change1                   0.020501\n",
            "Max_Gain_from_Open_Lag_4      0.020385\n",
            "Max_Gain_from_Open_Lag_1      0.020350\n",
            "RSI                           0.019871\n",
            "SMA5                          0.019769\n",
            "ROC                           0.019587\n",
            "PPO_Histogram                 0.019576\n",
            "Max_Gain_from_Open_Lag_5      0.018882\n",
            "EWO_Histogram                 0.018257\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum Precision (Clase 1) on training data for PAMP.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para PAMP.BA: 0.5000 (Precision: 1.0000)\n",
            "\n",
            "Evaluating best model on test set for PAMP.BA with best threshold (0.5000):\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.06      0.09       104\n",
            "         1.0       0.80      0.93      0.86       414\n",
            "\n",
            "    accuracy                           0.75       518\n",
            "   macro avg       0.48      0.49      0.47       518\n",
            "weighted avg       0.67      0.75      0.70       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para PAMP.BA:\n",
            "Label\n",
            "1.0    414\n",
            "0.0    104\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para PAMP.BA: 0.7992 \n",
            "\n",
            "ROC-AUC (Test Set) para PAMP.BA: 0.5046\n",
            "\n",
            "DEBUG: Zero values detected in last_features_cleaned for PAMP.BA.\n",
            "\n",
            "DEBUG: Zero values detected in last_features_scaled for PAMP.BA BEFORE prediction.\n",
            "\n",
            "Downloading data for TRAN.BA...\n",
            "MultiIndex columns detected for TRAN.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for TRAN.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-09-08  1770.0  1910.0  1620.0  1883.0  1527140     1883.0\n",
            "2025-09-09  1940.0  1940.0  1800.0  1936.0  1217507     1936.0\n",
            "2025-09-10  1980.0  2050.0  1951.0  2037.0  1240119     2037.0\n",
            "2025-09-11  2055.0  2075.0  1958.0  2001.0  2764162     2001.0\n",
            "2025-09-12  2048.0  2048.0  1895.0  1906.0   550280     1906.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-09-04  1990.0  2030.0  1945.0  1970.0   570580     1970.0       1965.0   \n",
            "2025-09-05  2000.0  2000.0  1900.0  1920.0   791867     1920.0       1970.0   \n",
            "2025-09-08  1770.0  1910.0  1620.0  1883.0  1527140     1883.0       1920.0   \n",
            "2025-09-09  1940.0  1940.0  1800.0  1936.0  1217507     1936.0       1883.0   \n",
            "2025-09-10  1980.0  2050.0  1951.0  2037.0  1240119     2037.0       1936.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       2290.0       2340.0       2380.0       2365.0      2050.0   \n",
            "2025-09-05       1965.0       2290.0       2340.0       2380.0      1990.0   \n",
            "2025-09-08       1970.0       1965.0       2290.0       2340.0      2000.0   \n",
            "2025-09-09       1920.0       1970.0       1965.0       2290.0      1770.0   \n",
            "2025-09-10       1883.0       1920.0       1970.0       1965.0      1940.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      2390.0      2385.0      2395.0      2440.0      2050.0   \n",
            "2025-09-05      2050.0      2390.0      2385.0      2395.0      2030.0   \n",
            "2025-09-08      1990.0      2050.0      2390.0      2385.0      2000.0   \n",
            "2025-09-09      2000.0      1990.0      2050.0      2390.0      1910.0   \n",
            "2025-09-10      1770.0      2000.0      1990.0      2050.0      1940.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      2390.0      2430.0      2480.0      2515.0    0.002545   \n",
            "2025-09-05      2050.0      2390.0      2430.0      2480.0   -0.025381   \n",
            "2025-09-08      2030.0      2050.0      2390.0      2430.0   -0.019271   \n",
            "2025-09-09      2000.0      2030.0      2050.0      2390.0    0.028147   \n",
            "2025-09-10      1910.0      2000.0      2030.0      2050.0    0.052169   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.141921    -0.021368    -0.016807     0.006342    -0.024742   \n",
            "2025-09-05     0.002545    -0.141921    -0.021368    -0.016807     0.006342   \n",
            "2025-09-08    -0.025381     0.002545    -0.141921    -0.021368    -0.016807   \n",
            "2025-09-09    -0.019271    -0.025381     0.002545    -0.141921    -0.021368   \n",
            "2025-09-10     0.028147    -0.019271    -0.025381     0.002545    -0.141921   \n",
            "\n",
            "                  RSI        ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                    \n",
            "2025-09-04   3.305785 -16.701903 -4.949037   -3.336476      -1.612562   \n",
            "2025-09-05   3.669725 -19.327731 -5.447399   -4.040117      -1.407282   \n",
            "2025-09-08   3.831418 -19.529915 -5.652324   -4.577519      -1.074805   \n",
            "2025-09-09  10.357143 -15.458515 -5.060302   -4.738447      -0.321855   \n",
            "2025-09-10  25.603865   3.664122 -3.726008   -4.400967       0.674959   \n",
            "\n",
            "                  EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13  \\\n",
            "Date                                                                  \n",
            "2025-09-04 -11.533067   -7.002501      -4.530567  2189.0  2390.3846   \n",
            "2025-09-05 -13.620619   -9.208540      -4.412079  2097.0  2341.1538   \n",
            "2025-09-08 -15.207764  -11.208281      -3.999482  2005.6  2290.6154   \n",
            "2025-09-09 -15.355816  -12.590793      -2.765023  1934.8  2238.7692   \n",
            "2025-09-10 -13.971037  -13.050875      -0.920163  1949.2  2193.5385   \n",
            "\n",
            "                SMA26    SMA50    SMA200  Volatility  \\\n",
            "Date                                                   \n",
            "2025-09-04  2517.8846  2402.00  2398.675  199.555262   \n",
            "2025-09-05  2487.5000  2396.50  2397.225  227.521543   \n",
            "2025-09-08  2458.9615  2391.86  2396.490  254.114826   \n",
            "2025-09-09  2430.3462  2388.48  2396.070  271.358978   \n",
            "2025-09-10  2406.1923  2387.92  2395.905  274.809499   \n",
            "\n",
            "            Max_Gain_from_Open_Current  Max_Gain_from_Open_Lag_1  \\\n",
            "Date                                                               \n",
            "2025-09-04                    0.020101                  0.000000   \n",
            "2025-09-05                    0.000000                  0.020101   \n",
            "2025-09-08                    0.158192                  0.000000   \n",
            "2025-09-09                    0.069588                  0.158192   \n",
            "2025-09-10                    0.047980                  0.069588   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_2  Max_Gain_from_Open_Lag_3  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.000000                  0.018868   \n",
            "2025-09-05                  0.000000                  0.000000   \n",
            "2025-09-08                  0.020101                  0.000000   \n",
            "2025-09-09                  0.000000                  0.020101   \n",
            "2025-09-10                  0.158192                  0.000000   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_4  Max_Gain_from_Open_Lag_5  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.035491                  0.030738   \n",
            "2025-09-05                  0.018868                  0.035491   \n",
            "2025-09-08                  0.000000                  0.018868   \n",
            "2025-09-09                  0.000000                  0.000000   \n",
            "2025-09-10                  0.020101                  0.000000   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_6  Label_raw  Label  \n",
            "Date                                                    \n",
            "2025-09-04                  0.012072          0    1.0  \n",
            "2025-09-05                  0.030738          1    1.0  \n",
            "2025-09-08                  0.035491          1    1.0  \n",
            "2025-09-09                  0.018868          1    0.0  \n",
            "2025-09-10                  0.000000          0    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "Distribucion de etiquetas para TRAN.BA:\n",
            "Label\n",
            "1.0    0.685777\n",
            "0.0    0.314223\n",
            "Name: proportion, dtype: float64\n",
            "Correlacion con label para TRAN.BA:\n",
            "Label                         1.000000\n",
            "Volatility                    0.094471\n",
            "high_lag_2                    0.093820\n",
            "SMA50                         0.093440\n",
            "open_lag_1                    0.093415\n",
            "high_lag_1                    0.093348\n",
            "close_lag_2                   0.093344\n",
            "open_lag_2                    0.093337\n",
            "close_lag_3                   0.093226\n",
            "close_lag_1                   0.093208\n",
            "SMA5                          0.093018\n",
            "high_lag_3                    0.092980\n",
            "SMA26                         0.092952\n",
            "SMA13                         0.092779\n",
            "open_lag_3                    0.092667\n",
            "close_lag_4                   0.092507\n",
            "high_lag_4                    0.092468\n",
            "close_lag_5                   0.092092\n",
            "open_lag_4                    0.092089\n",
            "high_lag_5                    0.092043\n",
            "open_lag_5                    0.091915\n",
            "SMA200                        0.089198\n",
            "EWO_Signal                    0.072512\n",
            "EWO                           0.072107\n",
            "PPO_Signal                    0.047769\n",
            "PPO                           0.043424\n",
            "RSI                           0.042117\n",
            "Max_Gain_from_Open_Lag_1      0.041518\n",
            "Max_Gain_from_Open_Lag_3      0.037705\n",
            "lag_change5                   0.036068\n",
            "ROC                           0.035736\n",
            "Max_Gain_from_Open_Lag_4      0.032932\n",
            "lag_change1                   0.024514\n",
            "lag_change3                   0.023463\n",
            "lag_change4                   0.022269\n",
            "Max_Gain_from_Open_Lag_5      0.021625\n",
            "lag_change2                   0.017985\n",
            "Max_Gain_from_Open_Lag_2      0.012630\n",
            "Max_Gain_from_Open_Lag_6      0.011840\n",
            "EWO_Histogram                 0.009567\n",
            "Max_Gain_from_Open_Current    0.003136\n",
            "PPO_Histogram                 0.000594\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para TRAN.BA\n",
            "Mejores hiperparámetros para TRAN.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for TRAN.BA:\n",
            "Max_Gain_from_Open_Current    0.035892\n",
            "Volatility                    0.031173\n",
            "close_lag_4                   0.030663\n",
            "high_lag_2                    0.028588\n",
            "high_lag_4                    0.028344\n",
            "high_lag_3                    0.027926\n",
            "high_lag_5                    0.027850\n",
            "open_lag_4                    0.027649\n",
            "open_lag_1                    0.027138\n",
            "open_lag_3                    0.027036\n",
            "close_lag_3                   0.026430\n",
            "SMA13                         0.026057\n",
            "EWO_Histogram                 0.025309\n",
            "SMA200                        0.025009\n",
            "SMA26                         0.024858\n",
            "EWO                           0.024757\n",
            "close_lag_2                   0.024474\n",
            "open_lag_5                    0.024005\n",
            "close_lag_5                   0.023658\n",
            "Max_Gain_from_Open_Lag_3      0.023532\n",
            "EWO_Signal                    0.023370\n",
            "RSI                           0.023327\n",
            "close_lag_1                   0.023212\n",
            "lag_change4                   0.023161\n",
            "Max_Gain_from_Open_Lag_4      0.022629\n",
            "PPO_Histogram                 0.022470\n",
            "PPO_Signal                    0.022434\n",
            "SMA50                         0.022406\n",
            "Max_Gain_from_Open_Lag_1      0.022213\n",
            "lag_change5                   0.022157\n",
            "Max_Gain_from_Open_Lag_2      0.022139\n",
            "ROC                           0.022067\n",
            "open_lag_2                    0.022005\n",
            "Max_Gain_from_Open_Lag_5      0.021756\n",
            "Max_Gain_from_Open_Lag_6      0.021678\n",
            "PPO                           0.021647\n",
            "lag_change2                   0.021525\n",
            "lag_change3                   0.021142\n",
            "lag_change1                   0.020982\n",
            "high_lag_1                    0.019674\n",
            "SMA5                          0.017658\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum Precision (Clase 1) on training data for TRAN.BA...\n",
            "Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para TRAN.BA: 0.5700 (Precision: 1.0000)\n",
            "\n",
            "Evaluating best model on test set for TRAN.BA with best threshold (0.5700):\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.09      0.11        81\n",
            "         1.0       0.84      0.91      0.88       437\n",
            "\n",
            "    accuracy                           0.78       518\n",
            "   macro avg       0.50      0.50      0.49       518\n",
            "weighted avg       0.74      0.78      0.76       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para TRAN.BA:\n",
            "Label\n",
            "1.0    437\n",
            "0.0     81\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para TRAN.BA: 0.8436 \n",
            "\n",
            "ROC-AUC (Test Set) para TRAN.BA: 0.4969\n",
            "\n",
            "DEBUG: Zero values detected in last_features_cleaned for TRAN.BA.\n",
            "\n",
            "Downloading data for YPFD.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex columns detected for YPFD.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for YPFD.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "               Open     High      Low    Close   Volume  Adj Close\n",
            "Date                                                              \n",
            "2025-09-08  37500.0  39740.0  36400.0  37860.0  1377767    37860.0\n",
            "2025-09-09  38200.0  40060.0  38000.0  38600.0   808166    38600.0\n",
            "2025-09-10  38800.0  41600.0  38800.0  41120.0   590144    41120.0\n",
            "2025-09-11  41200.0  41700.0  40600.0  40880.0   416272    40880.0\n",
            "2025-09-12  41000.0  41600.0  39620.0  40200.0   520388    40200.0\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "               Open     High      Low    Close   Volume  Adj Close  \\\n",
            "Date                                                                 \n",
            "2025-09-04  41000.0  42700.0  40425.0  42525.0   683759    42525.0   \n",
            "2025-09-05  42200.0  43725.0  41600.0  42875.0   584925    42875.0   \n",
            "2025-09-08  37500.0  39740.0  36400.0  37860.0  1377767    37860.0   \n",
            "2025-09-09  38200.0  40060.0  38000.0  38600.0   808166    38600.0   \n",
            "2025-09-10  38800.0  41600.0  38800.0  41120.0   590144    41120.0   \n",
            "\n",
            "            close_lag_1  close_lag_2  close_lag_3  close_lag_4  close_lag_5  \\\n",
            "Date                                                                          \n",
            "2025-09-04      40650.0      41550.0      40450.0      41300.0      41575.0   \n",
            "2025-09-05      42525.0      40650.0      41550.0      40450.0      41300.0   \n",
            "2025-09-08      42875.0      42525.0      40650.0      41550.0      40450.0   \n",
            "2025-09-09      37860.0      42875.0      42525.0      40650.0      41550.0   \n",
            "2025-09-10      38600.0      37860.0      42875.0      42525.0      40650.0   \n",
            "\n",
            "            open_lag_1  open_lag_2  open_lag_3  open_lag_4  open_lag_5  \\\n",
            "Date                                                                     \n",
            "2025-09-04     41000.0     40425.0     41300.0     41575.0     41200.0   \n",
            "2025-09-05     41000.0     41000.0     40425.0     41300.0     41575.0   \n",
            "2025-09-08     42200.0     41000.0     41000.0     40425.0     41300.0   \n",
            "2025-09-09     37500.0     42200.0     41000.0     41000.0     40425.0   \n",
            "2025-09-10     38200.0     37500.0     42200.0     41000.0     41000.0   \n",
            "\n",
            "            high_lag_1  high_lag_2  high_lag_3  high_lag_4  high_lag_5  \\\n",
            "Date                                                                     \n",
            "2025-09-04     42050.0     41650.0     41300.0     41800.0     42800.0   \n",
            "2025-09-05     42700.0     42050.0     41650.0     41300.0     41800.0   \n",
            "2025-09-08     43725.0     42700.0     42050.0     41650.0     41300.0   \n",
            "2025-09-09     39740.0     43725.0     42700.0     42050.0     41650.0   \n",
            "2025-09-10     40060.0     39740.0     43725.0     42700.0     42050.0   \n",
            "\n",
            "            Pct_change  lag_change1  lag_change2  lag_change3  lag_change4  \\\n",
            "Date                                                                         \n",
            "2025-09-04    0.046125    -0.021661     0.027194    -0.020581    -0.006615   \n",
            "2025-09-05    0.008230     0.046125    -0.021661     0.027194    -0.020581   \n",
            "2025-09-08   -0.116968     0.008230     0.046125    -0.021661     0.027194   \n",
            "2025-09-09    0.019546    -0.116968     0.008230     0.046125    -0.021661   \n",
            "2025-09-10    0.065285     0.019546    -0.116968     0.008230     0.046125   \n",
            "\n",
            "            lag_change5        RSI       ROC       PPO  PPO_Signal  \\\n",
            "Date                                                                 \n",
            "2025-09-04     0.009102  55.833333  2.285027 -0.201252   -0.707360   \n",
            "2025-09-05    -0.006615  64.628821  3.813559  0.257748   -0.385657   \n",
            "2025-09-08    -0.020581  32.079112 -6.402967 -1.133251   -0.634855   \n",
            "2025-09-09     0.027194  37.534626 -7.099880 -1.581247   -0.950319   \n",
            "2025-09-10    -0.021661  52.680000  1.156212 -0.877239   -0.925959   \n",
            "\n",
            "            PPO_Histogram       EWO  EWO_Signal  EWO_Histogram     SMA5  \\\n",
            "Date                                                                      \n",
            "2025-09-04       0.506108 -1.826492   -2.367696       0.541204  41295.0   \n",
            "2025-09-05       0.643405 -0.863104   -1.866165       1.003061  41610.0   \n",
            "2025-09-08      -0.498396 -3.550516   -2.427615      -1.122900  41092.0   \n",
            "2025-09-09      -0.630928 -4.707359   -3.187530      -1.519829  40502.0   \n",
            "2025-09-10       0.048720 -3.672197   -3.349085      -0.323111  40596.0   \n",
            "\n",
            "                 SMA13       SMA26    SMA50     SMA200   Volatility  \\\n",
            "Date                                                                  \n",
            "2025-09-04  41480.7692  43517.3077  42006.0  43442.625  2003.537579   \n",
            "2025-09-05  41565.3846  43442.3077  42068.0  43487.125  1655.455495   \n",
            "2025-09-08  41314.2308  43145.5769  42021.2  43508.050  1780.363117   \n",
            "2025-09-09  41071.9231  42892.6923  41991.2  43527.675  1758.143664   \n",
            "2025-09-10  40965.7692  42721.3462  42052.1  43559.025  1577.238155   \n",
            "\n",
            "            Max_Gain_from_Open_Current  Max_Gain_from_Open_Lag_1  \\\n",
            "Date                                                               \n",
            "2025-09-04                    0.066463                  0.066463   \n",
            "2025-09-05                    0.036137                  0.066463   \n",
            "2025-09-08                    0.109333                  0.036137   \n",
            "2025-09-09                    0.091623                  0.109333   \n",
            "2025-09-10                    0.074742                  0.091623   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_2  Max_Gain_from_Open_Lag_3  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.056277                  0.018160   \n",
            "2025-09-05                  0.066463                  0.056277   \n",
            "2025-09-08                  0.066463                  0.066463   \n",
            "2025-09-09                  0.036137                  0.066463   \n",
            "2025-09-10                  0.109333                  0.036137   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_4  Max_Gain_from_Open_Lag_5  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.005412                  0.038835   \n",
            "2025-09-05                  0.018160                  0.005412   \n",
            "2025-09-08                  0.056277                  0.018160   \n",
            "2025-09-09                  0.066463                  0.056277   \n",
            "2025-09-10                  0.066463                  0.066463   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_6  Label_raw  Label  \n",
            "Date                                                    \n",
            "2025-09-04                  0.022700          1    1.0  \n",
            "2025-09-05                  0.038835          1    1.0  \n",
            "2025-09-08                  0.005412          1    1.0  \n",
            "2025-09-09                  0.018160          1    0.0  \n",
            "2025-09-10                  0.056277          0    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "Distribucion de etiquetas para YPFD.BA:\n",
            "Label\n",
            "1.0    0.575342\n",
            "0.0    0.424658\n",
            "Name: proportion, dtype: float64\n",
            "Correlacion con label para YPFD.BA:\n",
            "Label                         1.000000\n",
            "close_lag_1                   0.132986\n",
            "high_lag_1                    0.132975\n",
            "open_lag_1                    0.132774\n",
            "high_lag_2                    0.132395\n",
            "close_lag_2                   0.132334\n",
            "SMA5                          0.132331\n",
            "open_lag_2                    0.131957\n",
            "SMA13                         0.131929\n",
            "open_lag_5                    0.131883\n",
            "high_lag_3                    0.131836\n",
            "close_lag_3                   0.131827\n",
            "high_lag_5                    0.131770\n",
            "high_lag_4                    0.131632\n",
            "close_lag_5                   0.131480\n",
            "open_lag_3                    0.131420\n",
            "close_lag_4                   0.131383\n",
            "open_lag_4                    0.131175\n",
            "SMA26                         0.130864\n",
            "SMA50                         0.130188\n",
            "Volatility                    0.128499\n",
            "SMA200                        0.125330\n",
            "Max_Gain_from_Open_Current    0.108198\n",
            "Max_Gain_from_Open_Lag_2      0.077729\n",
            "Max_Gain_from_Open_Lag_1      0.071926\n",
            "Max_Gain_from_Open_Lag_3      0.066303\n",
            "Max_Gain_from_Open_Lag_6      0.063293\n",
            "Max_Gain_from_Open_Lag_4      0.059695\n",
            "Max_Gain_from_Open_Lag_5      0.056471\n",
            "lag_change5                   0.017716\n",
            "EWO_Signal                    0.013076\n",
            "EWO                           0.013044\n",
            "RSI                           0.011890\n",
            "lag_change1                   0.011469\n",
            "ROC                           0.005468\n",
            "PPO_Histogram                 0.005065\n",
            "PPO                           0.003733\n",
            "PPO_Signal                    0.002157\n",
            "EWO_Histogram                 0.002076\n",
            "lag_change2                  -0.002593\n",
            "lag_change4                  -0.003579\n",
            "lag_change3                  -0.006154\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para YPFD.BA\n",
            "Mejores hiperparámetros para YPFD.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for YPFD.BA:\n",
            "Volatility                    0.060235\n",
            "high_lag_4                    0.043127\n",
            "SMA200                        0.042822\n",
            "SMA50                         0.034615\n",
            "Max_Gain_from_Open_Current    0.033792\n",
            "SMA26                         0.030055\n",
            "open_lag_5                    0.028975\n",
            "high_lag_1                    0.028387\n",
            "high_lag_3                    0.025680\n",
            "open_lag_1                    0.025404\n",
            "close_lag_5                   0.023675\n",
            "high_lag_5                    0.022567\n",
            "close_lag_3                   0.022445\n",
            "SMA13                         0.022335\n",
            "open_lag_2                    0.021929\n",
            "ROC                           0.021859\n",
            "close_lag_2                   0.021829\n",
            "Max_Gain_from_Open_Lag_6      0.021794\n",
            "Max_Gain_from_Open_Lag_2      0.021789\n",
            "EWO_Signal                    0.021716\n",
            "close_lag_4                   0.021714\n",
            "close_lag_1                   0.021633\n",
            "high_lag_2                    0.021532\n",
            "PPO_Histogram                 0.021431\n",
            "Max_Gain_from_Open_Lag_4      0.021005\n",
            "PPO                           0.020944\n",
            "EWO                           0.020711\n",
            "lag_change3                   0.020680\n",
            "PPO_Signal                    0.020559\n",
            "Max_Gain_from_Open_Lag_1      0.020378\n",
            "RSI                           0.020368\n",
            "lag_change4                   0.020360\n",
            "open_lag_4                    0.020237\n",
            "open_lag_3                    0.020109\n",
            "Max_Gain_from_Open_Lag_5      0.019811\n",
            "EWO_Histogram                 0.019626\n",
            "lag_change2                   0.019406\n",
            "lag_change1                   0.018910\n",
            "lag_change5                   0.018750\n",
            "Max_Gain_from_Open_Lag_3      0.018694\n",
            "SMA5                          0.018113\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum Precision (Clase 1) on training data for YPFD.BA...\n",
            "Mejor umbral para maximizar Precision (Clase 1) en entrenamiento para YPFD.BA: 0.6100 (Precision: 1.0000)\n",
            "\n",
            "Evaluating best model on test set for YPFD.BA with best threshold (0.6100):\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.26      0.20       102\n",
            "         1.0       0.79      0.66      0.72       416\n",
            "\n",
            "    accuracy                           0.58       518\n",
            "   macro avg       0.47      0.46      0.46       518\n",
            "weighted avg       0.66      0.58      0.62       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para YPFD.BA:\n",
            "Label\n",
            "1.0    416\n",
            "0.0    102\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para YPFD.BA: 0.8031 \n",
            "\n",
            "ROC-AUC (Test Set) para YPFD.BA: 0.4301\n",
            "     Papel Fecha Predicción Fecha Datos Predicción  \\\n",
            "0  ALUA.BA       2025-09-15  2025-09-10    Alcista   \n",
            "1  BBAR.BA       2025-09-15  2025-09-10    Alcista   \n",
            "2  METR.BA       2025-09-15  2025-09-10    Alcista   \n",
            "3  PAMP.BA       2025-09-15  2025-09-10    Alcista   \n",
            "4  TRAN.BA       2025-09-15  2025-09-10    Alcista   \n",
            "5  YPFD.BA       2025-09-15  2025-09-10    Alcista   \n",
            "\n",
            "   Probabilidad Alcista (Modelo)  Umbral de Clasificación  \\\n",
            "0                         0.6907                     0.53   \n",
            "1                         0.8137                     0.57   \n",
            "2                         0.9124                     0.63   \n",
            "3                         0.7236                     0.50   \n",
            "4                         0.6291                     0.57   \n",
            "5                         0.7976                     0.61   \n",
            "\n",
            "                                                                                               Mejores hiperparámetros (Incluye scale_pos_weight)  \\\n",
            "0  {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
            "1  {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
            "2  {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
            "3  {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
            "4  {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
            "5  {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
            "\n",
            "   Precision Test (Alcista)  Recall Test (Alcista)  F1 Test (Alcista)  \\\n",
            "0                  0.777083               0.937186           0.849658   \n",
            "1                  0.864603               0.997768           0.926425   \n",
            "2                  0.876068               0.917226           0.896175   \n",
            "3                  0.797101               0.929952           0.858417   \n",
            "4                  0.843552               0.913043           0.876923   \n",
            "5                  0.785714               0.661058           0.718016   \n",
            "\n",
            "   ROC-AUC Test  clase 1 en test (cleaned)  \\\n",
            "0      0.573765                     0.7683   \n",
            "1      0.441040                     0.8649   \n",
            "2      0.548981                     0.8629   \n",
            "3      0.504575                     0.7992   \n",
            "4      0.496850                     0.8436   \n",
            "5      0.430147                     0.8031   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Features Limpias (Predicción)  \\\n",
            "0                         {'RSI': {2025-09-10 00:00:00: 22.02380952380952}, 'ROC': {2025-09-10 00:00:00: 0.2857142857142857}, 'PPO': {2025-09-10 00:00:00: -0.4910590194243401}, 'PPO_Signal': {2025-09-10 00:00:00: -0.44710124137936935}, 'PPO_Histogram': {2025-09-10 00:00:00: -0.04395777804497075}, 'EWO': {2025-09-10 00:00:00: -1.4486191078044606}, 'EWO_Signal': {2025-09-10 00:00:00: -1.111244869861243}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.33737423794321764}, 'Volatility': {2025-09-10 00:00:00: 20.12283}, 'SMA5': {2025-09-10 00:00:00: 694.9}, 'SMA13': {2025-09-10 00:00:00: 711.9615}, 'SMA26': {2025-09-10 00:00:00: 710.0577}, 'SMA50': {2025-09-10 00:00:00: 713.85}, 'SMA200': {2025-09-10 00:00:00: 784.9925}, 'lag_change1': {2025-09-10 00:00:00: -0.003589375448671883}, 'lag_change2': {2025-09-10 00:00:00: 0.015306122448979664}, 'lag_change3': {2025-09-10 00:00:00: -0.014367816091954033}, 'lag_change4': {2025-09-10 00:00:00: -0.005714285714285672}, 'lag_change5': {2025-09-10 00:00:00: -0.051490514905149}, 'close_lag_1': {2025-09-10 00:00:00: 694.0}, 'close_lag_2': {2025-09-10 00:00:00: 696.5}, 'close_lag_3': {2025-09-10 00:00:00: 686.0}, 'close_lag_4': {2025-09-10 00:00:00: 696.0}, 'close_lag_5': {2025-09-10 00:00:00: 700.0}, 'open_lag_1': {2025-09-10 00:00:00: 700.0}, 'open_lag_2': {2025-09-10 00:00:00: 670.0}, 'open_lag_3': {2025-09-10 00:00:00: 680.0}, 'open_lag_4': {2025-09-10 00:00:00: 710.0}, 'open_lag_5': {2025-09-10 00:00:00: 735.0}, 'high_lag_1': {2025-09-10 00:00:00: 713.0}, 'high_lag_2': {2025-09-10 00:00:00: 705.0}, 'high_lag_3': {2025-09-10 00:00:00: 696.0}, 'high_lag_4': {2025-09-10 00:00:00: 717.0}, 'high_lag_5': {2025-09-10 00:00:00: 742.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.0235714285713949}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.0235714285713949}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.06940298507452328}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.04852941176463452}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.009859154929563579}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.009523809523796566}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.003994673768303602}}   \n",
            "1                                     {'RSI': {2025-09-10 00:00:00: 32.53012048192771}, 'ROC': {2025-09-10 00:00:00: -15.974729241877256}, 'PPO': {2025-09-10 00:00:00: -5.3389766580011075}, 'PPO_Signal': {2025-09-10 00:00:00: -4.3361629455140625}, 'PPO_Histogram': {2025-09-10 00:00:00: -1.002813712487045}, 'EWO': {2025-09-10 00:00:00: -19.51935321956679}, 'EWO_Signal': {2025-09-10 00:00:00: -16.528431983648822}, 'EWO_Histogram': {2025-09-10 00:00:00: -2.990921235917966}, 'Volatility': {2025-09-10 00:00:00: 773.324792}, 'SMA5': {2025-09-10 00:00:00: 4984.5}, 'SMA13': {2025-09-10 00:00:00: 5360.9615}, 'SMA26': {2025-09-10 00:00:00: 6177.7885}, 'SMA50': {2025-09-10 00:00:00: 6404.85}, 'SMA200': {2025-09-10 00:00:00: 7363.8125}, 'lag_change1': {2025-09-10 00:00:00: -0.023849140321686058}, 'lag_change2': {2025-09-10 00:00:00: -0.20079787234042556}, 'lag_change3': {2025-09-10 00:00:00: -0.013986013986013957}, 'lag_change4': {2025-09-10 00:00:00: 0.032490974729241895}, 'lag_change5': {2025-09-10 00:00:00: -0.014234875444839812}, 'close_lag_1': {2025-09-10 00:00:00: 4400.0}, 'close_lag_2': {2025-09-10 00:00:00: 4507.5}, 'close_lag_3': {2025-09-10 00:00:00: 5640.0}, 'close_lag_4': {2025-09-10 00:00:00: 5720.0}, 'close_lag_5': {2025-09-10 00:00:00: 5540.0}, 'open_lag_1': {2025-09-10 00:00:00: 4600.0}, 'open_lag_2': {2025-09-10 00:00:00: 5175.0}, 'open_lag_3': {2025-09-10 00:00:00: 5840.0}, 'open_lag_4': {2025-09-10 00:00:00: 5580.0}, 'open_lag_5': {2025-09-10 00:00:00: 5650.0}, 'high_lag_1': {2025-09-10 00:00:00: 4650.0}, 'high_lag_2': {2025-09-10 00:00:00: 5175.0}, 'high_lag_3': {2025-09-10 00:00:00: 5840.0}, 'high_lag_4': {2025-09-10 00:00:00: 5850.0}, 'high_lag_5': {2025-09-10 00:00:00: 5690.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.043956043956034294}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.03260869565216682}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.04838709677418487}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.03539823008848931}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.08534322820035521}}   \n",
            "2        {'RSI': {2025-09-10 00:00:00: 35.102739726027394}, 'ROC': {2025-09-10 00:00:00: -5.429553264604811}, 'PPO': {2025-09-10 00:00:00: -5.1254883136060885}, 'PPO_Signal': {2025-09-10 00:00:00: -5.245569085162645}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.12008077155655617}, 'EWO': {2025-09-10 00:00:00: -21.51889874854952}, 'EWO_Signal': {2025-09-10 00:00:00: -19.964037042024817}, 'EWO_Histogram': {2025-09-10 00:00:00: -1.5548617065247043}, 'Volatility': {2025-09-10 00:00:00: 249.501376}, 'SMA5': {2025-09-10 00:00:00: 1377.4}, 'SMA13': {2025-09-10 00:00:00: 1519.7692}, 'SMA26': {2025-09-10 00:00:00: 1799.3077}, 'SMA50': {2025-09-10 00:00:00: 1889.84}, 'SMA200': {2025-09-10 00:00:00: 2188.235}, 'lag_change1': {2025-09-10 00:00:00: -0.034375000000000044}, 'lag_change2': {2025-09-10 00:00:00: -0.1578947368421053}, 'lag_change3': {2025-09-10 00:00:00: 0.03050847457627115}, 'lag_change4': {2025-09-10 00:00:00: 0.013745704467353903}, 'lag_change5': {2025-09-10 00:00:00: -0.03642384105960261}, 'close_lag_1': {2025-09-10 00:00:00: 1236.0}, 'close_lag_2': {2025-09-10 00:00:00: 1280.0}, 'close_lag_3': {2025-09-10 00:00:00: 1520.0}, 'close_lag_4': {2025-09-10 00:00:00: 1475.0}, 'close_lag_5': {2025-09-10 00:00:00: 1455.0}, 'open_lag_1': {2025-09-10 00:00:00: 1310.0}, 'open_lag_2': {2025-09-10 00:00:00: 1360.0}, 'open_lag_3': {2025-09-10 00:00:00: 1500.0}, 'open_lag_4': {2025-09-10 00:00:00: 1455.0}, 'open_lag_5': {2025-09-10 00:00:00: 1520.0}, 'high_lag_1': {2025-09-10 00:00:00: 1330.0}, 'high_lag_2': {2025-09-10 00:00:00: 1405.0}, 'high_lag_3': {2025-09-10 00:00:00: 1550.0}, 'high_lag_4': {2025-09-10 00:00:00: 1515.0}, 'high_lag_5': {2025-09-10 00:00:00: 1550.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.11653543307077438}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.08244274809154012}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.03308823529409332}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.033333333333311115}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.0652920962198864}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.019736842105250174}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.012820512820504603}}   \n",
            "3                                {'RSI': {2025-09-10 00:00:00: 52.18446601941748}, 'ROC': {2025-09-10 00:00:00: -0.8310249307479225}, 'PPO': {2025-09-10 00:00:00: -1.147398945157694}, 'PPO_Signal': {2025-09-10 00:00:00: -1.1962556510418119}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.048856705884117835}, 'EWO': {2025-09-10 00:00:00: -4.905880769374763}, 'EWO_Signal': {2025-09-10 00:00:00: -4.489529457552637}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.41635131182212604}, 'Volatility': {2025-09-10 00:00:00: 172.085696}, 'SMA5': {2025-09-10 00:00:00: 3541.0}, 'SMA13': {2025-09-10 00:00:00: 3589.6154}, 'SMA26': {2025-09-10 00:00:00: 3775.0}, 'SMA50': {2025-09-10 00:00:00: 3754.2}, 'SMA200': {2025-09-10 00:00:00: 3819.95}, 'lag_change1': {2025-09-10 00:00:00: 0.032134659525631326}, 'lag_change2': {2025-09-10 00:00:00: -0.13098404255319152}, 'lag_change3': {2025-09-10 00:00:00: 0.00939597315436247}, 'lag_change4': {2025-09-10 00:00:00: 0.03185595567867039}, 'lag_change5': {2025-09-10 00:00:00: 0.0}, 'close_lag_1': {2025-09-10 00:00:00: 3372.5}, 'close_lag_2': {2025-09-10 00:00:00: 3267.5}, 'close_lag_3': {2025-09-10 00:00:00: 3760.0}, 'close_lag_4': {2025-09-10 00:00:00: 3725.0}, 'close_lag_5': {2025-09-10 00:00:00: 3610.0}, 'open_lag_1': {2025-09-10 00:00:00: 3320.0}, 'open_lag_2': {2025-09-10 00:00:00: 3452.5}, 'open_lag_3': {2025-09-10 00:00:00: 3680.0}, 'open_lag_4': {2025-09-10 00:00:00: 3610.0}, 'open_lag_5': {2025-09-10 00:00:00: 3520.0}, 'high_lag_1': {2025-09-10 00:00:00: 3440.0}, 'high_lag_2': {2025-09-10 00:00:00: 3452.5}, 'high_lag_3': {2025-09-10 00:00:00: 3850.0}, 'high_lag_4': {2025-09-10 00:00:00: 3755.0}, 'high_lag_5': {2025-09-10 00:00:00: 3680.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.07863501483677192}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.09487951807226058}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.04996379435190443}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.04619565217390049}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.06648199445981538}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.09374999999997337}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.05329593267880693}}   \n",
            "4                                                       {'RSI': {2025-09-10 00:00:00: 25.60386473429952}, 'ROC': {2025-09-10 00:00:00: 3.6641221374045805}, 'PPO': {2025-09-10 00:00:00: -3.726008383735165}, 'PPO_Signal': {2025-09-10 00:00:00: -4.4009672295842925}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.6749588458491274}, 'EWO': {2025-09-10 00:00:00: -13.971037469616455}, 'EWO_Signal': {2025-09-10 00:00:00: -13.05087452217676}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.9201629474396942}, 'Volatility': {2025-09-10 00:00:00: 274.809499}, 'SMA5': {2025-09-10 00:00:00: 1949.2}, 'SMA13': {2025-09-10 00:00:00: 2193.5385}, 'SMA26': {2025-09-10 00:00:00: 2406.1923}, 'SMA50': {2025-09-10 00:00:00: 2387.92}, 'SMA200': {2025-09-10 00:00:00: 2395.905}, 'lag_change1': {2025-09-10 00:00:00: 0.02814657461497605}, 'lag_change2': {2025-09-10 00:00:00: -0.019270833333333348}, 'lag_change3': {2025-09-10 00:00:00: -0.025380710659898442}, 'lag_change4': {2025-09-10 00:00:00: 0.0025445292620864812}, 'lag_change5': {2025-09-10 00:00:00: -0.14192139737991272}, 'close_lag_1': {2025-09-10 00:00:00: 1936.0}, 'close_lag_2': {2025-09-10 00:00:00: 1883.0}, 'close_lag_3': {2025-09-10 00:00:00: 1920.0}, 'close_lag_4': {2025-09-10 00:00:00: 1970.0}, 'close_lag_5': {2025-09-10 00:00:00: 1965.0}, 'open_lag_1': {2025-09-10 00:00:00: 1940.0}, 'open_lag_2': {2025-09-10 00:00:00: 1770.0}, 'open_lag_3': {2025-09-10 00:00:00: 2000.0}, 'open_lag_4': {2025-09-10 00:00:00: 1990.0}, 'open_lag_5': {2025-09-10 00:00:00: 2050.0}, 'high_lag_1': {2025-09-10 00:00:00: 1940.0}, 'high_lag_2': {2025-09-10 00:00:00: 1910.0}, 'high_lag_3': {2025-09-10 00:00:00: 2000.0}, 'high_lag_4': {2025-09-10 00:00:00: 2030.0}, 'high_lag_5': {2025-09-10 00:00:00: 2050.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.047979797979773746}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.06958762886594351}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.15819209039539087}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.020100502512552715}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.0}}   \n",
            "5  {'RSI': {2025-09-10 00:00:00: 52.68}, 'ROC': {2025-09-10 00:00:00: 1.156211562115621}, 'PPO': {2025-09-10 00:00:00: -0.8772394184206476}, 'PPO_Signal': {2025-09-10 00:00:00: -0.9259591218197915}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.04871970339914389}, 'EWO': {2025-09-10 00:00:00: -3.672196515494028}, 'EWO_Signal': {2025-09-10 00:00:00: -3.3490853662592004}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.32311114923482753}, 'Volatility': {2025-09-10 00:00:00: 1577.238155}, 'SMA5': {2025-09-10 00:00:00: 40596.0}, 'SMA13': {2025-09-10 00:00:00: 40965.7692}, 'SMA26': {2025-09-10 00:00:00: 42721.3462}, 'SMA50': {2025-09-10 00:00:00: 42052.1}, 'SMA200': {2025-09-10 00:00:00: 43559.025}, 'lag_change1': {2025-09-10 00:00:00: 0.01954569466455358}, 'lag_change2': {2025-09-10 00:00:00: -0.11696793002915451}, 'lag_change3': {2025-09-10 00:00:00: 0.008230452674897082}, 'lag_change4': {2025-09-10 00:00:00: 0.046125461254612476}, 'lag_change5': {2025-09-10 00:00:00: -0.02166064981949456}, 'close_lag_1': {2025-09-10 00:00:00: 38600.0}, 'close_lag_2': {2025-09-10 00:00:00: 37860.0}, 'close_lag_3': {2025-09-10 00:00:00: 42875.0}, 'close_lag_4': {2025-09-10 00:00:00: 42525.0}, 'close_lag_5': {2025-09-10 00:00:00: 40650.0}, 'open_lag_1': {2025-09-10 00:00:00: 38200.0}, 'open_lag_2': {2025-09-10 00:00:00: 37500.0}, 'open_lag_3': {2025-09-10 00:00:00: 42200.0}, 'open_lag_4': {2025-09-10 00:00:00: 41000.0}, 'open_lag_5': {2025-09-10 00:00:00: 41000.0}, 'high_lag_1': {2025-09-10 00:00:00: 40060.0}, 'high_lag_2': {2025-09-10 00:00:00: 39740.0}, 'high_lag_3': {2025-09-10 00:00:00: 43725.0}, 'high_lag_4': {2025-09-10 00:00:00: 42700.0}, 'high_lag_5': {2025-09-10 00:00:00: 42050.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.0747422680412352}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.09162303664921227}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.10933333333333042}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.036137440758292984}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.06646341463414472}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.06646341463414472}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.05627705627705489}}   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Features Escaladas (Predicción)  \n",
            "0  [-0.7818634853518561, 0.044757316601609594, -0.3832495566899804, -0.3924117529798455, -0.06086068095672429, -0.31706707436920106, -0.2703206224154513, -0.19779355102866564, 30.043158689979204, 52.73595848595849, 54.12918563364025, 54.0415509285829, 55.258611297025546, 67.69170730862187, -0.14348649757668872, 0.6112720219450265, -0.5736788385325617, -0.22783784833429088, -2.056347795594639, 52.64302059496568, 53.03598774885146, 52.23200612557427, 53.09934790947449, 53.61185983827493, 53.40621403912543, 51.202920830130665, 51.971560338201385, 54.277478862413524, 56.307277628032345, 52.50721954831545, 52.011127596439174, 51.63148079074972, 53.497374343585896, 55.3728432108027, 0.09437239351118115, 0.09441297184839482, 1.4271685027261352, 0.8201706870964343, -0.30434982888093587, -0.31410158176771164, -0.4751226744059963]  \n",
            "1                  [-0.5563744682079752, -2.007197656994868, -2.76833937912835, -2.476760723952092, -1.4372688784040728, -2.33958696404983, -2.070297733948386, -1.6887037198218429, 155.00641285592303, 51.59512741761435, 56.131931210490535, 64.69844242022965, 67.99798653435019, 72.7667965570392, -0.7265931849854965, -6.115559915879347, -0.4255501722409742, 0.9894397549657818, -0.4335416140785042, 45.28714812808009, 46.432824644305015, 58.163131378374885, 59.11360811930406, 57.42790359443175, 47.10431211498973, 53.08001130901894, 60.01091489471245, 57.37798845836768, 58.13378702343206, 46.95259547973982, 52.30331273427211, 59.044705047997766, 59.177496198682206, 57.57456840824396, 0.3623632910310479, 0.11047432367939544, -0.6138382151584646, -0.6138382151584646, 0.45969386862171524, 0.17163887669039912, 1.2792725431247385]  \n",
            "2                [-0.3745054107419694, -0.6281336396776755, -2.4760340510803056, -2.7628097855284848, 0.21161290719391843, -2.046821128313282, -1.9426993515867141, -0.7967262027254606, 336.6923973355626, 82.17211107793372, 91.01752208994233, 108.03069587737272, 110.79358737422626, 137.21438229600977, -1.030963541666669, -4.735526315789479, 0.9149999999999996, 0.4122565864833895, -1.0924116997792492, 73.58545671285948, 76.37873357228196, 90.71565113500598, 88.09325960245106, 87.09286998202518, 77.65994065281897, 80.62729970326409, 88.93590504451038, 86.26528189910978, 90.12284866468842, 77.55691768826618, 81.99503432160068, 90.66451990632318, 88.61533957845432, 90.73092134173135, 1.5858042500195857, 0.9882026375871523, 0.12351052107326538, 0.1287878789129126, 0.6880662296960662, -0.10817109358234392, -0.22920685607230776]  \n",
            "3                                         [-0.04414008902657611, -0.17823592746776742, -0.6855155997616817, -0.780649419113242, 0.0780532225507881, -0.8009510325615006, -0.7884736687961438, -0.21971376040656387, 77.2307268349907, 77.73587477465593, 78.73939154310818, 83.15648332160637, 83.33579025751025, 84.14454141684055, 1.0506682476692275, -4.282627433852966, 0.3072088142513833, 1.0415558037588895, 0.0, 74.19654070728214, 71.92283950617283, 82.87199293754139, 82.19067609368095, 79.65046398585949, 73.09592061742006, 76.00948076287068, 81.01675485008819, 79.47420634920634, 77.57559037740013, 73.69981761613562, 74.04897433143593, 82.63163550397594, 80.59015688802924, 79.06411359724613, 1.1622238090724453, 1.5087478734552227, 0.523221421139541, 0.4401811750513594, 0.8793396784865425, 1.4682448768184122, 0.592417013183931]  \n",
            "4                 [-0.6147590916174369, 0.408684110413545, -1.6823539333465318, -2.1347188360569342, 0.9451253132079582, -1.3991407534907576, -1.3157831341465105, -0.4192381922057084, 255.05107098244065, 85.59871659634321, 95.96703152364275, 103.82942010868511, 102.21913137344772, 101.89573358867963, 0.8724283345423732, -0.5973167698103562, -0.7866978995993149, 0.07886996754252583, -4.394355239670768, 85.02593406593407, 82.69626373626373, 84.32263736263737, 86.52043956043956, 86.30065934065934, 84.7917760279965, 77.35520559930009, 87.416447944007, 87.07422815852857, 89.80008768084173, 83.31442080378248, 82.11316695352839, 85.98580034423406, 87.27667814113596, 88.13726333907056, 0.42428934062640505, 0.8505118477899479, 2.5946018206728714, -0.5254051561276185, -0.12896493007326018, -0.5256687099526277, -0.5261359703453173]  \n",
            "5         [-0.029614419944876184, 0.09918919765174586, -0.6781460952282776, -0.7559840974273326, 0.09703139220566527, -0.6861214233390261, -0.6601505490191427, -0.21067204240307297, 91.51343809283078, 132.67664533070737, 133.60011417233736, 138.77738202887585, 134.0727156607819, 166.83783792357391, 0.7717961991695983, -4.618684849556809, 0.3249939283790559, 1.8213451244490504, -0.8556014077880957, 125.92028184015403, 123.52044579201834, 140.0508405084051, 139.07960096884108, 132.9490022172949, 124.29903563255967, 122.14129100875398, 137.765110847027, 133.84827868852457, 133.8488524590164, 127.52038369304556, 126.80128205128206, 139.57371794871796, 136.38681741640607, 134.60419512979183, 1.4887356084071173, 1.9454401748438521, 2.4264586733465277, 0.4347708688522255, 1.260602487950169, 1.26212669729396, 0.9854584453082402]  \n",
            "\n",
            "Prediccion para el proximo dia (hasta 2025-09-15 ):\n",
            "Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    Papel Fecha Datos Predicción  \\\n",
              "Fecha Predicción                                   \n",
              "2025-09-15        ALUA.BA  2025-09-10    Alcista   \n",
              "2025-09-15        BBAR.BA  2025-09-10    Alcista   \n",
              "2025-09-15        METR.BA  2025-09-10    Alcista   \n",
              "2025-09-15        PAMP.BA  2025-09-10    Alcista   \n",
              "2025-09-15        TRAN.BA  2025-09-10    Alcista   \n",
              "2025-09-15        YPFD.BA  2025-09-10    Alcista   \n",
              "\n",
              "                  Probabilidad Alcista (Modelo)  Umbral de Clasificación  \\\n",
              "Fecha Predicción                                                           \n",
              "2025-09-15                               0.6907                     0.53   \n",
              "2025-09-15                               0.8137                     0.57   \n",
              "2025-09-15                               0.9124                     0.63   \n",
              "2025-09-15                               0.7236                     0.50   \n",
              "2025-09-15                               0.6291                     0.57   \n",
              "2025-09-15                               0.7976                     0.61   \n",
              "\n",
              "                                                                                                              Mejores hiperparámetros (Incluye scale_pos_weight)  \\\n",
              "Fecha Predicción                                                                                                                                                   \n",
              "2025-09-15        {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
              "2025-09-15        {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
              "2025-09-15        {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
              "2025-09-15        {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
              "2025-09-15        {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
              "2025-09-15        {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}   \n",
              "\n",
              "                  Precision Test (Alcista)  Recall Test (Alcista)  \\\n",
              "Fecha Predicción                                                    \n",
              "2025-09-15                        0.777083               0.937186   \n",
              "2025-09-15                        0.864603               0.997768   \n",
              "2025-09-15                        0.876068               0.917226   \n",
              "2025-09-15                        0.797101               0.929952   \n",
              "2025-09-15                        0.843552               0.913043   \n",
              "2025-09-15                        0.785714               0.661058   \n",
              "\n",
              "                  F1 Test (Alcista)  ROC-AUC Test  clase 1 en test (cleaned)  \\\n",
              "Fecha Predicción                                                               \n",
              "2025-09-15                 0.849658      0.573765                     0.7683   \n",
              "2025-09-15                 0.926425      0.441040                     0.8649   \n",
              "2025-09-15                 0.896175      0.548981                     0.8629   \n",
              "2025-09-15                 0.858417      0.504575                     0.7992   \n",
              "2025-09-15                 0.876923      0.496850                     0.8436   \n",
              "2025-09-15                 0.718016      0.430147                     0.8031   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Features Limpias (Predicción)  \\\n",
              "Fecha Predicción                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "2025-09-15                               {'RSI': {2025-09-10 00:00:00: 22.02380952380952}, 'ROC': {2025-09-10 00:00:00: 0.2857142857142857}, 'PPO': {2025-09-10 00:00:00: -0.4910590194243401}, 'PPO_Signal': {2025-09-10 00:00:00: -0.44710124137936935}, 'PPO_Histogram': {2025-09-10 00:00:00: -0.04395777804497075}, 'EWO': {2025-09-10 00:00:00: -1.4486191078044606}, 'EWO_Signal': {2025-09-10 00:00:00: -1.111244869861243}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.33737423794321764}, 'Volatility': {2025-09-10 00:00:00: 20.12283}, 'SMA5': {2025-09-10 00:00:00: 694.9}, 'SMA13': {2025-09-10 00:00:00: 711.9615}, 'SMA26': {2025-09-10 00:00:00: 710.0577}, 'SMA50': {2025-09-10 00:00:00: 713.85}, 'SMA200': {2025-09-10 00:00:00: 784.9925}, 'lag_change1': {2025-09-10 00:00:00: -0.003589375448671883}, 'lag_change2': {2025-09-10 00:00:00: 0.015306122448979664}, 'lag_change3': {2025-09-10 00:00:00: -0.014367816091954033}, 'lag_change4': {2025-09-10 00:00:00: -0.005714285714285672}, 'lag_change5': {2025-09-10 00:00:00: -0.051490514905149}, 'close_lag_1': {2025-09-10 00:00:00: 694.0}, 'close_lag_2': {2025-09-10 00:00:00: 696.5}, 'close_lag_3': {2025-09-10 00:00:00: 686.0}, 'close_lag_4': {2025-09-10 00:00:00: 696.0}, 'close_lag_5': {2025-09-10 00:00:00: 700.0}, 'open_lag_1': {2025-09-10 00:00:00: 700.0}, 'open_lag_2': {2025-09-10 00:00:00: 670.0}, 'open_lag_3': {2025-09-10 00:00:00: 680.0}, 'open_lag_4': {2025-09-10 00:00:00: 710.0}, 'open_lag_5': {2025-09-10 00:00:00: 735.0}, 'high_lag_1': {2025-09-10 00:00:00: 713.0}, 'high_lag_2': {2025-09-10 00:00:00: 705.0}, 'high_lag_3': {2025-09-10 00:00:00: 696.0}, 'high_lag_4': {2025-09-10 00:00:00: 717.0}, 'high_lag_5': {2025-09-10 00:00:00: 742.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.0235714285713949}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.0235714285713949}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.06940298507452328}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.04852941176463452}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.009859154929563579}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.009523809523796566}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.003994673768303602}}   \n",
              "2025-09-15                                           {'RSI': {2025-09-10 00:00:00: 32.53012048192771}, 'ROC': {2025-09-10 00:00:00: -15.974729241877256}, 'PPO': {2025-09-10 00:00:00: -5.3389766580011075}, 'PPO_Signal': {2025-09-10 00:00:00: -4.3361629455140625}, 'PPO_Histogram': {2025-09-10 00:00:00: -1.002813712487045}, 'EWO': {2025-09-10 00:00:00: -19.51935321956679}, 'EWO_Signal': {2025-09-10 00:00:00: -16.528431983648822}, 'EWO_Histogram': {2025-09-10 00:00:00: -2.990921235917966}, 'Volatility': {2025-09-10 00:00:00: 773.324792}, 'SMA5': {2025-09-10 00:00:00: 4984.5}, 'SMA13': {2025-09-10 00:00:00: 5360.9615}, 'SMA26': {2025-09-10 00:00:00: 6177.7885}, 'SMA50': {2025-09-10 00:00:00: 6404.85}, 'SMA200': {2025-09-10 00:00:00: 7363.8125}, 'lag_change1': {2025-09-10 00:00:00: -0.023849140321686058}, 'lag_change2': {2025-09-10 00:00:00: -0.20079787234042556}, 'lag_change3': {2025-09-10 00:00:00: -0.013986013986013957}, 'lag_change4': {2025-09-10 00:00:00: 0.032490974729241895}, 'lag_change5': {2025-09-10 00:00:00: -0.014234875444839812}, 'close_lag_1': {2025-09-10 00:00:00: 4400.0}, 'close_lag_2': {2025-09-10 00:00:00: 4507.5}, 'close_lag_3': {2025-09-10 00:00:00: 5640.0}, 'close_lag_4': {2025-09-10 00:00:00: 5720.0}, 'close_lag_5': {2025-09-10 00:00:00: 5540.0}, 'open_lag_1': {2025-09-10 00:00:00: 4600.0}, 'open_lag_2': {2025-09-10 00:00:00: 5175.0}, 'open_lag_3': {2025-09-10 00:00:00: 5840.0}, 'open_lag_4': {2025-09-10 00:00:00: 5580.0}, 'open_lag_5': {2025-09-10 00:00:00: 5650.0}, 'high_lag_1': {2025-09-10 00:00:00: 4650.0}, 'high_lag_2': {2025-09-10 00:00:00: 5175.0}, 'high_lag_3': {2025-09-10 00:00:00: 5840.0}, 'high_lag_4': {2025-09-10 00:00:00: 5850.0}, 'high_lag_5': {2025-09-10 00:00:00: 5690.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.043956043956034294}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.03260869565216682}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.04838709677418487}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.03539823008848931}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.08534322820035521}}   \n",
              "2025-09-15              {'RSI': {2025-09-10 00:00:00: 35.102739726027394}, 'ROC': {2025-09-10 00:00:00: -5.429553264604811}, 'PPO': {2025-09-10 00:00:00: -5.1254883136060885}, 'PPO_Signal': {2025-09-10 00:00:00: -5.245569085162645}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.12008077155655617}, 'EWO': {2025-09-10 00:00:00: -21.51889874854952}, 'EWO_Signal': {2025-09-10 00:00:00: -19.964037042024817}, 'EWO_Histogram': {2025-09-10 00:00:00: -1.5548617065247043}, 'Volatility': {2025-09-10 00:00:00: 249.501376}, 'SMA5': {2025-09-10 00:00:00: 1377.4}, 'SMA13': {2025-09-10 00:00:00: 1519.7692}, 'SMA26': {2025-09-10 00:00:00: 1799.3077}, 'SMA50': {2025-09-10 00:00:00: 1889.84}, 'SMA200': {2025-09-10 00:00:00: 2188.235}, 'lag_change1': {2025-09-10 00:00:00: -0.034375000000000044}, 'lag_change2': {2025-09-10 00:00:00: -0.1578947368421053}, 'lag_change3': {2025-09-10 00:00:00: 0.03050847457627115}, 'lag_change4': {2025-09-10 00:00:00: 0.013745704467353903}, 'lag_change5': {2025-09-10 00:00:00: -0.03642384105960261}, 'close_lag_1': {2025-09-10 00:00:00: 1236.0}, 'close_lag_2': {2025-09-10 00:00:00: 1280.0}, 'close_lag_3': {2025-09-10 00:00:00: 1520.0}, 'close_lag_4': {2025-09-10 00:00:00: 1475.0}, 'close_lag_5': {2025-09-10 00:00:00: 1455.0}, 'open_lag_1': {2025-09-10 00:00:00: 1310.0}, 'open_lag_2': {2025-09-10 00:00:00: 1360.0}, 'open_lag_3': {2025-09-10 00:00:00: 1500.0}, 'open_lag_4': {2025-09-10 00:00:00: 1455.0}, 'open_lag_5': {2025-09-10 00:00:00: 1520.0}, 'high_lag_1': {2025-09-10 00:00:00: 1330.0}, 'high_lag_2': {2025-09-10 00:00:00: 1405.0}, 'high_lag_3': {2025-09-10 00:00:00: 1550.0}, 'high_lag_4': {2025-09-10 00:00:00: 1515.0}, 'high_lag_5': {2025-09-10 00:00:00: 1550.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.11653543307077438}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.08244274809154012}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.03308823529409332}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.033333333333311115}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.0652920962198864}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.019736842105250174}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.012820512820504603}}   \n",
              "2025-09-15                                      {'RSI': {2025-09-10 00:00:00: 52.18446601941748}, 'ROC': {2025-09-10 00:00:00: -0.8310249307479225}, 'PPO': {2025-09-10 00:00:00: -1.147398945157694}, 'PPO_Signal': {2025-09-10 00:00:00: -1.1962556510418119}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.048856705884117835}, 'EWO': {2025-09-10 00:00:00: -4.905880769374763}, 'EWO_Signal': {2025-09-10 00:00:00: -4.489529457552637}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.41635131182212604}, 'Volatility': {2025-09-10 00:00:00: 172.085696}, 'SMA5': {2025-09-10 00:00:00: 3541.0}, 'SMA13': {2025-09-10 00:00:00: 3589.6154}, 'SMA26': {2025-09-10 00:00:00: 3775.0}, 'SMA50': {2025-09-10 00:00:00: 3754.2}, 'SMA200': {2025-09-10 00:00:00: 3819.95}, 'lag_change1': {2025-09-10 00:00:00: 0.032134659525631326}, 'lag_change2': {2025-09-10 00:00:00: -0.13098404255319152}, 'lag_change3': {2025-09-10 00:00:00: 0.00939597315436247}, 'lag_change4': {2025-09-10 00:00:00: 0.03185595567867039}, 'lag_change5': {2025-09-10 00:00:00: 0.0}, 'close_lag_1': {2025-09-10 00:00:00: 3372.5}, 'close_lag_2': {2025-09-10 00:00:00: 3267.5}, 'close_lag_3': {2025-09-10 00:00:00: 3760.0}, 'close_lag_4': {2025-09-10 00:00:00: 3725.0}, 'close_lag_5': {2025-09-10 00:00:00: 3610.0}, 'open_lag_1': {2025-09-10 00:00:00: 3320.0}, 'open_lag_2': {2025-09-10 00:00:00: 3452.5}, 'open_lag_3': {2025-09-10 00:00:00: 3680.0}, 'open_lag_4': {2025-09-10 00:00:00: 3610.0}, 'open_lag_5': {2025-09-10 00:00:00: 3520.0}, 'high_lag_1': {2025-09-10 00:00:00: 3440.0}, 'high_lag_2': {2025-09-10 00:00:00: 3452.5}, 'high_lag_3': {2025-09-10 00:00:00: 3850.0}, 'high_lag_4': {2025-09-10 00:00:00: 3755.0}, 'high_lag_5': {2025-09-10 00:00:00: 3680.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.07863501483677192}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.09487951807226058}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.04996379435190443}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.04619565217390049}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.06648199445981538}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.09374999999997337}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.05329593267880693}}   \n",
              "2025-09-15                                                             {'RSI': {2025-09-10 00:00:00: 25.60386473429952}, 'ROC': {2025-09-10 00:00:00: 3.6641221374045805}, 'PPO': {2025-09-10 00:00:00: -3.726008383735165}, 'PPO_Signal': {2025-09-10 00:00:00: -4.4009672295842925}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.6749588458491274}, 'EWO': {2025-09-10 00:00:00: -13.971037469616455}, 'EWO_Signal': {2025-09-10 00:00:00: -13.05087452217676}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.9201629474396942}, 'Volatility': {2025-09-10 00:00:00: 274.809499}, 'SMA5': {2025-09-10 00:00:00: 1949.2}, 'SMA13': {2025-09-10 00:00:00: 2193.5385}, 'SMA26': {2025-09-10 00:00:00: 2406.1923}, 'SMA50': {2025-09-10 00:00:00: 2387.92}, 'SMA200': {2025-09-10 00:00:00: 2395.905}, 'lag_change1': {2025-09-10 00:00:00: 0.02814657461497605}, 'lag_change2': {2025-09-10 00:00:00: -0.019270833333333348}, 'lag_change3': {2025-09-10 00:00:00: -0.025380710659898442}, 'lag_change4': {2025-09-10 00:00:00: 0.0025445292620864812}, 'lag_change5': {2025-09-10 00:00:00: -0.14192139737991272}, 'close_lag_1': {2025-09-10 00:00:00: 1936.0}, 'close_lag_2': {2025-09-10 00:00:00: 1883.0}, 'close_lag_3': {2025-09-10 00:00:00: 1920.0}, 'close_lag_4': {2025-09-10 00:00:00: 1970.0}, 'close_lag_5': {2025-09-10 00:00:00: 1965.0}, 'open_lag_1': {2025-09-10 00:00:00: 1940.0}, 'open_lag_2': {2025-09-10 00:00:00: 1770.0}, 'open_lag_3': {2025-09-10 00:00:00: 2000.0}, 'open_lag_4': {2025-09-10 00:00:00: 1990.0}, 'open_lag_5': {2025-09-10 00:00:00: 2050.0}, 'high_lag_1': {2025-09-10 00:00:00: 1940.0}, 'high_lag_2': {2025-09-10 00:00:00: 1910.0}, 'high_lag_3': {2025-09-10 00:00:00: 2000.0}, 'high_lag_4': {2025-09-10 00:00:00: 2030.0}, 'high_lag_5': {2025-09-10 00:00:00: 2050.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.047979797979773746}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.06958762886594351}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.15819209039539087}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.020100502512552715}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.0}}   \n",
              "2025-09-15        {'RSI': {2025-09-10 00:00:00: 52.68}, 'ROC': {2025-09-10 00:00:00: 1.156211562115621}, 'PPO': {2025-09-10 00:00:00: -0.8772394184206476}, 'PPO_Signal': {2025-09-10 00:00:00: -0.9259591218197915}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.04871970339914389}, 'EWO': {2025-09-10 00:00:00: -3.672196515494028}, 'EWO_Signal': {2025-09-10 00:00:00: -3.3490853662592004}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.32311114923482753}, 'Volatility': {2025-09-10 00:00:00: 1577.238155}, 'SMA5': {2025-09-10 00:00:00: 40596.0}, 'SMA13': {2025-09-10 00:00:00: 40965.7692}, 'SMA26': {2025-09-10 00:00:00: 42721.3462}, 'SMA50': {2025-09-10 00:00:00: 42052.1}, 'SMA200': {2025-09-10 00:00:00: 43559.025}, 'lag_change1': {2025-09-10 00:00:00: 0.01954569466455358}, 'lag_change2': {2025-09-10 00:00:00: -0.11696793002915451}, 'lag_change3': {2025-09-10 00:00:00: 0.008230452674897082}, 'lag_change4': {2025-09-10 00:00:00: 0.046125461254612476}, 'lag_change5': {2025-09-10 00:00:00: -0.02166064981949456}, 'close_lag_1': {2025-09-10 00:00:00: 38600.0}, 'close_lag_2': {2025-09-10 00:00:00: 37860.0}, 'close_lag_3': {2025-09-10 00:00:00: 42875.0}, 'close_lag_4': {2025-09-10 00:00:00: 42525.0}, 'close_lag_5': {2025-09-10 00:00:00: 40650.0}, 'open_lag_1': {2025-09-10 00:00:00: 38200.0}, 'open_lag_2': {2025-09-10 00:00:00: 37500.0}, 'open_lag_3': {2025-09-10 00:00:00: 42200.0}, 'open_lag_4': {2025-09-10 00:00:00: 41000.0}, 'open_lag_5': {2025-09-10 00:00:00: 41000.0}, 'high_lag_1': {2025-09-10 00:00:00: 40060.0}, 'high_lag_2': {2025-09-10 00:00:00: 39740.0}, 'high_lag_3': {2025-09-10 00:00:00: 43725.0}, 'high_lag_4': {2025-09-10 00:00:00: 42700.0}, 'high_lag_5': {2025-09-10 00:00:00: 42050.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.0747422680412352}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.09162303664921227}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.10933333333333042}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.036137440758292984}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.06646341463414472}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.06646341463414472}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.05627705627705489}}   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Features Escaladas (Predicción)  \n",
              "Fecha Predicción                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "2025-09-15        [-0.7818634853518561, 0.044757316601609594, -0.3832495566899804, -0.3924117529798455, -0.06086068095672429, -0.31706707436920106, -0.2703206224154513, -0.19779355102866564, 30.043158689979204, 52.73595848595849, 54.12918563364025, 54.0415509285829, 55.258611297025546, 67.69170730862187, -0.14348649757668872, 0.6112720219450265, -0.5736788385325617, -0.22783784833429088, -2.056347795594639, 52.64302059496568, 53.03598774885146, 52.23200612557427, 53.09934790947449, 53.61185983827493, 53.40621403912543, 51.202920830130665, 51.971560338201385, 54.277478862413524, 56.307277628032345, 52.50721954831545, 52.011127596439174, 51.63148079074972, 53.497374343585896, 55.3728432108027, 0.09437239351118115, 0.09441297184839482, 1.4271685027261352, 0.8201706870964343, -0.30434982888093587, -0.31410158176771164, -0.4751226744059963]  \n",
              "2025-09-15                        [-0.5563744682079752, -2.007197656994868, -2.76833937912835, -2.476760723952092, -1.4372688784040728, -2.33958696404983, -2.070297733948386, -1.6887037198218429, 155.00641285592303, 51.59512741761435, 56.131931210490535, 64.69844242022965, 67.99798653435019, 72.7667965570392, -0.7265931849854965, -6.115559915879347, -0.4255501722409742, 0.9894397549657818, -0.4335416140785042, 45.28714812808009, 46.432824644305015, 58.163131378374885, 59.11360811930406, 57.42790359443175, 47.10431211498973, 53.08001130901894, 60.01091489471245, 57.37798845836768, 58.13378702343206, 46.95259547973982, 52.30331273427211, 59.044705047997766, 59.177496198682206, 57.57456840824396, 0.3623632910310479, 0.11047432367939544, -0.6138382151584646, -0.6138382151584646, 0.45969386862171524, 0.17163887669039912, 1.2792725431247385]  \n",
              "2025-09-15                      [-0.3745054107419694, -0.6281336396776755, -2.4760340510803056, -2.7628097855284848, 0.21161290719391843, -2.046821128313282, -1.9426993515867141, -0.7967262027254606, 336.6923973355626, 82.17211107793372, 91.01752208994233, 108.03069587737272, 110.79358737422626, 137.21438229600977, -1.030963541666669, -4.735526315789479, 0.9149999999999996, 0.4122565864833895, -1.0924116997792492, 73.58545671285948, 76.37873357228196, 90.71565113500598, 88.09325960245106, 87.09286998202518, 77.65994065281897, 80.62729970326409, 88.93590504451038, 86.26528189910978, 90.12284866468842, 77.55691768826618, 81.99503432160068, 90.66451990632318, 88.61533957845432, 90.73092134173135, 1.5858042500195857, 0.9882026375871523, 0.12351052107326538, 0.1287878789129126, 0.6880662296960662, -0.10817109358234392, -0.22920685607230776]  \n",
              "2025-09-15                                               [-0.04414008902657611, -0.17823592746776742, -0.6855155997616817, -0.780649419113242, 0.0780532225507881, -0.8009510325615006, -0.7884736687961438, -0.21971376040656387, 77.2307268349907, 77.73587477465593, 78.73939154310818, 83.15648332160637, 83.33579025751025, 84.14454141684055, 1.0506682476692275, -4.282627433852966, 0.3072088142513833, 1.0415558037588895, 0.0, 74.19654070728214, 71.92283950617283, 82.87199293754139, 82.19067609368095, 79.65046398585949, 73.09592061742006, 76.00948076287068, 81.01675485008819, 79.47420634920634, 77.57559037740013, 73.69981761613562, 74.04897433143593, 82.63163550397594, 80.59015688802924, 79.06411359724613, 1.1622238090724453, 1.5087478734552227, 0.523221421139541, 0.4401811750513594, 0.8793396784865425, 1.4682448768184122, 0.592417013183931]  \n",
              "2025-09-15                       [-0.6147590916174369, 0.408684110413545, -1.6823539333465318, -2.1347188360569342, 0.9451253132079582, -1.3991407534907576, -1.3157831341465105, -0.4192381922057084, 255.05107098244065, 85.59871659634321, 95.96703152364275, 103.82942010868511, 102.21913137344772, 101.89573358867963, 0.8724283345423732, -0.5973167698103562, -0.7866978995993149, 0.07886996754252583, -4.394355239670768, 85.02593406593407, 82.69626373626373, 84.32263736263737, 86.52043956043956, 86.30065934065934, 84.7917760279965, 77.35520559930009, 87.416447944007, 87.07422815852857, 89.80008768084173, 83.31442080378248, 82.11316695352839, 85.98580034423406, 87.27667814113596, 88.13726333907056, 0.42428934062640505, 0.8505118477899479, 2.5946018206728714, -0.5254051561276185, -0.12896493007326018, -0.5256687099526277, -0.5261359703453173]  \n",
              "2025-09-15               [-0.029614419944876184, 0.09918919765174586, -0.6781460952282776, -0.7559840974273326, 0.09703139220566527, -0.6861214233390261, -0.6601505490191427, -0.21067204240307297, 91.51343809283078, 132.67664533070737, 133.60011417233736, 138.77738202887585, 134.0727156607819, 166.83783792357391, 0.7717961991695983, -4.618684849556809, 0.3249939283790559, 1.8213451244490504, -0.8556014077880957, 125.92028184015403, 123.52044579201834, 140.0508405084051, 139.07960096884108, 132.9490022172949, 124.29903563255967, 122.14129100875398, 137.765110847027, 133.84827868852457, 133.8488524590164, 127.52038369304556, 126.80128205128206, 139.57371794871796, 136.38681741640607, 134.60419512979183, 1.4887356084071173, 1.9454401748438521, 2.4264586733465277, 0.4347708688522255, 1.260602487950169, 1.26212669729396, 0.9854584453082402]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fe64b2b-6082-49ed-819d-137acf934aa2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Papel</th>\n",
              "      <th>Fecha Datos</th>\n",
              "      <th>Predicción</th>\n",
              "      <th>Probabilidad Alcista (Modelo)</th>\n",
              "      <th>Umbral de Clasificación</th>\n",
              "      <th>Mejores hiperparámetros (Incluye scale_pos_weight)</th>\n",
              "      <th>Precision Test (Alcista)</th>\n",
              "      <th>Recall Test (Alcista)</th>\n",
              "      <th>F1 Test (Alcista)</th>\n",
              "      <th>ROC-AUC Test</th>\n",
              "      <th>clase 1 en test (cleaned)</th>\n",
              "      <th>Features Limpias (Predicción)</th>\n",
              "      <th>Features Escaladas (Predicción)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fecha Predicción</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-09-15</th>\n",
              "      <td>ALUA.BA</td>\n",
              "      <td>2025-09-10</td>\n",
              "      <td>Alcista</td>\n",
              "      <td>0.6907</td>\n",
              "      <td>0.53</td>\n",
              "      <td>{'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.937186</td>\n",
              "      <td>0.849658</td>\n",
              "      <td>0.573765</td>\n",
              "      <td>0.7683</td>\n",
              "      <td>{'RSI': {2025-09-10 00:00:00: 22.02380952380952}, 'ROC': {2025-09-10 00:00:00: 0.2857142857142857}, 'PPO': {2025-09-10 00:00:00: -0.4910590194243401}, 'PPO_Signal': {2025-09-10 00:00:00: -0.44710124137936935}, 'PPO_Histogram': {2025-09-10 00:00:00: -0.04395777804497075}, 'EWO': {2025-09-10 00:00:00: -1.4486191078044606}, 'EWO_Signal': {2025-09-10 00:00:00: -1.111244869861243}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.33737423794321764}, 'Volatility': {2025-09-10 00:00:00: 20.12283}, 'SMA5': {2025-09-10 00:00:00: 694.9}, 'SMA13': {2025-09-10 00:00:00: 711.9615}, 'SMA26': {2025-09-10 00:00:00: 710.0577}, 'SMA50': {2025-09-10 00:00:00: 713.85}, 'SMA200': {2025-09-10 00:00:00: 784.9925}, 'lag_change1': {2025-09-10 00:00:00: -0.003589375448671883}, 'lag_change2': {2025-09-10 00:00:00: 0.015306122448979664}, 'lag_change3': {2025-09-10 00:00:00: -0.014367816091954033}, 'lag_change4': {2025-09-10 00:00:00: -0.005714285714285672}, 'lag_change5': {2025-09-10 00:00:00: -0.051490514905149}, 'close_lag_1': {2025-09-10 00:00:00: 694.0}, 'close_lag_2': {2025-09-10 00:00:00: 696.5}, 'close_lag_3': {2025-09-10 00:00:00: 686.0}, 'close_lag_4': {2025-09-10 00:00:00: 696.0}, 'close_lag_5': {2025-09-10 00:00:00: 700.0}, 'open_lag_1': {2025-09-10 00:00:00: 700.0}, 'open_lag_2': {2025-09-10 00:00:00: 670.0}, 'open_lag_3': {2025-09-10 00:00:00: 680.0}, 'open_lag_4': {2025-09-10 00:00:00: 710.0}, 'open_lag_5': {2025-09-10 00:00:00: 735.0}, 'high_lag_1': {2025-09-10 00:00:00: 713.0}, 'high_lag_2': {2025-09-10 00:00:00: 705.0}, 'high_lag_3': {2025-09-10 00:00:00: 696.0}, 'high_lag_4': {2025-09-10 00:00:00: 717.0}, 'high_lag_5': {2025-09-10 00:00:00: 742.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.0235714285713949}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.0235714285713949}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.06940298507452328}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.04852941176463452}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.009859154929563579}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.009523809523796566}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.003994673768303602}}</td>\n",
              "      <td>[-0.7818634853518561, 0.044757316601609594, -0.3832495566899804, -0.3924117529798455, -0.06086068095672429, -0.31706707436920106, -0.2703206224154513, -0.19779355102866564, 30.043158689979204, 52.73595848595849, 54.12918563364025, 54.0415509285829, 55.258611297025546, 67.69170730862187, -0.14348649757668872, 0.6112720219450265, -0.5736788385325617, -0.22783784833429088, -2.056347795594639, 52.64302059496568, 53.03598774885146, 52.23200612557427, 53.09934790947449, 53.61185983827493, 53.40621403912543, 51.202920830130665, 51.971560338201385, 54.277478862413524, 56.307277628032345, 52.50721954831545, 52.011127596439174, 51.63148079074972, 53.497374343585896, 55.3728432108027, 0.09437239351118115, 0.09441297184839482, 1.4271685027261352, 0.8201706870964343, -0.30434982888093587, -0.31410158176771164, -0.4751226744059963]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-15</th>\n",
              "      <td>BBAR.BA</td>\n",
              "      <td>2025-09-10</td>\n",
              "      <td>Alcista</td>\n",
              "      <td>0.8137</td>\n",
              "      <td>0.57</td>\n",
              "      <td>{'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}</td>\n",
              "      <td>0.864603</td>\n",
              "      <td>0.997768</td>\n",
              "      <td>0.926425</td>\n",
              "      <td>0.441040</td>\n",
              "      <td>0.8649</td>\n",
              "      <td>{'RSI': {2025-09-10 00:00:00: 32.53012048192771}, 'ROC': {2025-09-10 00:00:00: -15.974729241877256}, 'PPO': {2025-09-10 00:00:00: -5.3389766580011075}, 'PPO_Signal': {2025-09-10 00:00:00: -4.3361629455140625}, 'PPO_Histogram': {2025-09-10 00:00:00: -1.002813712487045}, 'EWO': {2025-09-10 00:00:00: -19.51935321956679}, 'EWO_Signal': {2025-09-10 00:00:00: -16.528431983648822}, 'EWO_Histogram': {2025-09-10 00:00:00: -2.990921235917966}, 'Volatility': {2025-09-10 00:00:00: 773.324792}, 'SMA5': {2025-09-10 00:00:00: 4984.5}, 'SMA13': {2025-09-10 00:00:00: 5360.9615}, 'SMA26': {2025-09-10 00:00:00: 6177.7885}, 'SMA50': {2025-09-10 00:00:00: 6404.85}, 'SMA200': {2025-09-10 00:00:00: 7363.8125}, 'lag_change1': {2025-09-10 00:00:00: -0.023849140321686058}, 'lag_change2': {2025-09-10 00:00:00: -0.20079787234042556}, 'lag_change3': {2025-09-10 00:00:00: -0.013986013986013957}, 'lag_change4': {2025-09-10 00:00:00: 0.032490974729241895}, 'lag_change5': {2025-09-10 00:00:00: -0.014234875444839812}, 'close_lag_1': {2025-09-10 00:00:00: 4400.0}, 'close_lag_2': {2025-09-10 00:00:00: 4507.5}, 'close_lag_3': {2025-09-10 00:00:00: 5640.0}, 'close_lag_4': {2025-09-10 00:00:00: 5720.0}, 'close_lag_5': {2025-09-10 00:00:00: 5540.0}, 'open_lag_1': {2025-09-10 00:00:00: 4600.0}, 'open_lag_2': {2025-09-10 00:00:00: 5175.0}, 'open_lag_3': {2025-09-10 00:00:00: 5840.0}, 'open_lag_4': {2025-09-10 00:00:00: 5580.0}, 'open_lag_5': {2025-09-10 00:00:00: 5650.0}, 'high_lag_1': {2025-09-10 00:00:00: 4650.0}, 'high_lag_2': {2025-09-10 00:00:00: 5175.0}, 'high_lag_3': {2025-09-10 00:00:00: 5840.0}, 'high_lag_4': {2025-09-10 00:00:00: 5850.0}, 'high_lag_5': {2025-09-10 00:00:00: 5690.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.043956043956034294}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.03260869565216682}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.04838709677418487}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.03539823008848931}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.08534322820035521}}</td>\n",
              "      <td>[-0.5563744682079752, -2.007197656994868, -2.76833937912835, -2.476760723952092, -1.4372688784040728, -2.33958696404983, -2.070297733948386, -1.6887037198218429, 155.00641285592303, 51.59512741761435, 56.131931210490535, 64.69844242022965, 67.99798653435019, 72.7667965570392, -0.7265931849854965, -6.115559915879347, -0.4255501722409742, 0.9894397549657818, -0.4335416140785042, 45.28714812808009, 46.432824644305015, 58.163131378374885, 59.11360811930406, 57.42790359443175, 47.10431211498973, 53.08001130901894, 60.01091489471245, 57.37798845836768, 58.13378702343206, 46.95259547973982, 52.30331273427211, 59.044705047997766, 59.177496198682206, 57.57456840824396, 0.3623632910310479, 0.11047432367939544, -0.6138382151584646, -0.6138382151584646, 0.45969386862171524, 0.17163887669039912, 1.2792725431247385]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-15</th>\n",
              "      <td>METR.BA</td>\n",
              "      <td>2025-09-10</td>\n",
              "      <td>Alcista</td>\n",
              "      <td>0.9124</td>\n",
              "      <td>0.63</td>\n",
              "      <td>{'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}</td>\n",
              "      <td>0.876068</td>\n",
              "      <td>0.917226</td>\n",
              "      <td>0.896175</td>\n",
              "      <td>0.548981</td>\n",
              "      <td>0.8629</td>\n",
              "      <td>{'RSI': {2025-09-10 00:00:00: 35.102739726027394}, 'ROC': {2025-09-10 00:00:00: -5.429553264604811}, 'PPO': {2025-09-10 00:00:00: -5.1254883136060885}, 'PPO_Signal': {2025-09-10 00:00:00: -5.245569085162645}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.12008077155655617}, 'EWO': {2025-09-10 00:00:00: -21.51889874854952}, 'EWO_Signal': {2025-09-10 00:00:00: -19.964037042024817}, 'EWO_Histogram': {2025-09-10 00:00:00: -1.5548617065247043}, 'Volatility': {2025-09-10 00:00:00: 249.501376}, 'SMA5': {2025-09-10 00:00:00: 1377.4}, 'SMA13': {2025-09-10 00:00:00: 1519.7692}, 'SMA26': {2025-09-10 00:00:00: 1799.3077}, 'SMA50': {2025-09-10 00:00:00: 1889.84}, 'SMA200': {2025-09-10 00:00:00: 2188.235}, 'lag_change1': {2025-09-10 00:00:00: -0.034375000000000044}, 'lag_change2': {2025-09-10 00:00:00: -0.1578947368421053}, 'lag_change3': {2025-09-10 00:00:00: 0.03050847457627115}, 'lag_change4': {2025-09-10 00:00:00: 0.013745704467353903}, 'lag_change5': {2025-09-10 00:00:00: -0.03642384105960261}, 'close_lag_1': {2025-09-10 00:00:00: 1236.0}, 'close_lag_2': {2025-09-10 00:00:00: 1280.0}, 'close_lag_3': {2025-09-10 00:00:00: 1520.0}, 'close_lag_4': {2025-09-10 00:00:00: 1475.0}, 'close_lag_5': {2025-09-10 00:00:00: 1455.0}, 'open_lag_1': {2025-09-10 00:00:00: 1310.0}, 'open_lag_2': {2025-09-10 00:00:00: 1360.0}, 'open_lag_3': {2025-09-10 00:00:00: 1500.0}, 'open_lag_4': {2025-09-10 00:00:00: 1455.0}, 'open_lag_5': {2025-09-10 00:00:00: 1520.0}, 'high_lag_1': {2025-09-10 00:00:00: 1330.0}, 'high_lag_2': {2025-09-10 00:00:00: 1405.0}, 'high_lag_3': {2025-09-10 00:00:00: 1550.0}, 'high_lag_4': {2025-09-10 00:00:00: 1515.0}, 'high_lag_5': {2025-09-10 00:00:00: 1550.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.11653543307077438}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.08244274809154012}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.03308823529409332}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.033333333333311115}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.0652920962198864}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.019736842105250174}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.012820512820504603}}</td>\n",
              "      <td>[-0.3745054107419694, -0.6281336396776755, -2.4760340510803056, -2.7628097855284848, 0.21161290719391843, -2.046821128313282, -1.9426993515867141, -0.7967262027254606, 336.6923973355626, 82.17211107793372, 91.01752208994233, 108.03069587737272, 110.79358737422626, 137.21438229600977, -1.030963541666669, -4.735526315789479, 0.9149999999999996, 0.4122565864833895, -1.0924116997792492, 73.58545671285948, 76.37873357228196, 90.71565113500598, 88.09325960245106, 87.09286998202518, 77.65994065281897, 80.62729970326409, 88.93590504451038, 86.26528189910978, 90.12284866468842, 77.55691768826618, 81.99503432160068, 90.66451990632318, 88.61533957845432, 90.73092134173135, 1.5858042500195857, 0.9882026375871523, 0.12351052107326538, 0.1287878789129126, 0.6880662296960662, -0.10817109358234392, -0.22920685607230776]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-15</th>\n",
              "      <td>PAMP.BA</td>\n",
              "      <td>2025-09-10</td>\n",
              "      <td>Alcista</td>\n",
              "      <td>0.7236</td>\n",
              "      <td>0.50</td>\n",
              "      <td>{'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}</td>\n",
              "      <td>0.797101</td>\n",
              "      <td>0.929952</td>\n",
              "      <td>0.858417</td>\n",
              "      <td>0.504575</td>\n",
              "      <td>0.7992</td>\n",
              "      <td>{'RSI': {2025-09-10 00:00:00: 52.18446601941748}, 'ROC': {2025-09-10 00:00:00: -0.8310249307479225}, 'PPO': {2025-09-10 00:00:00: -1.147398945157694}, 'PPO_Signal': {2025-09-10 00:00:00: -1.1962556510418119}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.048856705884117835}, 'EWO': {2025-09-10 00:00:00: -4.905880769374763}, 'EWO_Signal': {2025-09-10 00:00:00: -4.489529457552637}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.41635131182212604}, 'Volatility': {2025-09-10 00:00:00: 172.085696}, 'SMA5': {2025-09-10 00:00:00: 3541.0}, 'SMA13': {2025-09-10 00:00:00: 3589.6154}, 'SMA26': {2025-09-10 00:00:00: 3775.0}, 'SMA50': {2025-09-10 00:00:00: 3754.2}, 'SMA200': {2025-09-10 00:00:00: 3819.95}, 'lag_change1': {2025-09-10 00:00:00: 0.032134659525631326}, 'lag_change2': {2025-09-10 00:00:00: -0.13098404255319152}, 'lag_change3': {2025-09-10 00:00:00: 0.00939597315436247}, 'lag_change4': {2025-09-10 00:00:00: 0.03185595567867039}, 'lag_change5': {2025-09-10 00:00:00: 0.0}, 'close_lag_1': {2025-09-10 00:00:00: 3372.5}, 'close_lag_2': {2025-09-10 00:00:00: 3267.5}, 'close_lag_3': {2025-09-10 00:00:00: 3760.0}, 'close_lag_4': {2025-09-10 00:00:00: 3725.0}, 'close_lag_5': {2025-09-10 00:00:00: 3610.0}, 'open_lag_1': {2025-09-10 00:00:00: 3320.0}, 'open_lag_2': {2025-09-10 00:00:00: 3452.5}, 'open_lag_3': {2025-09-10 00:00:00: 3680.0}, 'open_lag_4': {2025-09-10 00:00:00: 3610.0}, 'open_lag_5': {2025-09-10 00:00:00: 3520.0}, 'high_lag_1': {2025-09-10 00:00:00: 3440.0}, 'high_lag_2': {2025-09-10 00:00:00: 3452.5}, 'high_lag_3': {2025-09-10 00:00:00: 3850.0}, 'high_lag_4': {2025-09-10 00:00:00: 3755.0}, 'high_lag_5': {2025-09-10 00:00:00: 3680.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.07863501483677192}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.09487951807226058}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.04996379435190443}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.04619565217390049}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.06648199445981538}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.09374999999997337}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.05329593267880693}}</td>\n",
              "      <td>[-0.04414008902657611, -0.17823592746776742, -0.6855155997616817, -0.780649419113242, 0.0780532225507881, -0.8009510325615006, -0.7884736687961438, -0.21971376040656387, 77.2307268349907, 77.73587477465593, 78.73939154310818, 83.15648332160637, 83.33579025751025, 84.14454141684055, 1.0506682476692275, -4.282627433852966, 0.3072088142513833, 1.0415558037588895, 0.0, 74.19654070728214, 71.92283950617283, 82.87199293754139, 82.19067609368095, 79.65046398585949, 73.09592061742006, 76.00948076287068, 81.01675485008819, 79.47420634920634, 77.57559037740013, 73.69981761613562, 74.04897433143593, 82.63163550397594, 80.59015688802924, 79.06411359724613, 1.1622238090724453, 1.5087478734552227, 0.523221421139541, 0.4401811750513594, 0.8793396784865425, 1.4682448768184122, 0.592417013183931]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-15</th>\n",
              "      <td>TRAN.BA</td>\n",
              "      <td>2025-09-10</td>\n",
              "      <td>Alcista</td>\n",
              "      <td>0.6291</td>\n",
              "      <td>0.57</td>\n",
              "      <td>{'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}</td>\n",
              "      <td>0.843552</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.876923</td>\n",
              "      <td>0.496850</td>\n",
              "      <td>0.8436</td>\n",
              "      <td>{'RSI': {2025-09-10 00:00:00: 25.60386473429952}, 'ROC': {2025-09-10 00:00:00: 3.6641221374045805}, 'PPO': {2025-09-10 00:00:00: -3.726008383735165}, 'PPO_Signal': {2025-09-10 00:00:00: -4.4009672295842925}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.6749588458491274}, 'EWO': {2025-09-10 00:00:00: -13.971037469616455}, 'EWO_Signal': {2025-09-10 00:00:00: -13.05087452217676}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.9201629474396942}, 'Volatility': {2025-09-10 00:00:00: 274.809499}, 'SMA5': {2025-09-10 00:00:00: 1949.2}, 'SMA13': {2025-09-10 00:00:00: 2193.5385}, 'SMA26': {2025-09-10 00:00:00: 2406.1923}, 'SMA50': {2025-09-10 00:00:00: 2387.92}, 'SMA200': {2025-09-10 00:00:00: 2395.905}, 'lag_change1': {2025-09-10 00:00:00: 0.02814657461497605}, 'lag_change2': {2025-09-10 00:00:00: -0.019270833333333348}, 'lag_change3': {2025-09-10 00:00:00: -0.025380710659898442}, 'lag_change4': {2025-09-10 00:00:00: 0.0025445292620864812}, 'lag_change5': {2025-09-10 00:00:00: -0.14192139737991272}, 'close_lag_1': {2025-09-10 00:00:00: 1936.0}, 'close_lag_2': {2025-09-10 00:00:00: 1883.0}, 'close_lag_3': {2025-09-10 00:00:00: 1920.0}, 'close_lag_4': {2025-09-10 00:00:00: 1970.0}, 'close_lag_5': {2025-09-10 00:00:00: 1965.0}, 'open_lag_1': {2025-09-10 00:00:00: 1940.0}, 'open_lag_2': {2025-09-10 00:00:00: 1770.0}, 'open_lag_3': {2025-09-10 00:00:00: 2000.0}, 'open_lag_4': {2025-09-10 00:00:00: 1990.0}, 'open_lag_5': {2025-09-10 00:00:00: 2050.0}, 'high_lag_1': {2025-09-10 00:00:00: 1940.0}, 'high_lag_2': {2025-09-10 00:00:00: 1910.0}, 'high_lag_3': {2025-09-10 00:00:00: 2000.0}, 'high_lag_4': {2025-09-10 00:00:00: 2030.0}, 'high_lag_5': {2025-09-10 00:00:00: 2050.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.047979797979773746}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.06958762886594351}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.15819209039539087}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.020100502512552715}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.0}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.0}}</td>\n",
              "      <td>[-0.6147590916174369, 0.408684110413545, -1.6823539333465318, -2.1347188360569342, 0.9451253132079582, -1.3991407534907576, -1.3157831341465105, -0.4192381922057084, 255.05107098244065, 85.59871659634321, 95.96703152364275, 103.82942010868511, 102.21913137344772, 101.89573358867963, 0.8724283345423732, -0.5973167698103562, -0.7866978995993149, 0.07886996754252583, -4.394355239670768, 85.02593406593407, 82.69626373626373, 84.32263736263737, 86.52043956043956, 86.30065934065934, 84.7917760279965, 77.35520559930009, 87.416447944007, 87.07422815852857, 89.80008768084173, 83.31442080378248, 82.11316695352839, 85.98580034423406, 87.27667814113596, 88.13726333907056, 0.42428934062640505, 0.8505118477899479, 2.5946018206728714, -0.5254051561276185, -0.12896493007326018, -0.5256687099526277, -0.5261359703453173]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-15</th>\n",
              "      <td>YPFD.BA</td>\n",
              "      <td>2025-09-10</td>\n",
              "      <td>Alcista</td>\n",
              "      <td>0.7976</td>\n",
              "      <td>0.61</td>\n",
              "      <td>{'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.661058</td>\n",
              "      <td>0.718016</td>\n",
              "      <td>0.430147</td>\n",
              "      <td>0.8031</td>\n",
              "      <td>{'RSI': {2025-09-10 00:00:00: 52.68}, 'ROC': {2025-09-10 00:00:00: 1.156211562115621}, 'PPO': {2025-09-10 00:00:00: -0.8772394184206476}, 'PPO_Signal': {2025-09-10 00:00:00: -0.9259591218197915}, 'PPO_Histogram': {2025-09-10 00:00:00: 0.04871970339914389}, 'EWO': {2025-09-10 00:00:00: -3.672196515494028}, 'EWO_Signal': {2025-09-10 00:00:00: -3.3490853662592004}, 'EWO_Histogram': {2025-09-10 00:00:00: -0.32311114923482753}, 'Volatility': {2025-09-10 00:00:00: 1577.238155}, 'SMA5': {2025-09-10 00:00:00: 40596.0}, 'SMA13': {2025-09-10 00:00:00: 40965.7692}, 'SMA26': {2025-09-10 00:00:00: 42721.3462}, 'SMA50': {2025-09-10 00:00:00: 42052.1}, 'SMA200': {2025-09-10 00:00:00: 43559.025}, 'lag_change1': {2025-09-10 00:00:00: 0.01954569466455358}, 'lag_change2': {2025-09-10 00:00:00: -0.11696793002915451}, 'lag_change3': {2025-09-10 00:00:00: 0.008230452674897082}, 'lag_change4': {2025-09-10 00:00:00: 0.046125461254612476}, 'lag_change5': {2025-09-10 00:00:00: -0.02166064981949456}, 'close_lag_1': {2025-09-10 00:00:00: 38600.0}, 'close_lag_2': {2025-09-10 00:00:00: 37860.0}, 'close_lag_3': {2025-09-10 00:00:00: 42875.0}, 'close_lag_4': {2025-09-10 00:00:00: 42525.0}, 'close_lag_5': {2025-09-10 00:00:00: 40650.0}, 'open_lag_1': {2025-09-10 00:00:00: 38200.0}, 'open_lag_2': {2025-09-10 00:00:00: 37500.0}, 'open_lag_3': {2025-09-10 00:00:00: 42200.0}, 'open_lag_4': {2025-09-10 00:00:00: 41000.0}, 'open_lag_5': {2025-09-10 00:00:00: 41000.0}, 'high_lag_1': {2025-09-10 00:00:00: 40060.0}, 'high_lag_2': {2025-09-10 00:00:00: 39740.0}, 'high_lag_3': {2025-09-10 00:00:00: 43725.0}, 'high_lag_4': {2025-09-10 00:00:00: 42700.0}, 'high_lag_5': {2025-09-10 00:00:00: 42050.0}, 'Max_Gain_from_Open_Current': {2025-09-10 00:00:00: 0.0747422680412352}, 'Max_Gain_from_Open_Lag_1': {2025-09-10 00:00:00: 0.09162303664921227}, 'Max_Gain_from_Open_Lag_2': {2025-09-10 00:00:00: 0.10933333333333042}, 'Max_Gain_from_Open_Lag_3': {2025-09-10 00:00:00: 0.036137440758292984}, 'Max_Gain_from_Open_Lag_4': {2025-09-10 00:00:00: 0.06646341463414472}, 'Max_Gain_from_Open_Lag_5': {2025-09-10 00:00:00: 0.06646341463414472}, 'Max_Gain_from_Open_Lag_6': {2025-09-10 00:00:00: 0.05627705627705489}}</td>\n",
              "      <td>[-0.029614419944876184, 0.09918919765174586, -0.6781460952282776, -0.7559840974273326, 0.09703139220566527, -0.6861214233390261, -0.6601505490191427, -0.21067204240307297, 91.51343809283078, 132.67664533070737, 133.60011417233736, 138.77738202887585, 134.0727156607819, 166.83783792357391, 0.7717961991695983, -4.618684849556809, 0.3249939283790559, 1.8213451244490504, -0.8556014077880957, 125.92028184015403, 123.52044579201834, 140.0508405084051, 139.07960096884108, 132.9490022172949, 124.29903563255967, 122.14129100875398, 137.765110847027, 133.84827868852457, 133.8488524590164, 127.52038369304556, 126.80128205128206, 139.57371794871796, 136.38681741640607, 134.60419512979183, 1.4887356084071173, 1.9454401748438521, 2.4264586733465277, 0.4347708688522255, 1.260602487950169, 1.26212669729396, 0.9854584453082402]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fe64b2b-6082-49ed-819d-137acf934aa2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9fe64b2b-6082-49ed-819d-137acf934aa2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9fe64b2b-6082-49ed-819d-137acf934aa2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f146400e-d933-47e0-a5d7-7f9640e5060c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f146400e-d933-47e0-a5d7-7f9640e5060c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f146400e-d933-47e0-a5d7-7f9640e5060c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a17d42f5-68e9-4e5a-84b3-07ed977630e0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resultsp_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a17d42f5-68e9-4e5a-84b3-07ed977630e0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('resultsp_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resultsp_df",
              "summary": "{\n  \"name\": \"resultsp_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Fecha Predicci\\u00f3n\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-15 00:00:00\",\n        \"max\": \"2025-09-15 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-09-15 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Papel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"ALUA.BA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fecha Datos\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-10 00:00:00\",\n        \"max\": \"2025-09-10 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-09-10 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicci\\u00f3n\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Alcista\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Probabilidad Alcista (Modelo)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6906999945640564\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Umbral de Clasificaci\\u00f3n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04833908011812665,\n        \"min\": 0.5,\n        \"max\": 0.63,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mejores hiperpar\\u00e1metros (Incluye scale_pos_weight)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Test (Alcista)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04273764224745243,\n        \"min\": 0.7770833333333333,\n        \"max\": 0.8760683760683761,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7770833333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Test (Alcista)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11754103871904943,\n        \"min\": 0.6610576923076923,\n        \"max\": 0.9977678571428571,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9371859296482412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Test (Alcista)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07222079089134864,\n        \"min\": 0.7180156657963447,\n        \"max\": 0.9264248704663213,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8496583143507973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC-AUC Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056962090129020614,\n        \"min\": 0.430147,\n        \"max\": 0.573765,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.573765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clase 1 en test (cleaned)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.039303570660522265,\n        \"min\": 0.7683,\n        \"max\": 0.8649,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7683\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Features Limpias (Predicci\\u00f3n)\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Features Escaladas (Predicci\\u00f3n)\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3f2bb24-576b-4e3e-8e3e-d619ea7f0a8a\", \"Predic_results_2025-09-14.csv\", 22996)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Archivo 'Predic_results_2025-09-14.csv' generado y descargado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0f6ba43",
        "outputId": "e4212e98-0f71-4cda-8a4a-ac7e9bfd3deb"
      },
      "source": [
        "!pip install imblearn"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (from imblearn) (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "809c0f48",
        "outputId": "de031f48-2b35-49e8-dd9e-7f7415281722"
      },
      "source": [],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1754429140.py, line 664)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1754429140.py\"\u001b[0;36m, line \u001b[0;32m664\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import files\n",
        "from scipy import stats\n",
        "import time\n",
        "from imblearn.over_sampling import SMOTE # Import SMOTE\n",
        "import matplotlib.pyplot as plt # Import for plotting (optional for this step)\n",
        "import seaborn as sns # Import for plotting (optional for this step)\n",
        "import os # Import os for creating directories\n",
        "\n",
        "\n",
        "# --- Control Flag ---\n",
        "run_full_model = True # Set to True to run model training, tuning, and prediction; Set to False to only run data/feature analysis\n",
        "# --- End Control Flag ---\n",
        "\n",
        "\n",
        "# Functions for features\n",
        "def add_lagged_price_features(df, etiqueta=\"close_lag\", dato=\"Close\"):\n",
        "    for lag in range(1, 6):\n",
        "        df[f'{etiqueta}_{lag}'] = df[dato].shift(lag)\n",
        "    return df\n",
        "\n",
        "def calculate_RSI(series, period=7):\n",
        "    delta = series.diff(1)\n",
        "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def calculate_ROC(series, period=5):\n",
        "    return ((series - series.shift(period)) / series.shift(period)) * 100\n",
        "\n",
        "def calculate_PPO(series, fast_period=5, slow_period=9, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ppo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ppo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ppo - signal_line\n",
        "    return ppo, signal_line, histogram\n",
        "\n",
        "def calculate_EWO(series, fast_period=5, slow_period=35, signal_period=5):\n",
        "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
        "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
        "    ewo = (ema_fast - ema_slow) / ema_slow * 100\n",
        "    signal_line = ewo.ewm(span=signal_period, adjust=False).mean()\n",
        "    histogram = ewo - signal_line\n",
        "    return ewo, signal_line, histogram\n",
        "\n",
        "def calculate_volatility(series, window=20):\n",
        "    return series.rolling(window).std().round(6)\n",
        "\n",
        "def calculate_sma5(series, period=5):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma13(series, period=13):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma26(series, period=26):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma50(series, period=50):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "def calculate_sma200(series, period=200):\n",
        "    return series.rolling(window=period).mean().round(4)\n",
        "\n",
        "\n",
        "def create_features(df, umbral, n_days_high=1):\n",
        "    df = add_lagged_price_features(df, \"close_lag\", \"Close\")\n",
        "    df = add_lagged_price_features(df, \"open_lag\", \"Open\")\n",
        "    df = add_lagged_price_features(df, \"high_lag\", \"High\")\n",
        "    df['Pct_change'] = df['Close'].pct_change()\n",
        "    for lag in range(1, 6):\n",
        "        df[f'lag_change{lag}'] = df['Pct_change'].shift(lag)\n",
        "    df['RSI'] = calculate_RSI(df['Close'])\n",
        "    df['ROC'] = calculate_ROC(df['Close'])\n",
        "    df['PPO'], df['PPO_Signal'], df['PPO_Histogram'] = calculate_PPO(df['Close'])\n",
        "    df['EWO'], df['EWO_Signal'], df['EWO_Histogram'] = calculate_EWO(df['Close'])\n",
        "    df['SMA5'] = calculate_sma5(df['Close'])\n",
        "    df['SMA13'] = calculate_sma13(df['Close'])\n",
        "    df['SMA26'] = calculate_sma26(df['Close'])\n",
        "    df['SMA50'] = calculate_sma50(df['Close'])\n",
        "    df['SMA200'] = calculate_sma200(df['Close'])\n",
        "    df['Volatility'] = calculate_volatility(df['Close'])\n",
        "\n",
        "    # --- New Feature: Max Gain from Open over Past N Days ---\n",
        "    # Calculate the maximum High price over the *next N days* for *each historical day*.\n",
        "    # Use rolling().max() with min_periods=1 to handle ends of series.\n",
        "    # Then shift to align with the start of the N-day window (the current day's Open).\n",
        "    max_high_over_next_n_days_hist = df['High'].rolling(window=n_days_high, min_periods=1).max().shift(-n_days_high + 1)\n",
        "\n",
        "\n",
        "    # Calculate the potential max gain from Open for *each historical day*\n",
        "    # Using the Open price of that historical day\n",
        "    epsilon = 1e-9 # To prevent division by zero\n",
        "    df['Max_Gain_from_Open_Current'] = (max_high_over_next_n_days_hist - df['Open']) / (df['Open'] + epsilon)\n",
        "\n",
        "    # --- Add lagged versions of the new feature ---\n",
        "    for lag in range(1, 7): # Create lags from 1 to 6\n",
        "        df[f'Max_Gain_from_Open_Lag_{lag}'] = df['Max_Gain_from_Open_Current'].shift(lag)\n",
        "\n",
        "\n",
        "    # Calculate the target based on tomorrow's Open vs Max High over next n_days_high days\n",
        "    # Use rolling().max() with min_periods=1 for the target as well.\n",
        "    # Shift to align with the start of the N-day window for the target (tomorrow's Open).\n",
        "    max_high_next_n_days_target = df['High'].rolling(window=n_days_high, min_periods=1).max().shift(-n_days_high + 1)\n",
        "    open_next_day = df['Open'].shift(-1)\n",
        "    df['Label_raw'] = ((max_high_next_n_days_target - open_next_day) / (open_next_day + epsilon) > umbral).astype(int)\n",
        "    df['Label'] = df['Label_raw'].shift(-1) # Target for the next day\n",
        "\n",
        "\n",
        "    # Replace inf values with NaN before dropping\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Dropping NaNs here will remove rows where features or the target are still NaN (e.g., due to initial lags,\n",
        "    # or if min_periods=1 still results in NaN for very short series, although less likely now for the rolling max).\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Definir fecha de corte manualmente (cambiar diariamente)\n",
        "end_date = dt.datetime(2025, 9, 14)  # Ejemplo: cambiar a 2025-07-18 mañana\n",
        "\n",
        "tk =[ \"ALUA.BA\", \"BBAR.BA\", \"BMA.BA\", \"COME.BA\", \"CRES.BA\", \"EDN.BA\", \"GGAL.BA\", \"IRSA.BA\", \"LOMA.BA\", \"METR.BA\", \"PAMP.BA\", \"SUPV.BA\", \"TECO2.BA\", \"TGNO4.BA\", \"TGSU2.BA\", \"TRAN.BA\", \"TXAR.BA\", \"VALO.BA\", \"YPFD.BA\"]\n",
        "\n",
        "\n",
        "# results = [] # el del test, para que no lo reinicie - REMOVED\n",
        "resultsp = [] # las predicciones, para que no lo reinicie\n",
        "\n",
        "umbral = 0.019\n",
        "lapso = 1 # Lapso is no longer directly used for the target definition, but keeping it doesn't hurt\n",
        "n_days_high_target = 3 # Define the number of days for the High target (used for both target and new feature)\n",
        "\n",
        "# Define clipping bounds - adjust based on feature distributions\n",
        "lower_bound = -1e9\n",
        "upper_bound = 1e9\n",
        "\n",
        "\n",
        "for papel in tk:\n",
        "\n",
        "  symbol=papel\n",
        "  #symbol=\"COME.BA\"\n",
        "  # Fechas dinámicas\n",
        "  start_date = dt.datetime(2001, 1, 1)  # Inicio fijo\n",
        "  train_end = end_date - pd.Timedelta(days=780)  # 6 meses antes de end_date (ajustable)\n",
        "  next_day = end_date + pd.Timedelta(days=1)  # Predicción para el día siguiente\n",
        "\n",
        "\n",
        "  # Select features - Add the new feature and its lags\n",
        "  features = ['RSI', 'ROC', 'PPO', 'PPO_Signal', 'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'Volatility', 'SMA5', 'SMA13', 'SMA26', 'SMA50', 'SMA200' ] + [f'lag_change{i}' for i in range(1, 6)] + \\\n",
        "            [f'close_lag_{i}' for i in range(1, 6)] + [f'open_lag_{i}' for i in range(1, 6)]+ [f'high_lag_{i}' for i in range(1, 6)] + \\\n",
        "            ['Max_Gain_from_Open_Current'] + [f'Max_Gain_from_Open_Lag_{i}' for i in range(1, 7)]\n",
        "\n",
        "\n",
        "  # Download data for the current ticker inside the loop\n",
        "  print(f\"\\nDownloading data for {symbol}...\")\n",
        "  df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=False)\n",
        "\n",
        "  # Verify data download\n",
        "  if df.empty:\n",
        "      print(f\"Warning: No data downloaded for {symbol}. Skipping.\")\n",
        "      continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "  # Handle MultiIndex columns and ensure standard column names - More robust logic\n",
        "  required_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "  processed_df = None # Initialize processed_df\n",
        "\n",
        "  if isinstance(df.columns, pd.MultiIndex):\n",
        "      print(f\"MultiIndex columns detected for {symbol}.\")\n",
        "      try:\n",
        "          # Attempt to extract columns by looking for standard names in ANY level of the MultiIndex tuple\n",
        "          extracted_data = {}\n",
        "          for std_name in required_cols:\n",
        "              matching_col_tuple = None\n",
        "              # Iterate through all column tuples\n",
        "              for col_tuple in df.columns:\n",
        "                  # Check if the standard name exists in ANY level of the current tuple\n",
        "                  if std_name in col_tuple:\n",
        "                       matching_col_tuple = col_tuple\n",
        "                       break # Found a match in this tuple\n",
        "\n",
        "              if matching_col_tuple:\n",
        "                  extracted_data[std_name] = df[matching_col_tuple]\n",
        "              else:\n",
        "                  print(f\"Warning: Could not find standard column '{std_name}' in any level of MultiIndex for {symbol}. Column missing.\")\n",
        "                  # Continue to look for other required columns, processed_df will be checked later\n",
        "\n",
        "          if len(extracted_data) == len(required_cols):\n",
        "              processed_df = pd.DataFrame(extracted_data)\n",
        "              processed_df.index = df.index # Preserve original index\n",
        "              print(f\"Successfully extracted and flattened MultiIndex columns for {symbol}.\")\n",
        "          else:\n",
        "              missing_cols = [name for name in required_cols if name not in extracted_data]\n",
        "              print(f\"Warning: Could not extract all required columns from MultiIndex for {symbol}. Missing: {missing_cols}. Skipping ticker.\")\n",
        "              continue # Skip to the next ticker\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Warning: An error occurred while processing MultiIndex columns for {symbol}: {e}. Skipping.\")\n",
        "          #print(f\"Original columns: {df.columns.tolist()}\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "  else: # If not MultiIndex columns, assume standard flat DataFrame is already present\n",
        "      print(f\"No MultiIndex columns detected for {symbol}. Checking for standard columns.\")\n",
        "      # Check if the required columns are directly present\n",
        "      if all(col in df.columns for col in required_cols):\n",
        "          processed_df = df[required_cols].copy() # Select required columns and make a copy\n",
        "          print(f\"Using existing standard columns for {symbol}.\")\n",
        "      else:\n",
        "          missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "          print(f\"Warning: Required standard columns not found in flat DataFrame for {symbol}. Missing: {missing_cols}. Skipping ticker.\")\n",
        "          #print(f\"Available columns: {df.columns.tolist()}\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "  # Ensure df is set to processed_df if successful\n",
        "  df = processed_df\n",
        "\n",
        "  # Handle MultiIndex index if present (less common with single ticker download but possible)\n",
        "  if isinstance(df.index, pd.MultiIndex):\n",
        "      print(f\"MultiIndex index detected for {symbol}. Attempting to flatten index.\")\n",
        "      try:\n",
        "          # Assuming the MultiIndex index structure is ('Ticker', 'Date')\n",
        "          if 'Ticker' in df.index.names:\n",
        "               df = df.xs(symbol, level='Ticker', axis=0)\n",
        "               print(f\"Índice aplanado para {symbol}.\")\n",
        "          else:\n",
        "               print(f\"Warning: MultiIndex index detected for {symbol} but 'Ticker' level not found. Skipping index flattening.\")\n",
        "               # If 'Ticker' level is not there, maybe it's just a date/time MultiIndex?\n",
        "               # Or a different structure. For now, proceed without flattening index if Ticker level is missing.\n",
        "\n",
        "\n",
        "      except KeyError:\n",
        "          print(f\"Warning: Could not select ticker from MultiIndex index for {symbol}. Skipping.\")\n",
        "          continue # Skip to the next ticker\n",
        "      except Exception as e:\n",
        "          print(f\"Warning: An error occurred while flattening MultiIndex index for {symbol}: {e}. Skipping.\")\n",
        "          continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "  df.index = pd.to_datetime(df.index)\n",
        "  if not df.index.is_unique:\n",
        "      print(f\"Advertencia: Índice con fechas duplicadas para {symbol}. Eliminando duplicados...\")\n",
        "      df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after initial processing and cleaning for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  # Ensure numeric types and handle potential non-numeric data\n",
        "  for col in required_cols:\n",
        "      if col in df.columns: # Ensure column exists before processing\n",
        "          df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "      else:\n",
        "           # This should ideally not happen if previous checks passed, but as a safeguard:\n",
        "           print(f\"Error: Required column '{col}' not found in df for {symbol} before numeric conversion. Skipping ticker.\")\n",
        "           df = pd.DataFrame() # Set df to empty to skip further processing\n",
        "           break # Exit column processing loop\n",
        "\n",
        "\n",
        "  if df.empty: # Check again if df became empty due to missing columns\n",
        "       continue # Skip to the next ticker\n",
        "\n",
        "  # Drop rows where essential price data is missing after coercion\n",
        "  df.dropna(subset=['Open', 'High', 'Low', 'Close'], inplace=True)\n",
        "\n",
        "\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after dropping rows with missing price data for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  df['Open']= df['Open'].round(2)\n",
        "  df['High']= df['High'].round(2)\n",
        "  df['Low']= df['Low'].round(2)\n",
        "  df['Close']= df['Close'].round(2)\n",
        "  df['Adj Close']= df['Adj Close'].round(2)\n",
        "\n",
        "  print(\"Últimas filas del DataFrame antes de crear features:\")\n",
        "  print(df.tail())\n",
        "\n",
        "\n",
        "  # Crear features with the new target definition\n",
        "  df = create_features(df, umbral=umbral, n_days_high=n_days_high_target) # Pass n_days_high_target, removed lapso\n",
        "\n",
        "  # Verify data is not empty after feature creation and dropna\n",
        "  if df.empty:\n",
        "      print(f\"Warning: DataFrame is empty after feature creation and dropna for {symbol}. Skipping.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  # Verify data after creating features\n",
        "  print(f\"\\nÚltimas filas del DataFrame después de crear features:\")\n",
        "  print(df.tail())\n",
        "  print(df.columns)\n",
        "\n",
        "  # --- Add Historical Target Distribution Check ---\n",
        "  print(f\"\\nOverall historical target distribution for {symbol} (before train/test split):\")\n",
        "  historical_target_distribution = df[\"Label\"].value_counts(normalize=True)\n",
        "  print(historical_target_distribution)\n",
        "  if 0 not in historical_target_distribution.index or historical_target_distribution.loc[0] < 0.01: # Threshold for very low minority class percentage\n",
        "       print(f\"Warning: Historical 'Bajista' (Class 0) instances are very rare (<1%) or non-existent for {symbol}.\")\n",
        "  # --- End Historical Target Distribution Check ---\n",
        "\n",
        "\n",
        "  # --- Plot Feature Distributions for BBAR.BA by Class (Deep Dive) ---\n",
        "  # Keep plotting code commented out or removed if user cannot see them\n",
        "  # if symbol == \"BBAR.BA\":\n",
        "  #     print(f\"\\nDEBUG: Reached plotting section for {symbol}.\") # Debug print\n",
        "  #     print(f\"Generating feature distribution plots for {symbol} by target class...\")\n",
        "\n",
        "  #     # Create a directory to save plots\n",
        "  #     plot_dir = f\"{symbol}_feature_plots\"\n",
        "  #     if not os.path.exists(plot_dir):\n",
        "  #         os.makedirs(plot_dir)\n",
        "  #         print(f\"Created directory: {plot_dir}\")\n",
        "\n",
        "\n",
        "  #     # Select a subset of features to plot - choose some representative ones\n",
        "  #     features_to_plot = [\n",
        "  #         'RSI', 'ROC', 'PPO_Histogram', 'EWO_Histogram', 'Volatility',\n",
        "  #         'SMA5', 'lag_change1', 'Max_Gain_from_Open_Current', 'Max_Gain_from_Open_Lag_2'\n",
        "  #     ]\n",
        "\n",
        "  #     # Ensure selected features exist in the DataFrame\n",
        "  #     features_to_plot_existing = [f for f in features_to_plot if f in df.columns]\n",
        "\n",
        "  #     if not features_to_plot_existing:\n",
        "  #         print(f\"Warning: None of the selected features for plotting exist in the DataFrame for {symbol}.\")\n",
        "  #     else:\n",
        "  #         # Use the full historical data (after feature creation and dropna) for these plots\n",
        "  #         plot_df = df[features_to_plot_existing + ['Label']].copy()\n",
        "  #         plot_df['Label'] = plot_df['Label'].astype(str) # Convert label to string for plotting hue\n",
        "\n",
        "  #         # Set up the plotting style\n",
        "  #         sns.set_style(\"whitegrid\")\n",
        "\n",
        "  #         for feature in features_to_plot_existing:\n",
        "  #             plt.figure(figsize=(10, 5))\n",
        "  #             # Use histplot for distributions\n",
        "  #             sns.histplot(data=plot_df, x=feature, hue='Label', kde=True, palette='viridis', common_norm=False, stat='density') # common_norm=False & stat='density' for comparing shapes regardless of class counts\n",
        "  #             plt.title(f'Distribution of {feature} for {symbol} by Target Class')\n",
        "  #             plt.xlabel(feature)\n",
        "  #             plt.ylabel('Density') # Changed from Frequency to Density\n",
        "  #             plt.legend(title='Target', labels=['Alcista (1)', 'Bajista (0)']) # Customize legend labels\n",
        "\n",
        "  #             # Save the plot to a file\n",
        "  #             plot_filename = os.path.join(plot_dir, f\"{symbol}_{feature}_distribution.png\")\n",
        "  #             plt.savefig(plot_filename)\n",
        "  #             print(f\"Saved plot: {plot_filename}\")\n",
        "\n",
        "  #             plt.close() # Close the plot figure to free up memory\n",
        "\n",
        "  #     print(\"Finished generating and saving feature distribution plots for BBAR.BA.\")\n",
        "  # --- End Plot Feature Distributions ---\n",
        "\n",
        "  # --- Add Feature Distribution Analysis Table for ALL Tickers by Class ---\n",
        "  # This block should run regardless of run_full_model flag\n",
        "  print(f\"\\nDEBUG: Reached feature distribution table analysis section for {symbol}.\")\n",
        "  print(f\"Generating feature distribution analysis table for {symbol} by target class...\")\n",
        "\n",
        "  # Use the full historical data (after feature creation and dropna) for this analysis\n",
        "  analysis_df = df[features + ['Label']].copy() # Use all features for table analysis\n",
        "\n",
        "  if analysis_df.empty:\n",
        "       print(f\"Warning: DataFrame is empty for feature distribution analysis for {symbol}.\")\n",
        "  elif 'Label' not in analysis_df.columns:\n",
        "       print(f\"Error: 'Label' column not found in DataFrame for feature distribution analysis for {symbol}.\")\n",
        "  elif len(analysis_df['Label'].unique()) < 2:\n",
        "       print(f\"Warning: Only one class exists in 'Label' for feature distribution analysis for {symbol}. Cannot group by class.\")\n",
        "       # Even if only one class, we can still show the describe table for that class\n",
        "       print(f\"\\nFeature Distribution Analysis Table for {symbol} (Only one class):\")\n",
        "       display(analysis_df.describe().transpose()) # Show describe for the single class\n",
        "  else: # This else should be aligned with the if/elif above\n",
        "      # Group by Label and calculate descriptive statistics for all features\n",
        "      feature_distribution_table = analysis_df.groupby('Label').describe().transpose()\n",
        "\n",
        "      print(f\"\\nFeature Distribution Analysis Table for {symbol} by Target Class:\")\n",
        "      display(feature_distribution_table) # Use display for better formatting\n",
        "\n",
        "  print(f\"Finished generating feature distribution analysis table for {symbol}.\") # This print should be aligned with the if/elif/else block\n",
        "  # --- End Feature Distribution Analysis Table ---\n",
        "\n",
        "\n",
        "  # --- Start of block for full model run (training, tuning, prediction, results table) ---\n",
        "  if run_full_model:\n",
        "      # Dividir datos en entrenamiento y prueba (moved inside the if run_full_model block)\n",
        "      X = df[features]\n",
        "      y = df['Label']\n",
        "      X_train_full = X[df.index <= train_end]\n",
        "      y_train_full = y[df.index <= train_end]\n",
        "      X_test = X[(df.index > train_end) & (df.index <= end_date)]  # Hasta end_date\n",
        "      y_test = y[(df.index > train_end) & (df.index <= end_date)]\n",
        "\n",
        "      # Check if original training data is sufficient BEFORE proceeding\n",
        "      if not X_train_full.empty and not y_train_full.empty and len(y_train_full.unique()) > 1:\n",
        "\n",
        "          correlation = df[features + [\"Label\"]].corr()[\"Label\"].sort_values(ascending=False)\n",
        "          print(f\"Correlacion con label para {symbol}:\")\n",
        "          print(correlation)\n",
        "\n",
        "          # Initialize test metrics before evaluation (only if model runs)\n",
        "          precision_test_alcista = None\n",
        "          recall_test_alcista = None\n",
        "          f1_test_alcista = None\n",
        "          roc_auc_test = None\n",
        "          ratio_1_test = None\n",
        "          best_model = None # Initialize best_model to None\n",
        "          best_threshold = 0.5 # Initialize best_threshold to default\n",
        "\n",
        "\n",
        "          # Optimizar hiperparámetros con RandomizedSearchCV\n",
        "          print(f\"Optimizar hiperparámetros con RandomizedSearchCV para {symbol}\")\n",
        "          param_dist = {\n",
        "              'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "              'max_depth': [3, 5, 7, 9],\n",
        "              'n_estimators': [100, 500, 900],\n",
        "              'subsample': [0.6, 0.8, 1.0],\n",
        "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "              'gamma': [0, 0.1, 0.2],\n",
        "              'scale_pos_weight': [0.5, 1, 2, 5, 10, 20, 50, 100] # Incluir scale_pos_weight en la búsqueda\n",
        "          }\n",
        "\n",
        "          # Inicializar el clasificador XGBoost sin scale_pos_weight fijo (se tuneará)\n",
        "          xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "          # Usar TimeSeriesSplit para cross-validation\n",
        "          n_splits = 5  # Puedes ajustar el número de splits\n",
        "          tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "          # Definir scorer para maximizar Precision de la Clase 1 (for RandomizedSearchCV)\n",
        "          precision_scorer = make_scorer(precision_score, pos_label=1, zero_division=0) # zero_division=0 para manejar casos sin predicciones positivas\n",
        "\n",
        "          # Clean X_train_full and y_train_full before fitting RandomizedSearchCV and SMOTE\n",
        "          X_train_full_cleaned_for_tuning = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "          X_train_full_cleaned_for_tuning.dropna(inplace=True)\n",
        "          y_train_full_cleaned_for_tuning = y_train_full.loc[X_train_full_cleaned_for_tuning.index] # Ensure y matches cleaned X\n",
        "\n",
        "          # Explicit check, conversion, and fallback for non-finite values before fitting RandomizedSearchCV\n",
        "          X_train_full_cleaned_for_tuning = X_train_full_cleaned_for_tuning.astype(np.float64) # Ensure dtype\n",
        "          if not np.isfinite(X_train_full_cleaned_for_tuning).all().all():\n",
        "              print(f\"\\nWarning: Non-finite values detected in X_train_full_cleaned_for_tuning for {symbol} before RandomizedSearchCV fit. Attempting to fill with median.\")\n",
        "              for col in X_train_full_cleaned_for_tuning.columns:\n",
        "                  finite_values = X_train_full_cleaned_for_tuning[col][np.isfinite(X_train_full_cleaned_for_tuning[col])]\n",
        "                  if not finite_values.empty:\n",
        "                      median_val = finite_values.median()\n",
        "                      X_train_full_cleaned_for_tuning[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                      X_train_full_cleaned_for_tuning[col].fillna(median_val, inplace=True)\n",
        "                  else:\n",
        "                      print(f\"Warning: Column '{col}' in X_train_full_cleaned_for_tuning is all non-finite. Filling with 0.\")\n",
        "                      X_train_full_cleaned_for_tuning[col].fillna(0, inplace=True)\n",
        "\n",
        "          # --- Apply SMOTE to the training data ---\n",
        "          X_train_res, y_train_res = X_train_full_cleaned_for_tuning.copy(), y_train_full_cleaned_for_tuning.copy() # Initialize with cleaned data\n",
        "          # Check if resampling is needed and possible\n",
        "          if len(y_train_full_cleaned_for_tuning.unique()) > 1 and y_train_full_cleaned_for_tuning.value_counts().min() > 1: # SMOTE needs at least 2 samples of the minority class\n",
        "              try:\n",
        "                  print(f\"\\nApplying SMOTE to training data for {symbol}...\")\n",
        "                  sm = SMOTE(random_state=42)\n",
        "                  X_train_res, y_train_res = sm.fit_resample(X_train_full_cleaned_for_tuning, y_train_full_cleaned_for_tuning)\n",
        "                  print(f\"Original training data shape: {X_train_full_cleaned_for_tuning.shape}, Resampled shape: {X_train_res.shape}\")\n",
        "                  print(f\"Original training target distribution: {y_train_full_cleaned_for_tuning.value_counts()}, Resampled target distribution: {y_train_res.value_counts()}\")\n",
        "              except Exception as e:\n",
        "                  print(f\"\\nWarning: Could not apply SMOTE to training data for {symbol}: {e}. Proceeding with original imbalanced training data.\")\n",
        "                  # X_train_res and y_train_res remain the original cleaned training data\n",
        "          elif len(y_train_full_cleaned_for_tuning.unique()) == 1:\n",
        "               print(f\"\\nWarning: Only one class in training data for {symbol} after cleaning. Cannot apply SMOTE.\")\n",
        "               # X_train_res and y_train_res remain the original cleaned training data\n",
        "          else: # Not enough samples for SMOTE (e.g., only 1 minority sample)\n",
        "              print(f\"\\nWarning: Not enough samples in minority class for SMOTE for {symbol}. Proceeding with original imbalanced training data.\")\n",
        "              # X_train_res and y_train_res remain the original cleaned training data\n",
        "\n",
        "\n",
        "          # Check if resampled data is sufficient for tuning and evaluation\n",
        "          if not X_train_res.empty and not y_train_res.empty and len(y_train_res.unique()) > 1:\n",
        "              # Perform tuning, evaluation, and prediction within a general try-except block\n",
        "              # to prevent script crash on problematic tickers\n",
        "              try:\n",
        "                  # Fit RandomizedSearchCV on the resampled training data\n",
        "                  random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=20, cv=tscv, scoring=precision_scorer, n_jobs=-1, random_state=42) # Usar precision_scorer\n",
        "                  random_search.fit(X_train_res, y_train_res) # Fit on resampled data\n",
        "                  print(f\"Mejores hiperparámetros para {symbol}:\", random_search.best_params_)\n",
        "\n",
        "                  # Usar el mejor modelo encontrado por RandomizedSearchCV\n",
        "                  best_model = random_search.best_estimator_\n",
        "\n",
        "                  # Get and print feature importance (fitted on resampled data)\n",
        "                  feature_importance = pd.Series(best_model.feature_importances_, index=features)\n",
        "                  print(f\"\\nFeature Importance for {symbol}:\")\n",
        "                  print(feature_importance.sort_values(ascending=False))\n",
        "\n",
        "                  # Optimize the threshold for maximum F1-score on the full original training set (NOT resampled)\n",
        "                  # Threshold optimization should reflect real-world data distribution\n",
        "                  X_train_full_cleaned_for_threshold = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "                  X_train_full_cleaned_for_threshold.dropna(inplace=True)\n",
        "                  y_train_full_cleaned_for_threshold = y_train_full.loc[X_train_full_cleaned_for_threshold.index]\n",
        "\n",
        "                  if not X_train_full_cleaned_for_threshold.empty and not y_train_full_cleaned_for_threshold.empty and len(y_train_full_cleaned_for_threshold.unique()) > 1:\n",
        "                      # Predict probabilities on the ORIGINAL cleaned training data for threshold optimization\n",
        "                      y_train_prob = best_model.predict_proba(X_train_full_cleaned_for_threshold)[:, 1]\n",
        "                      thresholds = np.arange(0.01, 1.0, 0.01)\n",
        "                      best_threshold = 0.5\n",
        "                      best_f1 = 0 # Changed from best_precision to best_f1\n",
        "\n",
        "                      print(f\"Optimizing threshold for maximum F1-score on training data (ORIGINAL distribution) for {symbol}...\") # Updated message\n",
        "                      # Calculate F1-score for each threshold\n",
        "                      for threshold in thresholds:\n",
        "                          y_pred_threshold = (y_train_prob >= threshold).astype(int)\n",
        "                          # Calculate f1_score (handles zero_division internally based on scikit-learn version)\n",
        "                          f1 = f1_score(y_train_full_cleaned_for_threshold, y_pred_threshold, zero_division=0)\n",
        "                          if f1 > best_f1:\n",
        "                              best_f1 = f1\n",
        "                              best_threshold = threshold\n",
        "\n",
        "                      print(f\"Mejor umbral para maximizar F1-score en entrenamiento (ORIGINAL distribution) para {symbol}: {best_threshold:.4f} (F1-score: {best_f1:.4f})\") # Updated message and metric\n",
        "                  else:\n",
        "                      print(f\"\\nWarning: Original training set for {symbol} contains no samples or only one class after cleaning for threshold optimization. Cannot optimize threshold for F1-score. Using default threshold 0.5.\") # Updated message\n",
        "                      best_threshold = 0.5\n",
        "\n",
        "\n",
        "                  # Evaluar el modelo en el conjunto de prueba con el best threshold (Test set is NOT resampled)\n",
        "                  if not X_test.empty and not y_test.empty and len(y_test.unique()) > 1:\n",
        "                      print(f\"\\nEvaluating best model on test set for {symbol} with best threshold ({best_threshold:.4f}):\")\n",
        "\n",
        "                      # Clean X_test before evaluation\n",
        "                      X_test_cleaned = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "                      y_test_cleaned = y_test.loc[X_test_cleaned.index]\n",
        "\n",
        "                      # Scale X_test using the scaler fitted on the ORIGINAL training data\n",
        "                      scaler = RobustScaler()\n",
        "                      # Fit scaler on the ORIGINAL cleaned training data (NOT resampled)\n",
        "                      X_train_full_cleaned_for_scaler_eval = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "                      X_train_full_cleaned_for_scaler_eval.dropna(inplace=True)\n",
        "                      X_train_full_cleaned_for_scaler_eval = X_train_full_cleaned_for_scaler_eval.clip(lower=lower_bound, upper=upper_bound)\n",
        "                      X_train_full_cleaned_for_scaler_eval = X_train_full_cleaned_for_scaler_eval.astype(np.float64)\n",
        "\n",
        "                      if not X_train_full_cleaned_for_scaler_eval.empty and np.isfinite(X_train_full_cleaned_for_scaler_eval).all().all():\n",
        "                          scaler.fit(X_train_full_cleaned_for_scaler_eval)\n",
        "\n",
        "                          X_test_cleaned = X_test_cleaned.astype(np.float64)\n",
        "                          if not np.isfinite(X_test_cleaned).all().all():\n",
        "                               print(f\"\\nWarning: Non-finite values detected in X_test_cleaned for {symbol} before scaler transform. Attempting to fill with median (from train data).\")\n",
        "                               train_medians = X_train_full_cleaned_for_scaler_eval.median()\n",
        "                               for col in X_test_cleaned.columns:\n",
        "                                   median_val = train_medians.get(col, 0)\n",
        "                                   X_test_cleaned[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                                   X_test_cleaned[col].fillna(median_val, inplace=True)\n",
        "                               if not np.isfinite(X_test_cleaned).all().all():\n",
        "                                    print(f\"\\nERROR: Non-finite values STILL detected in X_test_cleaned for {symbol} after filling with median!\")\n",
        "\n",
        "\n",
        "                          if not X_test_cleaned.empty and np.isfinite(X_test_cleaned).all().all():\n",
        "                              X_test_scaled = scaler.transform(X_test_cleaned)\n",
        "\n",
        "                              y_test_pred_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "                              y_test_pred = (y_test_pred_prob >= best_threshold).astype(int)\n",
        "\n",
        "                              if len(y_test_cleaned.unique()) > 1:\n",
        "                                  print(f\"\\nClassification Report (Test Set) for {symbol}:\")\n",
        "                                  print(classification_report(y_test_cleaned, y_test_pred, zero_division=0))\n",
        "                                  precision_test_alcista = precision_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "                                  recall_test_alcista = recall_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "                                  f1_test_alcista = f1_score(y_test_cleaned, y_test_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "                                  print(f\"Tamaño de y_test (cleaned): {y_test_cleaned.size}\")\n",
        "                                  print(f\"Distribución de clases en y_test (cleaned) para {symbol}:\")\n",
        "                                  print(y_test_cleaned.value_counts())\n",
        "                                  if 1 in y_test_cleaned.value_counts():\n",
        "                                      ratio_1_test=(y_test_cleaned.value_counts()[1]/y_test_cleaned.size).round(4)\n",
        "                                  else:\n",
        "                                      ratio_1_test = 0\n",
        "                                  print(f\"% clase 1 test para {symbol}: {ratio_1_test} \")\n",
        "\n",
        "                                  if len(y_test_cleaned.unique()) > 1:\n",
        "                                       roc_auc_test = roc_auc_score(y_test_cleaned, y_test_pred_prob).round(6)\n",
        "                                       print(f\"\\nROC-AUC (Test Set) para {symbol}: {roc_auc_test:.4f}\")\n",
        "                                  else:\n",
        "                                       roc_auc_test = None\n",
        "                                       print(f\"\\nWarning: Test set for {symbol} contains only one class after cleaning. Cannot calculate ROC-AUC.\")\n",
        "\n",
        "                              else:\n",
        "                                  print(f\"\\nWarning: Test set for {symbol} contains only one class after cleaning. Cannot generate full classification report.\")\n",
        "                                  precision_test_alcista = None\n",
        "                                  recall_test_alcista = None\n",
        "                                  f1_test_alcista = None\n",
        "                                  roc_auc_test = None\n",
        "                                  ratio_1_test = None\n",
        "\n",
        "\n",
        "                          else:\n",
        "                              print(f\"\\nWarning: X_test became empty after cleaning or contains non-finite values for {symbol}. Skipping test evaluation.\")\n",
        "                              precision_test_alcista = None\n",
        "                              recall_test_alcista = None\n",
        "                              f1_test_alcista = None\n",
        "                              roc_auc_test = None\n",
        "                              ratio_1_test = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                      else:\n",
        "                          print(f\"\\nAdvertencia: Conjunto de prueba insuficiente o con una sola clase para evaluación para {symbol}.\")\n",
        "                          precision_test_alcista = None\n",
        "                          recall_test_alcista = None\n",
        "                          f1_test_alcista = None\n",
        "                          roc_auc_test = None\n",
        "                          ratio_1_test = None\n",
        "\n",
        "                      # Prediction for the next day is done only if model was trained successfully\n",
        "                      last_features = df[features].iloc[-1:]\n",
        "                      last_features_cleaned = None\n",
        "                      last_features_scaled = None\n",
        "                      future_pred_prob = None\n",
        "                      future_pred = None\n",
        "\n",
        "                      if not last_features.empty:\n",
        "                          # Ensure last_features is a single row DataFrame before cleaning\n",
        "                          if not isinstance(last_features, pd.DataFrame) or len(last_features) != 1:\n",
        "                               print(f\"\\nError: last_features is not a single row DataFrame for {symbol}. Skipping prediction.\")\n",
        "                               # Set prediction results to skipped\n",
        "                               last_data_date = df.index[-1] if not df.empty else None\n",
        "                               last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                               resultsp.append({\n",
        "                                   'Papel': symbol,\n",
        "                                   'Fecha Predicción': next_day,\n",
        "                                   'Fecha Datos': last_data_date,\n",
        "                                   'Predicción': 'Skipped (Prediction Data Error)',\n",
        "                                   'Precio actual': last_close,\n",
        "                                   'Probabilidad Alcista (Modelo)': None,\n",
        "                                   'Umbral de Clasificación': None,\n",
        "                                   'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                                   'Precision Test (Alcista)': precision_test_alcista,\n",
        "                                   'Recall Test (Alcista)': recall_test_alcista,\n",
        "                                   'F1 Test (Alcista)': f1_test_alcista,\n",
        "                                   'ROC-AUC Test': roc_auc_test,\n",
        "                                   'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                                   'Features Limpias (Predicción)': None,\n",
        "                                   'Features Escaladas (Predicción)': None\n",
        "                               })\n",
        "                               # No need to continue here, the append is done and we move to the next ticker\n",
        "                               continue # Skip to the next ticker\n",
        "\n",
        "\n",
        "                          last_features_cleaned = last_features.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "                          last_features_cleaned = last_features_cleaned.clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "                          # Add checks for NaN, Inf, and Zero in cleaned features BEFORE scaling\n",
        "                          has_nan_cleaned = last_features_cleaned.isna().any().any()\n",
        "                          has_inf_cleaned = np.isinf(last_features_cleaned).any().any()\n",
        "                          has_zero_cleaned = (last_features_cleaned == 0).any().any()\n",
        "\n",
        "                          if has_nan_cleaned:\n",
        "                              print(f\"\\nDEBUG: NaN values detected in last_features_cleaned for {symbol}.\")\n",
        "                          if has_inf_cleaned:\n",
        "                              print(f\"\\nDEBUG: Inf values detected in last_features_cleaned for {symbol}.\")\n",
        "                          if has_zero_cleaned:\n",
        "                               print(f\"\\nDEBUG: Zero values detected in last_features_cleaned for {symbol}.\")\n",
        "\n",
        "\n",
        "                          if not last_features_cleaned.empty and np.isfinite(last_features_cleaned).all().all():\n",
        "                              # Ensure scaler is fitted on the *cleaned* full training data\n",
        "                              scaler = RobustScaler()\n",
        "                              # Fit scaler on the ORIGINAL cleaned training data (NOT resampled)\n",
        "                              X_train_full_cleaned_for_scaler_pred = X_train_full.replace([np.inf, -np.inf], np.nan)\n",
        "                              X_train_full_cleaned_for_scaler_pred.dropna(inplace=True)\n",
        "                              X_train_full_cleaned_for_scaler_pred = X_train_full_cleaned_for_scaler_pred.clip(lower=lower_bound, upper=upper_bound)\n",
        "                              X_train_full_cleaned_for_scaler_pred = X_train_full_cleaned_for_scaler_pred.astype(np.float64)\n",
        "\n",
        "                              if not X_train_full_cleaned_for_scaler_pred.empty and np.isfinite(X_train_full_cleaned_for_scaler_pred).all().all():\n",
        "                                   scaler.fit(X_train_full_cleaned_for_scaler_pred)\n",
        "\n",
        "                                   last_features_cleaned = last_features_cleaned.astype(np.float64)\n",
        "                                   # Add explicit fallback for non-finite values AFTER dropna for prediction data\n",
        "                                   # This fallback is actually redundant if dropna() was called just above and np.isfinite checked,\n",
        "                                   # but keeping it for safety if flow changes. The main checks should be BEFORE scaling.\n",
        "                                   # Let's rely on the check and skip if still non-finite after cleaning.\n",
        "\n",
        "                                   if not last_features_cleaned.empty and np.isfinite(last_features_cleaned).all().all():\n",
        "                                       last_features_scaled = scaler.transform(last_features_cleaned)\n",
        "\n",
        "                                       # Add checks for NaN, Inf, and Zero in scaled features BEFORE prediction\n",
        "                                       has_nan_scaled = np.isnan(last_features_scaled).any()\n",
        "                                       has_inf_scaled = np.isinf(last_features_scaled).any()\n",
        "                                       has_zero_scaled = (last_features_scaled == 0).any()\n",
        "\n",
        "                                       if has_nan_scaled:\n",
        "                                           print(f\"\\nDEBUG: NaN values detected in last_features_scaled for {symbol}.\")\n",
        "                                       if has_inf_scaled:\n",
        "                                           print(f\"\\nDEBUG: Inf values detected in last_features_scaled for {symbol}.\")\n",
        "                                       if has_zero_scaled:\n",
        "                                            print(f\"\\nDEBUG: Zero values detected in last_features_scaled for {symbol}.\")\n",
        "\n",
        "\n",
        "                                       future_pred_prob = best_model.predict_proba(last_features_scaled)[:, 1][0].round(4)\n",
        "                                       future_pred = 1 if future_pred_prob >= best_threshold else 0\n",
        "\n",
        "                                       last_close = None\n",
        "                                       last_open = None\n",
        "                                       last_max = None\n",
        "                                       if not df.empty:\n",
        "                                           last_close = df['Close'].iloc[-1]\n",
        "                                           last_open = df['Open'].iloc[-1]\n",
        "                                           last_max = df['High'].iloc[-1]\n",
        "                                           last_data_date = df.index[-1]\n",
        "                                       else:\n",
        "                                           print(f\"Warning: DataFrame 'df' is empty for {symbol}. Cannot get last prices.\")\n",
        "                                           last_data_date = None\n",
        "\n",
        "                                       action = 'BUY' if future_pred == 1 else 'SELL'\n",
        "                                       direction = 1 if future_pred == 1 else -1\n",
        "\n",
        "                                       # Explicitly use to_dict() and tolist()\n",
        "                                       cleaned_features_dict = last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None\n",
        "                                       scaled_features_list = last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "\n",
        "\n",
        "                                       resultsp.append({\n",
        "                                                   'Papel': symbol,\n",
        "                                                   'Fecha Predicción': next_day,\n",
        "                                                   'Fecha Datos': last_data_date,\n",
        "                                                   'Predicción': 'Alcista' if future_pred == 1 else 'Bajista',\n",
        "                                                   'Probabilidad Alcista (Modelo)': future_pred_prob,\n",
        "                                                   'Umbral de Clasificación': best_threshold.round(4),\n",
        "                                                   'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)', # Add check for best_model\n",
        "                                                   'Precision Test (Alcista)': precision_test_alcista,\n",
        "                                                   'Recall Test (Alcista)': recall_test_alcista,\n",
        "                                                   'F1 Test (Alcista)': f1_test_alcista,\n",
        "                                                   'ROC-AUC Test': roc_auc_test,\n",
        "                                                   'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                                                   'Features Limpias (Predicción)': cleaned_features_dict, # Add cleaned features using to_dict\n",
        "                                                   'Features Escaladas (Predicción)': scaled_features_list # Add scaled features as a list\n",
        "                                           })\n",
        "\n",
        "\n",
        "\n",
        "                          else:\n",
        "                               print(f\"Warning: Training data (X_train_full) became empty or contains non-finite values after cleaning for scaler fitting for prediction. Skipping prediction for {symbol}.\")\n",
        "                               last_data_date = df.index[-1] if not df.empty else None\n",
        "                               last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                               # Explicitly use None for feature columns if prediction skipped due to data issues\n",
        "                               resultsp.append({\n",
        "                                   'Papel': symbol,\n",
        "                                   'Fecha Predicción': next_day,\n",
        "                                   'Fecha Datos': last_data_date,\n",
        "                                   'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                                   'Precio actual': last_close,\n",
        "                                   'Probabilidad Alcista (Modelo)': None,\n",
        "                                   'Umbral de Clasificación': None,\n",
        "                                   'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                                   'Precision Test (Alcista)': precision_test_alcista,\n",
        "                                   'Recall Test (Alcista)': recall_test_alcista,\n",
        "                                   'F1 Test (Alcista)': f1_test_alcista,\n",
        "                                   'ROC-AUC Test': roc_auc_test,\n",
        "                                   'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                                    'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                                    'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                               })\n",
        "\n",
        "\n",
        "                      else:\n",
        "                          print(f\"Warning: Could not make prediction for {symbol} as last_features became empty or contains non-finite values after cleaning.\")\n",
        "                          last_data_date = df.index[-1] if not df.empty else None\n",
        "                          last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                          # Explicitly use None for feature columns if prediction skipped due to data issues\n",
        "                          resultsp.append({\n",
        "                              'Papel': symbol,\n",
        "                              'Fecha Predicción': next_day,\n",
        "                              'Fecha Datos': last_data_date,\n",
        "                              'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                              'Precio actual': last_close,\n",
        "                              'Probabilidad Alcista (Modelo)': None,\n",
        "                              'Umbral de Clasificación': None,\n",
        "                              'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                              'Precision Test (Alcista)': precision_test_alcista,\n",
        "                              'Recall Test (Alcista)': recall_test_alcista,\n",
        "                              'F1 Test (Alcista)': f1_test_alcista,\n",
        "                              'ROC-AUC Test': roc_auc_test,\n",
        "                              'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                       'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                       'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                          })\n",
        "\n",
        "\n",
        "                  else:\n",
        "                      print(f\"Warning: Could not make prediction for {symbol} as last_features was initially empty.\")\n",
        "                      last_data_date = df.index[-1] if not df.empty else None\n",
        "                      last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "                      # Explicitly use None for feature columns if prediction skipped due to data issues\n",
        "                      resultsp.append({\n",
        "                          'Papel': symbol,\n",
        "                          'Fecha Predicción': next_day,\n",
        "                          'Fecha Datos': last_data_date,\n",
        "                          'Predicción': 'Skipped (Prediction Data Issue)',\n",
        "                          'Precio actual': last_close,\n",
        "                          'Probabilidad Alcista (Modelo)': None,\n",
        "                          'Umbral de Clasificación': None,\n",
        "                          'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                          'Precision Test (Alcista)': precision_test_alcista,\n",
        "                          'Recall Test (Alcista)': recall_test_alcista,\n",
        "                          'F1 Test (Alcista)': f1_test_alcista,\n",
        "                          'ROC-AUC Test': roc_auc_test,\n",
        "                          'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                       'Features Limpias (Predicción)': last_features_cleaned.to_dict() if last_features_cleaned is not None and not last_features_cleaned.empty else None,\n",
        "                       'Features Escaladas (Predicción)': last_features_scaled.tolist()[0] if last_features_scaled is not None and last_features_scaled.size > 0 else None\n",
        "                      })\n",
        "\n",
        "\n",
        "              # Catch a general Exception during tuning/evaluation/prediction to prevent script crash\n",
        "              except Exception as e:\n",
        "                  print(f\"ERROR: An error occurred during tuning, evaluation, or prediction for {symbol}: {e}. Skipping this ticker.\")\n",
        "                  best_model = None\n",
        "                  best_threshold = 0.5\n",
        "                  precision_test_alcista = None\n",
        "                  recall_test_alcista = None\n",
        "                  f1_test_alcista = None\n",
        "                  roc_auc_test = None\n",
        "                  ratio_1_test = None\n",
        "\n",
        "                  last_data_date = df.index[-1] if not df.empty else None\n",
        "                  last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "                  # Append entry indicating skip due to general error, explicitly add None for feature columns\n",
        "                  resultsp.append({\n",
        "                        'Papel': symbol,\n",
        "                        'Fecha Predicción': next_day,\n",
        "                        'Fecha Datos': last_data_date,\n",
        "                        'Predicción': 'Skipped (Error)',\n",
        "                        'Precio actual': last_close,\n",
        "                        'Probabilidad Alcista (Modelo)': None,\n",
        "                        'Umbral de Clasificación': None,\n",
        "                        'Mejores hiperparámetros (Incluye scale_pos_weight)': str(random_search.best_params_) if best_model is not None else 'Skipped (Tuning Error)',\n",
        "                        'Precision Test (Alcista)': precision_test_alcista,\n",
        "                        'Recall Test (Alcista)': recall_test_alcista,\n",
        "                        'F1 Test (Alcista)': f1_test_alcista,\n",
        "                        'ROC-AUC Test': roc_auc_test,\n",
        "                        'clase 1 en test (cleaned)': ratio_1_test,\n",
        "                        'Features Limpias (Predicción)': None,\n",
        "                        'Features Escaladas (Predicción)': None\n",
        "                  })\n",
        "\n",
        "          else: # This else belongs to the check for sufficient RESAMPLED data\n",
        "              print(f\"Warning: Resampled training data is insufficient or has only one class for {symbol}. Skipping model training and prediction.\")\n",
        "              last_data_date = df.index[-1] if not df.empty else None\n",
        "              last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "              # Append entry indicating skip due to insufficient training data (resampled)\n",
        "              resultsp.append({\n",
        "                    'Papel': symbol,\n",
        "                    'Fecha Predicción': next_day,\n",
        "                    'Fecha Datos': last_data_date,\n",
        "                    'Predicción': 'Skipped (Insufficient Resampled Training Data)', # More specific message\n",
        "                    'Precio actual': last_close,\n",
        "                    'Probabilidad Alcista (Modelo)': None,\n",
        "                    'Umbral de Clasificación': None,\n",
        "                    'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Insufficient Resampled Training Data)',\n",
        "                    'Precision Test (Alcista)': None, # Set to None as no model ran\n",
        "                    'Recall Test (Alcista)': None, # Set to None as no model ran\n",
        "                    'F1 Test (Alcista)': None, # Set to None as no model ran\n",
        "                    'ROC-AUC Test': None, # Set to None as no model ran\n",
        "                    'clase 1 en test (cleaned)': None, # Set to None as no model ran\n",
        "                    'Features Limpias (Predicción)': None,\n",
        "                    'Features Escaladas (Predicción)': None\n",
        "              })\n",
        "\n",
        "\n",
        "      else: # This else belongs to the initial check for sufficient ORIGINAL training data\n",
        "          print(f\"Warning: Original training data is insufficient or has only one class for {symbol}. Skipping model training and prediction.\")\n",
        "          last_data_date = df.index[-1] if not df.empty else None\n",
        "          last_close = df['Close'].iloc[-1] if not df.empty and 'Close' in df.columns else None\n",
        "\n",
        "          # Append entry indicating skip due to insufficient training data (original)\n",
        "          resultsp.append({\n",
        "                'Papel': symbol,\n",
        "                'Fecha Predicción': next_day,\n",
        "                'Fecha Datos': last_data_date,\n",
        "                'Predicción': 'Skipped (Insufficient Original Training Data)', # More specific message\n",
        "                'Precio actual': last_close,\n",
        "                'Probabilidad Alcista (Modelo)': None,\n",
        "                'Umbral de Clasificación': None,\n",
        "                'Mejores hiperparámetros (Incluye scale_pos_weight)': 'Skipped (Insufficient Original Training Data)',\n",
        "                'Precision Test (Alcista)': None, # Set to None as no model ran\n",
        "                'Recall Test (Alcista)': None, # Set to None as no model ran\n",
        "                'F1 Test (Alcista)': None, # Set to None as no model ran\n",
        "                'ROC-AUC Test': None, # Set to None as no model ran\n",
        "                'clase 1 en test (cleaned)': None, # Set to None as no model ran\n",
        "                'Features Limpias (Predicción)': None,\n",
        "                'Features Escaladas (Predicción)': None\n",
        "          })\n",
        "\n",
        "\n",
        "  # --- End of block for full model run ---\n",
        "\n",
        "\n",
        "# Create prediction results table ONLY if the full model was run\n",
        "if run_full_model: # Moved this entire block inside the if condition\n",
        "    resultsp_df = pd.DataFrame(resultsp)\n",
        "    print(resultsp_df)\n",
        "    if not resultsp_df.empty:\n",
        "        resultsp_df.set_index('Fecha Predicción', inplace=True)\n",
        "\n",
        "        # Mostrar resultados de predicción\n",
        "        pd.set_option('display.max_columns', None)\n",
        "        #pd.set_option('display.max_rows', None) # Optional: display all rows\n",
        "        pd.set_option('display.max_colwidth', None) # Optional: display full content of columns\n",
        "\n",
        "        print(f\"\\nPrediccion para el proximo dia (hasta {next_day.strftime('%Y-%m-%d')}):\")\n",
        "        print(\"Nota: 'Fecha Predicción' es la fecha predicha; 'Fecha Datos' es la fecha de los datos usados.\")\n",
        "        display(resultsp_df) # Use display for better formatting\n",
        "\n",
        "        # Guardar y descargar el CSV de predicciones\n",
        "        resultsp_df.to_csv(f\"Predic_results_{end_date.strftime('%Y-%m-%d')}.csv\", sep=\";\")\n",
        "        files.download(f\"Predic_results_{end_date.strftime('%Y-%m-%d')}.csv\")\n",
        "        print(f\"\\nArchivo 'Predic_results_{end_date.strftime('%Y-%m-%d')}.csv' generado y descargado.\")\n",
        "    else:\n",
        "        print(\"\\nNo hay resultados de predicción para mostrar.\")\n",
        "else: # Add a message when skipping the full model run\n",
        "    print(\"\\n'run_full_model' is set to False. Skipping model training, tuning, evaluation, and prediction.\")\n",
        "    print(\"Feature distribution analysis tables for all tickers are displayed above.\")"
      ],
      "metadata": {
        "id": "NKQcw1hmEzhT",
        "outputId": "55767312-2ff8-4ea2-f66b-a0e3c87f2985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading data for ALUA.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex columns detected for ALUA.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for ALUA.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "             Open   High    Low  Close   Volume  Adj Close\n",
            "Date                                                      \n",
            "2025-09-08  670.0  705.0  600.0  696.5  1572445      696.5\n",
            "2025-09-09  700.0  713.0  678.5  694.0  1217950      694.0\n",
            "2025-09-10  700.0  716.5  691.5  702.0   641358      702.0\n",
            "2025-09-11  702.0  713.0  676.0  682.0  1443135      682.0\n",
            "2025-09-12  686.0  702.0  660.0  666.0   420245      666.0\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "             Open   High    Low  Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                      \n",
            "2025-09-04  710.0  717.0  685.0  696.0   949242      696.0        700.0   \n",
            "2025-09-05  680.0  696.0  664.0  686.0  2029661      686.0        696.0   \n",
            "2025-09-08  670.0  705.0  600.0  696.5  1572445      696.5        686.0   \n",
            "2025-09-09  700.0  713.0  678.5  694.0  1217950      694.0        696.5   \n",
            "2025-09-10  700.0  716.5  691.5  702.0   641358      702.0        694.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04        738.0        749.0        723.0        697.0       735.0   \n",
            "2025-09-05        700.0        738.0        749.0        723.0       710.0   \n",
            "2025-09-08        696.0        700.0        738.0        749.0       680.0   \n",
            "2025-09-09        686.0        696.0        700.0        738.0       670.0   \n",
            "2025-09-10        696.5        686.0        696.0        700.0       700.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04       751.0       710.0       700.0       737.0       742.0   \n",
            "2025-09-05       735.0       751.0       710.0       700.0       717.0   \n",
            "2025-09-08       710.0       735.0       751.0       710.0       696.0   \n",
            "2025-09-09       680.0       710.0       735.0       751.0       705.0   \n",
            "2025-09-10       670.0       680.0       710.0       735.0       713.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04       754.0       752.0       727.0       744.0   -0.005714   \n",
            "2025-09-05       742.0       754.0       752.0       727.0   -0.014368   \n",
            "2025-09-08       717.0       742.0       754.0       752.0    0.015306   \n",
            "2025-09-09       696.0       717.0       742.0       754.0   -0.003589   \n",
            "2025-09-10       705.0       696.0       717.0       742.0    0.011527   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.051491    -0.014686     0.035961     0.037303    -0.054274   \n",
            "2025-09-05    -0.005714    -0.051491    -0.014686     0.035961     0.037303   \n",
            "2025-09-08    -0.014368    -0.005714    -0.051491    -0.014686     0.035961   \n",
            "2025-09-09     0.015306    -0.014368    -0.005714    -0.051491    -0.014686   \n",
            "2025-09-10    -0.003589     0.015306    -0.014368    -0.005714    -0.051491   \n",
            "\n",
            "                  RSI       ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                   \n",
            "2025-09-04  40.764331 -0.143472 -0.267917    0.217375      -0.485293   \n",
            "2025-09-05  33.548387 -5.117566 -0.705336   -0.090195      -0.615141   \n",
            "2025-09-08  49.800797 -7.009346 -0.695150   -0.291847      -0.403303   \n",
            "2025-09-09  35.784314 -5.962060 -0.691674   -0.425122      -0.266552   \n",
            "2025-09-10  22.023810  0.285714 -0.491059   -0.447101      -0.043958   \n",
            "\n",
            "                 EWO  EWO_Signal  EWO_Histogram   SMA5     SMA13     SMA26  \\\n",
            "Date                                                                         \n",
            "2025-09-04 -0.277641    0.440168      -0.717810  721.2  708.3846  720.7308   \n",
            "2025-09-05 -1.276330   -0.131998      -1.144332  713.8  708.6154  718.2692   \n",
            "2025-09-08 -1.473545   -0.579180      -0.894365  703.3  709.9615  714.7885   \n",
            "2025-09-09 -1.669313   -0.942558      -0.726756  694.5  711.1923  711.7115   \n",
            "2025-09-10 -1.448619   -1.111245      -0.337374  694.9  711.9615  710.0577   \n",
            "\n",
            "             SMA50    SMA200  Volatility  Max_Gain_from_Open_Current  \\\n",
            "Date                                                                   \n",
            "2025-09-04  713.70  787.4300   20.275147                    0.009859   \n",
            "2025-09-05  714.30  786.6500   20.709520                    0.048529   \n",
            "2025-09-08  714.43  786.1225   20.323874                    0.069403   \n",
            "2025-09-09  714.19  785.5375   20.500497                    0.023571   \n",
            "2025-09-10  713.85  784.9925   20.122830                    0.023571   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_1  Max_Gain_from_Open_Lag_2  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.009524                  0.003995   \n",
            "2025-09-05                  0.009859                  0.009524   \n",
            "2025-09-08                  0.048529                  0.009859   \n",
            "2025-09-09                  0.069403                  0.048529   \n",
            "2025-09-10                  0.023571                  0.069403   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_3  Max_Gain_from_Open_Lag_4  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.061972                  0.077143   \n",
            "2025-09-05                  0.003995                  0.061972   \n",
            "2025-09-08                  0.009524                  0.003995   \n",
            "2025-09-09                  0.009859                  0.009524   \n",
            "2025-09-10                  0.048529                  0.009859   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_5  Max_Gain_from_Open_Lag_6  Label_raw  \\\n",
            "Date                                                                        \n",
            "2025-09-04                  0.020353                  0.027586          1   \n",
            "2025-09-05                  0.077143                  0.020353          1   \n",
            "2025-09-08                  0.061972                  0.077143          1   \n",
            "2025-09-09                  0.003995                  0.061972          1   \n",
            "2025-09-10                  0.009524                  0.003995          1   \n",
            "\n",
            "            Label  \n",
            "Date               \n",
            "2025-09-04    1.0  \n",
            "2025-09-05    1.0  \n",
            "2025-09-08    1.0  \n",
            "2025-09-09    1.0  \n",
            "2025-09-10    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "\n",
            "Overall historical target distribution for ALUA.BA (before train/test split):\n",
            "Label\n",
            "1.0    0.588778\n",
            "0.0    0.411222\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "DEBUG: Reached feature distribution table analysis section for ALUA.BA.\n",
            "Generating feature distribution analysis table for ALUA.BA by target class...\n",
            "\n",
            "Feature Distribution Analysis Table for ALUA.BA by Target Class:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Label                                   0.0          1.0\n",
              "RSI                      count  2272.000000  3253.000000\n",
              "                         mean     51.347561    51.600978\n",
              "                         std      24.330060    25.578069\n",
              "                         min       0.000000     0.000000\n",
              "                         25%      33.333333    32.558140\n",
              "...                                     ...          ...\n",
              "Max_Gain_from_Open_Lag_6 min       0.000000     0.000000\n",
              "                         25%       0.007240     0.009434\n",
              "                         50%       0.017961     0.024064\n",
              "                         75%       0.036085     0.049724\n",
              "                         max       0.271978     0.761421\n",
              "\n",
              "[328 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ebaa163-2e10-4813-8f39-05414dac8328\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">RSI</th>\n",
              "      <th>count</th>\n",
              "      <td>2272.000000</td>\n",
              "      <td>3253.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>51.347561</td>\n",
              "      <td>51.600978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>24.330060</td>\n",
              "      <td>25.578069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.333333</td>\n",
              "      <td>32.558140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Max_Gain_from_Open_Lag_6</th>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.007240</td>\n",
              "      <td>0.009434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.017961</td>\n",
              "      <td>0.024064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.036085</td>\n",
              "      <td>0.049724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.271978</td>\n",
              "      <td>0.761421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>328 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ebaa163-2e10-4813-8f39-05414dac8328')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ebaa163-2e10-4813-8f39-05414dac8328 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ebaa163-2e10-4813-8f39-05414dac8328');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0ae521dc-8eb6-47f6-b560-b4dd30be38a8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ae521dc-8eb6-47f6-b560-b4dd30be38a8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0ae521dc-8eb6-47f6-b560-b4dd30be38a8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6158490d-955d-4e11-a411-0536a3d8fe67\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_distribution_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6158490d-955d-4e11-a411-0536a3d8fe67 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_distribution_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_distribution_table",
              "summary": "{\n  \"name\": \"feature_distribution_table\",\n  \"rows\": 328,\n  \"fields\": [\n    {\n      \"column\": 0.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 765.2238199519054,\n        \"min\": -30.081300813008127,\n        \"max\": 2272.0,\n        \"num_unique_values\": 233,\n        \"samples\": [\n          59.4700196302817,\n          0.02717274512201592,\n          0.036085324893684614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1078.5419735017922,\n        \"min\": -35.48387096774193,\n        \"max\": 3253.0,\n        \"num_unique_values\": 215,\n        \"samples\": [\n          0.04972375687860558,\n          0.043801639410358854,\n          275.2852733169522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished generating feature distribution analysis table for ALUA.BA.\n",
            "Correlacion con label para ALUA.BA:\n",
            "Label                         1.000000\n",
            "Max_Gain_from_Open_Current    0.176044\n",
            "Volatility                    0.137457\n",
            "high_lag_1                    0.133648\n",
            "high_lag_2                    0.133553\n",
            "open_lag_1                    0.133132\n",
            "close_lag_2                   0.133121\n",
            "open_lag_2                    0.133050\n",
            "close_lag_1                   0.132892\n",
            "close_lag_3                   0.132868\n",
            "high_lag_3                    0.132730\n",
            "high_lag_4                    0.132608\n",
            "high_lag_5                    0.132543\n",
            "SMA5                          0.132482\n",
            "open_lag_4                    0.132300\n",
            "SMA13                         0.132219\n",
            "close_lag_5                   0.132119\n",
            "open_lag_3                    0.132067\n",
            "open_lag_5                    0.131868\n",
            "close_lag_4                   0.131611\n",
            "Max_Gain_from_Open_Lag_3      0.131285\n",
            "SMA26                         0.131199\n",
            "SMA50                         0.128918\n",
            "Max_Gain_from_Open_Lag_5      0.122891\n",
            "Max_Gain_from_Open_Lag_6      0.120744\n",
            "Max_Gain_from_Open_Lag_1      0.117974\n",
            "Max_Gain_from_Open_Lag_4      0.116613\n",
            "SMA200                        0.112518\n",
            "Max_Gain_from_Open_Lag_2      0.105624\n",
            "EWO_Signal                    0.039022\n",
            "EWO                           0.035932\n",
            "lag_change3                   0.030163\n",
            "PPO_Signal                    0.021733\n",
            "lag_change5                   0.016503\n",
            "PPO                           0.013751\n",
            "ROC                           0.007542\n",
            "lag_change2                   0.007511\n",
            "RSI                           0.004974\n",
            "lag_change1                  -0.001266\n",
            "lag_change4                  -0.003333\n",
            "EWO_Histogram                -0.007945\n",
            "PPO_Histogram                -0.016057\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para ALUA.BA\n",
            "\n",
            "Applying SMOTE to training data for ALUA.BA...\n",
            "Original training data shape: (5007, 41), Resampled shape: (5710, 41)\n",
            "Original training target distribution: Label\n",
            "1.0    2855\n",
            "0.0    2152\n",
            "Name: count, dtype: int64, Resampled target distribution: Label\n",
            "1.0    2855\n",
            "0.0    2855\n",
            "Name: count, dtype: int64\n",
            "Mejores hiperparámetros para ALUA.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for ALUA.BA:\n",
            "high_lag_2                    0.052892\n",
            "open_lag_2                    0.041731\n",
            "Volatility                    0.041620\n",
            "close_lag_3                   0.034146\n",
            "Max_Gain_from_Open_Current    0.033732\n",
            "high_lag_5                    0.030462\n",
            "close_lag_4                   0.026607\n",
            "EWO_Signal                    0.026522\n",
            "open_lag_3                    0.026499\n",
            "high_lag_4                    0.025456\n",
            "high_lag_1                    0.025166\n",
            "SMA200                        0.024395\n",
            "open_lag_5                    0.024391\n",
            "SMA26                         0.024065\n",
            "open_lag_4                    0.023691\n",
            "open_lag_1                    0.023583\n",
            "PPO_Histogram                 0.023138\n",
            "SMA13                         0.022596\n",
            "close_lag_1                   0.022082\n",
            "PPO_Signal                    0.021932\n",
            "SMA50                         0.021920\n",
            "close_lag_2                   0.021633\n",
            "high_lag_3                    0.021504\n",
            "Max_Gain_from_Open_Lag_3      0.021458\n",
            "Max_Gain_from_Open_Lag_6      0.021393\n",
            "EWO                           0.021269\n",
            "PPO                           0.020938\n",
            "close_lag_5                   0.020804\n",
            "ROC                           0.020780\n",
            "Max_Gain_from_Open_Lag_2      0.020727\n",
            "lag_change4                   0.020511\n",
            "lag_change3                   0.020349\n",
            "Max_Gain_from_Open_Lag_1      0.020236\n",
            "RSI                           0.019804\n",
            "Max_Gain_from_Open_Lag_5      0.019722\n",
            "lag_change5                   0.019284\n",
            "EWO_Histogram                 0.019177\n",
            "lag_change1                   0.019034\n",
            "Max_Gain_from_Open_Lag_4      0.018789\n",
            "lag_change2                   0.018495\n",
            "SMA5                          0.017466\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum F1-score on training data (ORIGINAL distribution) for ALUA.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor umbral para maximizar F1-score en entrenamiento (ORIGINAL distribution) para ALUA.BA: 0.3300 (F1-score: 0.9610)\n",
            "\n",
            "Evaluating best model on test set for ALUA.BA with best threshold (0.3300):\n",
            "\n",
            "Classification Report (Test Set) for ALUA.BA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       120\n",
            "         1.0       0.77      1.00      0.87       398\n",
            "\n",
            "    accuracy                           0.77       518\n",
            "   macro avg       0.38      0.50      0.43       518\n",
            "weighted avg       0.59      0.77      0.67       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para ALUA.BA:\n",
            "Label\n",
            "1.0    398\n",
            "0.0    120\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para ALUA.BA: 0.7683 \n",
            "\n",
            "ROC-AUC (Test Set) para ALUA.BA: 0.5747\n",
            "\n",
            "Downloading data for BBAR.BA...\n",
            "MultiIndex columns detected for BBAR.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for BBAR.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-09-08  5175.0  5175.0  4482.5  4507.5  1397504     4507.5\n",
            "2025-09-09  4600.0  4650.0  4385.0  4400.0   761818     4400.0\n",
            "2025-09-10  4550.0  4710.0  4475.0  4655.0   206731     4655.0\n",
            "2025-09-11  4695.0  4750.0  4542.5  4592.5   266476     4592.5\n",
            "2025-09-12  4680.0  4680.0  4310.0  4447.5   368480     4447.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-09-04  5580.0  5850.0  5510.0  5720.0   276714     5720.0       5540.0   \n",
            "2025-09-05  5840.0  5840.0  5410.0  5640.0   596771     5640.0       5720.0   \n",
            "2025-09-08  5175.0  5175.0  4482.5  4507.5  1397504     4507.5       5640.0   \n",
            "2025-09-09  4600.0  4650.0  4385.0  4400.0   761818     4400.0       4507.5   \n",
            "2025-09-10  4550.0  4710.0  4475.0  4655.0   206731     4655.0       4400.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       5620.0       5380.0       5520.0       5610.0      5650.0   \n",
            "2025-09-05       5540.0       5620.0       5380.0       5520.0      5580.0   \n",
            "2025-09-08       5720.0       5540.0       5620.0       5380.0      5840.0   \n",
            "2025-09-09       5640.0       5720.0       5540.0       5620.0      5175.0   \n",
            "2025-09-10       4507.5       5640.0       5720.0       5540.0      4600.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      5390.0      5650.0      5610.0      5620.0      5690.0   \n",
            "2025-09-05      5650.0      5390.0      5650.0      5610.0      5850.0   \n",
            "2025-09-08      5580.0      5650.0      5390.0      5650.0      5840.0   \n",
            "2025-09-09      5840.0      5580.0      5650.0      5390.0      5175.0   \n",
            "2025-09-10      5175.0      5840.0      5580.0      5650.0      4650.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      5650.0      5650.0      5680.0      5780.0    0.032491   \n",
            "2025-09-05      5690.0      5650.0      5650.0      5680.0   -0.013986   \n",
            "2025-09-08      5850.0      5690.0      5650.0      5650.0   -0.200798   \n",
            "2025-09-09      5840.0      5850.0      5690.0      5650.0   -0.023849   \n",
            "2025-09-10      5175.0      5840.0      5850.0      5690.0    0.057955   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.014235     0.044610    -0.025362    -0.016043     0.016304   \n",
            "2025-09-05     0.032491    -0.014235     0.044610    -0.025362    -0.016043   \n",
            "2025-09-08    -0.013986     0.032491    -0.014235     0.044610    -0.025362   \n",
            "2025-09-09    -0.200798    -0.013986     0.032491    -0.014235     0.044610   \n",
            "2025-09-10    -0.023849    -0.200798    -0.013986     0.032491    -0.014235   \n",
            "\n",
            "                  RSI        ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                    \n",
            "2025-09-04  47.663551   1.960784 -1.936610   -2.960132       1.023522   \n",
            "2025-09-05  56.666667   2.173913 -1.528495   -2.482919       0.954424   \n",
            "2025-09-08  21.621622 -16.217472 -4.015444   -2.993761      -1.021683   \n",
            "2025-09-09  21.428571 -21.708185 -5.516746   -3.834756      -1.681990   \n",
            "2025-09-10  32.530120 -15.974729 -5.338977   -4.336163      -1.002814   \n",
            "\n",
            "                  EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13  \\\n",
            "Date                                                                  \n",
            "2025-09-04 -11.661127  -12.282763       0.621637  5556.0  5836.1538   \n",
            "2025-09-05 -11.034682  -11.866736       0.832054  5580.0  5770.0000   \n",
            "2025-09-08 -15.607353  -13.113608      -2.493744  5405.5  5615.9615   \n",
            "2025-09-09 -18.871697  -15.032971      -3.838726  5161.5  5476.7308   \n",
            "2025-09-10 -19.519353  -16.528432      -2.990921  4984.5  5360.9615   \n",
            "\n",
            "                SMA26    SMA50     SMA200  Volatility  \\\n",
            "Date                                                    \n",
            "2025-09-04  6534.6154  6558.40  7388.4000  750.249081   \n",
            "2025-09-05  6475.0000  6535.60  7386.0000  722.840887   \n",
            "2025-09-08  6371.8269  6489.95  7379.0375  772.329983   \n",
            "2025-09-09  6273.7500  6443.35  7371.1375  799.949947   \n",
            "2025-09-10  6177.7885  6404.85  7363.8125  773.324792   \n",
            "\n",
            "            Max_Gain_from_Open_Current  Max_Gain_from_Open_Lag_1  \\\n",
            "Date                                                               \n",
            "2025-09-04                    0.048387                  0.035398   \n",
            "2025-09-05                    0.000000                  0.048387   \n",
            "2025-09-08                    0.000000                  0.000000   \n",
            "2025-09-09                    0.032609                  0.000000   \n",
            "2025-09-10                    0.043956                  0.032609   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_2  Max_Gain_from_Open_Lag_3  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.085343                  0.007080   \n",
            "2025-09-05                  0.035398                  0.085343   \n",
            "2025-09-08                  0.048387                  0.035398   \n",
            "2025-09-09                  0.000000                  0.048387   \n",
            "2025-09-10                  0.000000                  0.000000   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_4  Max_Gain_from_Open_Lag_5  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.012478                  0.028470   \n",
            "2025-09-05                  0.007080                  0.012478   \n",
            "2025-09-08                  0.085343                  0.007080   \n",
            "2025-09-09                  0.035398                  0.085343   \n",
            "2025-09-10                  0.048387                  0.035398   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_6  Label_raw  Label  \n",
            "Date                                                    \n",
            "2025-09-04                  0.010381          0    1.0  \n",
            "2025-09-05                  0.028470          1    1.0  \n",
            "2025-09-08                  0.012478          1    1.0  \n",
            "2025-09-09                  0.007080          1    0.0  \n",
            "2025-09-10                  0.085343          0    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "\n",
            "Overall historical target distribution for BBAR.BA (before train/test split):\n",
            "Label\n",
            "1.0    0.69197\n",
            "0.0    0.30803\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "DEBUG: Reached feature distribution table analysis section for BBAR.BA.\n",
            "Generating feature distribution analysis table for BBAR.BA by target class...\n",
            "\n",
            "Feature Distribution Analysis Table for BBAR.BA by Target Class:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Label                                   0.0          1.0\n",
              "RSI                      count  1826.000000  4102.000000\n",
              "                         mean     52.339050    52.790074\n",
              "                         std      24.332178    24.894616\n",
              "                         min       0.000000     0.000000\n",
              "                         25%      35.294118    34.161588\n",
              "...                                     ...          ...\n",
              "Max_Gain_from_Open_Lag_6 min      -0.027778     0.000000\n",
              "                         25%       0.009609     0.012315\n",
              "                         50%       0.023962     0.031799\n",
              "                         75%       0.048536     0.062500\n",
              "                         max       2.333333     2.124378\n",
              "\n",
              "[328 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-764f54ed-51ac-49b0-98e3-f816e1042f6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">RSI</th>\n",
              "      <th>count</th>\n",
              "      <td>1826.000000</td>\n",
              "      <td>4102.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>52.339050</td>\n",
              "      <td>52.790074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>24.332178</td>\n",
              "      <td>24.894616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35.294118</td>\n",
              "      <td>34.161588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Max_Gain_from_Open_Lag_6</th>\n",
              "      <th>min</th>\n",
              "      <td>-0.027778</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.009609</td>\n",
              "      <td>0.012315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.023962</td>\n",
              "      <td>0.031799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.048536</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.124378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>328 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-764f54ed-51ac-49b0-98e3-f816e1042f6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-764f54ed-51ac-49b0-98e3-f816e1042f6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-764f54ed-51ac-49b0-98e3-f816e1042f6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0f6461db-fb19-4284-82e6-fb49b4e9e112\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f6461db-fb19-4284-82e6-fb49b4e9e112')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0f6461db-fb19-4284-82e6-fb49b4e9e112 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b8e959ae-2866-40ec-b94e-e8547e56dddd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_distribution_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b8e959ae-2866-40ec-b94e-e8547e56dddd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_distribution_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_distribution_table",
              "summary": "{\n  \"name\": \"feature_distribution_table\",\n  \"rows\": 328,\n  \"fields\": [\n    {\n      \"column\": 0.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2218.5767561275647,\n        \"min\": -32.467532467532465,\n        \"max\": 9860.0,\n        \"num_unique_values\": 242,\n        \"samples\": [\n          -7.871944869159638,\n          70.46144505160899,\n          244.9616757940854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2472.3588698776275,\n        \"min\": -41.45827056342271,\n        \"max\": 9860.0,\n        \"num_unique_values\": 228,\n        \"samples\": [\n          0.0322879982511153,\n          1.6,\n          8.385714029406188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished generating feature distribution analysis table for BBAR.BA.\n",
            "Correlacion con label para BBAR.BA:\n",
            "Label                         1.000000\n",
            "high_lag_1                    0.102475\n",
            "close_lag_1                   0.102424\n",
            "open_lag_1                    0.102082\n",
            "high_lag_2                    0.101677\n",
            "close_lag_2                   0.101671\n",
            "SMA5                          0.101554\n",
            "SMA13                         0.101335\n",
            "open_lag_5                    0.101233\n",
            "high_lag_3                    0.101142\n",
            "close_lag_5                   0.101098\n",
            "high_lag_4                    0.101062\n",
            "open_lag_2                    0.101042\n",
            "open_lag_3                    0.101000\n",
            "high_lag_5                    0.100923\n",
            "close_lag_4                   0.100823\n",
            "open_lag_4                    0.100819\n",
            "close_lag_3                   0.100795\n",
            "SMA26                         0.100699\n",
            "SMA50                         0.100206\n",
            "SMA200                        0.097080\n",
            "Volatility                    0.091043\n",
            "Max_Gain_from_Open_Lag_4      0.072055\n",
            "Max_Gain_from_Open_Lag_3      0.063872\n",
            "Max_Gain_from_Open_Lag_2      0.063385\n",
            "Max_Gain_from_Open_Lag_1      0.051232\n",
            "Max_Gain_from_Open_Current    0.044586\n",
            "Max_Gain_from_Open_Lag_6      0.034693\n",
            "Max_Gain_from_Open_Lag_5      0.024498\n",
            "lag_change1                   0.022015\n",
            "ROC                           0.020367\n",
            "EWO                           0.015259\n",
            "lag_change4                   0.014911\n",
            "EWO_Signal                    0.014308\n",
            "lag_change5                   0.010871\n",
            "PPO_Histogram                 0.009744\n",
            "RSI                           0.008424\n",
            "EWO_Histogram                 0.006730\n",
            "PPO                           0.006562\n",
            "PPO_Signal                    0.003473\n",
            "lag_change2                   0.002250\n",
            "lag_change3                  -0.000996\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para BBAR.BA\n",
            "\n",
            "Applying SMOTE to training data for BBAR.BA...\n",
            "Original training data shape: (5410, 41), Resampled shape: (7308, 41)\n",
            "Original training target distribution: Label\n",
            "1.0    3654\n",
            "0.0    1756\n",
            "Name: count, dtype: int64, Resampled target distribution: Label\n",
            "1.0    3654\n",
            "0.0    3654\n",
            "Name: count, dtype: int64\n",
            "Mejores hiperparámetros para BBAR.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for BBAR.BA:\n",
            "Max_Gain_from_Open_Current    0.042616\n",
            "open_lag_2                    0.039117\n",
            "SMA200                        0.033684\n",
            "SMA13                         0.029298\n",
            "Volatility                    0.028906\n",
            "high_lag_2                    0.026758\n",
            "high_lag_3                    0.026629\n",
            "high_lag_5                    0.026350\n",
            "open_lag_3                    0.026091\n",
            "open_lag_1                    0.025892\n",
            "close_lag_3                   0.025490\n",
            "open_lag_4                    0.025385\n",
            "close_lag_4                   0.025341\n",
            "PPO_Signal                    0.024873\n",
            "SMA50                         0.024561\n",
            "open_lag_5                    0.024408\n",
            "Max_Gain_from_Open_Lag_6      0.024208\n",
            "Max_Gain_from_Open_Lag_1      0.024129\n",
            "high_lag_1                    0.023601\n",
            "Max_Gain_from_Open_Lag_4      0.023450\n",
            "high_lag_4                    0.023387\n",
            "Max_Gain_from_Open_Lag_2      0.023036\n",
            "Max_Gain_from_Open_Lag_5      0.023016\n",
            "EWO_Histogram                 0.022518\n",
            "close_lag_1                   0.022137\n",
            "Max_Gain_from_Open_Lag_3      0.022102\n",
            "close_lag_2                   0.021653\n",
            "PPO                           0.021523\n",
            "SMA26                         0.021517\n",
            "lag_change4                   0.021469\n",
            "lag_change1                   0.021462\n",
            "EWO_Signal                    0.021300\n",
            "close_lag_5                   0.021148\n",
            "ROC                           0.021008\n",
            "lag_change5                   0.020936\n",
            "RSI                           0.020920\n",
            "PPO_Histogram                 0.020839\n",
            "lag_change2                   0.020506\n",
            "lag_change3                   0.020337\n",
            "EWO                           0.020319\n",
            "SMA5                          0.018082\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum F1-score on training data (ORIGINAL distribution) for BBAR.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor umbral para maximizar F1-score en entrenamiento (ORIGINAL distribution) para BBAR.BA: 0.3200 (F1-score: 0.9467)\n",
            "\n",
            "Evaluating best model on test set for BBAR.BA with best threshold (0.3200):\n",
            "\n",
            "Classification Report (Test Set) for BBAR.BA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        70\n",
            "         1.0       0.86      1.00      0.93       448\n",
            "\n",
            "    accuracy                           0.86       518\n",
            "   macro avg       0.43      0.50      0.46       518\n",
            "weighted avg       0.75      0.86      0.80       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para BBAR.BA:\n",
            "Label\n",
            "1.0    448\n",
            "0.0     70\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para BBAR.BA: 0.8649 \n",
            "\n",
            "ROC-AUC (Test Set) para BBAR.BA: 0.4321\n",
            "\n",
            "DEBUG: Zero values detected in last_features_cleaned for BBAR.BA.\n",
            "\n",
            "Downloading data for BMA.BA...\n",
            "MultiIndex columns detected for BMA.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for BMA.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-09-08  7365.0  7365.0  6460.0  6555.0  3488651     6555.0\n",
            "2025-09-09  6680.0  6750.0  6290.0  6305.0  1597875     6305.0\n",
            "2025-09-10  6420.0  6825.0  6400.0  6795.0  1224492     6795.0\n",
            "2025-09-11  6700.0  6920.0  6580.0  6650.0   349563     6650.0\n",
            "2025-09-12  6700.0  6700.0  6240.0  6420.0   584327     6420.0\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-09-04  7770.0  8100.0  7700.0  8010.0   405782     8010.0       7720.0   \n",
            "2025-09-05  8080.0  8200.0  7720.0  8140.0   431742     8140.0       8010.0   \n",
            "2025-09-08  7365.0  7365.0  6460.0  6555.0  3488651     6555.0       8140.0   \n",
            "2025-09-09  6680.0  6750.0  6290.0  6305.0  1597875     6305.0       6555.0   \n",
            "2025-09-10  6420.0  6825.0  6400.0  6795.0  1224492     6795.0       6305.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       7930.0       7660.0       7820.0       7930.0      8090.0   \n",
            "2025-09-05       7720.0       7930.0       7660.0       7820.0      7770.0   \n",
            "2025-09-08       8010.0       7720.0       7930.0       7660.0      8080.0   \n",
            "2025-09-09       8140.0       8010.0       7720.0       7930.0      7365.0   \n",
            "2025-09-10       6555.0       8140.0       8010.0       7720.0      6680.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      7630.0      7800.0      7940.0      7850.0      8090.0   \n",
            "2025-09-05      8090.0      7630.0      7800.0      7940.0      8100.0   \n",
            "2025-09-08      7770.0      8090.0      7630.0      7800.0      8200.0   \n",
            "2025-09-09      8080.0      7770.0      8090.0      7630.0      7365.0   \n",
            "2025-09-10      7365.0      8080.0      7770.0      8090.0      6750.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      8000.0      8130.0      7980.0      8100.0    0.037565   \n",
            "2025-09-05      8090.0      8000.0      8130.0      7980.0    0.016230   \n",
            "2025-09-08      8100.0      8090.0      8000.0      8130.0   -0.194717   \n",
            "2025-09-09      8200.0      8100.0      8090.0      8000.0   -0.038139   \n",
            "2025-09-10      7365.0      8200.0      8100.0      8090.0    0.077716   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.026482     0.035248    -0.020460    -0.013871     0.036601   \n",
            "2025-09-05     0.037565    -0.026482     0.035248    -0.020460    -0.013871   \n",
            "2025-09-08     0.016230     0.037565    -0.026482     0.035248    -0.020460   \n",
            "2025-09-09    -0.194717     0.016230     0.037565    -0.026482     0.035248   \n",
            "2025-09-10    -0.038139    -0.194717     0.016230     0.037565    -0.026482   \n",
            "\n",
            "                  RSI        ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                    \n",
            "2025-09-04  48.000000   1.008827 -1.471874   -2.166897       0.695023   \n",
            "2025-09-05  66.896552   4.092072 -0.772083   -1.701959       0.929876   \n",
            "2025-09-08  25.045372 -14.425587 -3.092428   -2.165449      -0.926980   \n",
            "2025-09-09  23.834197 -20.491803 -4.713578   -3.014825      -1.698753   \n",
            "2025-09-10  36.589147 -11.981865 -4.402057   -3.477236      -0.924821   \n",
            "\n",
            "                  EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13  \\\n",
            "Date                                                                  \n",
            "2025-09-04  -8.191389   -8.512328       0.320939  7828.0  8132.3077   \n",
            "2025-09-05  -6.974772   -7.999809       1.025037  7892.0  8100.0000   \n",
            "2025-09-08 -11.346157   -9.115259      -2.230899  7671.0  7935.7692   \n",
            "2025-09-09 -14.861184  -11.030567      -3.830617  7346.0  7751.5385   \n",
            "2025-09-10 -15.222297  -12.427811      -2.794487  7161.0  7599.6154   \n",
            "\n",
            "                SMA26   SMA50     SMA200  Volatility  \\\n",
            "Date                                                   \n",
            "2025-09-04  8797.6923  8696.4  10129.275  715.776354   \n",
            "2025-09-05  8748.4615  8688.0  10121.725  675.357800   \n",
            "2025-09-08  8637.5000  8647.1  10108.500  764.464854   \n",
            "2025-09-09  8527.6923  8602.0  10094.175  846.194267   \n",
            "2025-09-10  8429.8077  8569.7  10081.850  834.312631   \n",
            "\n",
            "            Max_Gain_from_Open_Current  Max_Gain_from_Open_Lag_1  \\\n",
            "Date                                                               \n",
            "2025-09-04                    0.055341                  0.013597   \n",
            "2025-09-05                    0.014851                  0.055341   \n",
            "2025-09-08                    0.000000                  0.014851   \n",
            "2025-09-09                    0.035928                  0.000000   \n",
            "2025-09-10                    0.077882                  0.035928   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_2  Max_Gain_from_Open_Lag_3  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.061599                  0.042308   \n",
            "2025-09-05                  0.013597                  0.061599   \n",
            "2025-09-08                  0.055341                  0.013597   \n",
            "2025-09-09                  0.014851                  0.055341   \n",
            "2025-09-10                  0.000000                  0.014851   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_4  Max_Gain_from_Open_Lag_5  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.023929                  0.035669   \n",
            "2025-09-05                  0.042308                  0.023929   \n",
            "2025-09-08                  0.061599                  0.042308   \n",
            "2025-09-09                  0.013597                  0.061599   \n",
            "2025-09-10                  0.055341                  0.013597   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_6  Label_raw  Label  \n",
            "Date                                                    \n",
            "2025-09-04                  0.000000          0    1.0  \n",
            "2025-09-05                  0.035669          1    1.0  \n",
            "2025-09-08                  0.023929          1    1.0  \n",
            "2025-09-09                  0.042308          1    1.0  \n",
            "2025-09-10                  0.061599          1    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "\n",
            "Overall historical target distribution for BMA.BA (before train/test split):\n",
            "Label\n",
            "1.0    0.687265\n",
            "0.0    0.312735\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "DEBUG: Reached feature distribution table analysis section for BMA.BA.\n",
            "Generating feature distribution analysis table for BMA.BA by target class...\n",
            "\n",
            "Feature Distribution Analysis Table for BMA.BA by Target Class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Label                                   0.0          1.0\n",
              "RSI                      count  1832.000000  4026.000000\n",
              "                         mean     53.655398    54.155427\n",
              "                         std      25.252266    25.116178\n",
              "                         min       0.000000     0.000000\n",
              "                         25%      34.740803    34.744816\n",
              "...                                     ...          ...\n",
              "Max_Gain_from_Open_Lag_6 min       0.000000    -0.022727\n",
              "                         25%       0.008000     0.012379\n",
              "                         50%       0.024327     0.031017\n",
              "                         75%       0.046479     0.059850\n",
              "                         max       2.453333     2.066667\n",
              "\n",
              "[328 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58e9d6d2-9668-4b19-b433-c5187bf070f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">RSI</th>\n",
              "      <th>count</th>\n",
              "      <td>1832.000000</td>\n",
              "      <td>4026.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>53.655398</td>\n",
              "      <td>54.155427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.252266</td>\n",
              "      <td>25.116178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>34.740803</td>\n",
              "      <td>34.744816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Max_Gain_from_Open_Lag_6</th>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.022727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.012379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.024327</td>\n",
              "      <td>0.031017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.046479</td>\n",
              "      <td>0.059850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.453333</td>\n",
              "      <td>2.066667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>328 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58e9d6d2-9668-4b19-b433-c5187bf070f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58e9d6d2-9668-4b19-b433-c5187bf070f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58e9d6d2-9668-4b19-b433-c5187bf070f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-340c5ebb-7fcb-4678-ad16-c881dc370a4c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-340c5ebb-7fcb-4678-ad16-c881dc370a4c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-340c5ebb-7fcb-4678-ad16-c881dc370a4c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b8366e92-74d4-4684-8b0b-63e17c41f3c4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_distribution_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b8366e92-74d4-4684-8b0b-63e17c41f3c4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_distribution_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_distribution_table",
              "summary": "{\n  \"name\": \"feature_distribution_table\",\n  \"rows\": 328,\n  \"fields\": [\n    {\n      \"column\": 0.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3126.1401029760095,\n        \"min\": -43.63636363636364,\n        \"max\": 14275.0,\n        \"num_unique_values\": 235,\n        \"samples\": [\n          121.19749999999999,\n          0.03724457199386007,\n          11.675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3411.126292475855,\n        \"min\": -42.19653179190752,\n        \"max\": 14500.0,\n        \"num_unique_values\": 230,\n        \"samples\": [\n          0.030967166273375542,\n          0.326,\n          8.849054377890242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished generating feature distribution analysis table for BMA.BA.\n",
            "Correlacion con label para BMA.BA:\n",
            "Label                         1.000000\n",
            "high_lag_1                    0.103232\n",
            "high_lag_2                    0.103039\n",
            "open_lag_1                    0.103035\n",
            "close_lag_1                   0.102994\n",
            "close_lag_2                   0.102914\n",
            "open_lag_2                    0.102767\n",
            "SMA5                          0.102722\n",
            "Volatility                    0.102646\n",
            "high_lag_3                    0.102602\n",
            "close_lag_3                   0.102529\n",
            "open_lag_3                    0.102265\n",
            "close_lag_4                   0.102110\n",
            "high_lag_4                    0.102033\n",
            "close_lag_5                   0.101911\n",
            "high_lag_5                    0.101822\n",
            "open_lag_4                    0.101793\n",
            "SMA13                         0.101749\n",
            "open_lag_5                    0.101375\n",
            "SMA26                         0.101047\n",
            "SMA50                         0.100193\n",
            "SMA200                        0.093373\n",
            "Max_Gain_from_Open_Lag_3      0.061427\n",
            "Max_Gain_from_Open_Lag_2      0.057380\n",
            "Max_Gain_from_Open_Lag_6      0.054881\n",
            "Max_Gain_from_Open_Lag_4      0.052504\n",
            "Max_Gain_from_Open_Lag_1      0.050225\n",
            "Max_Gain_from_Open_Current    0.029838\n",
            "EWO                           0.028971\n",
            "EWO_Signal                    0.028164\n",
            "Max_Gain_from_Open_Lag_5      0.026720\n",
            "lag_change1                   0.025653\n",
            "ROC                           0.021851\n",
            "PPO                           0.015046\n",
            "PPO_Signal                    0.013101\n",
            "lag_change5                   0.011006\n",
            "lag_change3                   0.010866\n",
            "RSI                           0.009215\n",
            "PPO_Histogram                 0.009185\n",
            "EWO_Histogram                 0.008457\n",
            "lag_change2                   0.002752\n",
            "lag_change4                   0.002514\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para BMA.BA\n",
            "\n",
            "Applying SMOTE to training data for BMA.BA...\n",
            "Original training data shape: (5340, 41), Resampled shape: (7162, 41)\n",
            "Original training target distribution: Label\n",
            "1.0    3581\n",
            "0.0    1759\n",
            "Name: count, dtype: int64, Resampled target distribution: Label\n",
            "0.0    3581\n",
            "1.0    3581\n",
            "Name: count, dtype: int64\n",
            "Mejores hiperparámetros para BMA.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for BMA.BA:\n",
            "SMA200                        0.041369\n",
            "high_lag_1                    0.041150\n",
            "high_lag_4                    0.034678\n",
            "high_lag_2                    0.032471\n",
            "Max_Gain_from_Open_Current    0.032148\n",
            "close_lag_2                   0.031255\n",
            "high_lag_5                    0.030668\n",
            "open_lag_3                    0.029870\n",
            "open_lag_2                    0.029296\n",
            "high_lag_3                    0.027484\n",
            "open_lag_1                    0.026831\n",
            "close_lag_4                   0.026574\n",
            "close_lag_1                   0.026522\n",
            "SMA26                         0.025645\n",
            "close_lag_3                   0.024539\n",
            "Volatility                    0.024343\n",
            "Max_Gain_from_Open_Lag_6      0.023489\n",
            "EWO                           0.022989\n",
            "Max_Gain_from_Open_Lag_1      0.022809\n",
            "open_lag_4                    0.022769\n",
            "Max_Gain_from_Open_Lag_3      0.022414\n",
            "SMA50                         0.022308\n",
            "lag_change1                   0.021680\n",
            "ROC                           0.021619\n",
            "SMA13                         0.021542\n",
            "EWO_Signal                    0.020956\n",
            "open_lag_5                    0.020952\n",
            "PPO                           0.020880\n",
            "lag_change3                   0.020650\n",
            "Max_Gain_from_Open_Lag_5      0.020363\n",
            "lag_change4                   0.020350\n",
            "PPO_Histogram                 0.020302\n",
            "lag_change5                   0.019876\n",
            "Max_Gain_from_Open_Lag_2      0.019585\n",
            "Max_Gain_from_Open_Lag_4      0.019479\n",
            "lag_change2                   0.019473\n",
            "EWO_Histogram                 0.019462\n",
            "RSI                           0.018935\n",
            "PPO_Signal                    0.018610\n",
            "close_lag_5                   0.018313\n",
            "SMA5                          0.015350\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum F1-score on training data (ORIGINAL distribution) for BMA.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor umbral para maximizar F1-score en entrenamiento (ORIGINAL distribution) para BMA.BA: 0.3200 (F1-score: 0.9521)\n",
            "\n",
            "Evaluating best model on test set for BMA.BA with best threshold (0.3200):\n",
            "\n",
            "Classification Report (Test Set) for BMA.BA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        73\n",
            "         1.0       0.86      1.00      0.92       445\n",
            "\n",
            "    accuracy                           0.86       518\n",
            "   macro avg       0.43      0.50      0.46       518\n",
            "weighted avg       0.74      0.86      0.79       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para BMA.BA:\n",
            "Label\n",
            "1.0    445\n",
            "0.0     73\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para BMA.BA: 0.8591 \n",
            "\n",
            "ROC-AUC (Test Set) para BMA.BA: 0.4840\n",
            "\n",
            "DEBUG: Zero values detected in last_features_cleaned for BMA.BA.\n",
            "\n",
            "Downloading data for COME.BA...\n",
            "MultiIndex columns detected for COME.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for COME.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "             Open   High    Low  Close    Volume  Adj Close\n",
            "Date                                                       \n",
            "2025-09-08  34.80  35.90  32.50  34.76  20598800      34.76\n",
            "2025-09-09  35.21  35.50  33.00  33.30  29859268      33.30\n",
            "2025-09-10  33.20  34.50  33.20  34.28  19601082      34.28\n",
            "2025-09-11  34.70  34.70  33.91  34.14  10992283      34.14\n",
            "2025-09-12  34.10  34.75  32.30  33.21   8187407      33.21\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "             Open   High    Low  Close    Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                       \n",
            "2025-09-04  40.00  41.50  38.00  38.90  32963415      38.90        39.70   \n",
            "2025-09-05  38.90  39.45  38.15  38.80  13628320      38.80        38.90   \n",
            "2025-09-08  34.80  35.90  32.50  34.76  20598800      34.76        38.80   \n",
            "2025-09-09  35.21  35.50  33.00  33.30  29859268      33.30        34.76   \n",
            "2025-09-10  33.20  34.50  33.20  34.28  19601082      34.28        33.30   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04        40.75        40.90        42.35        44.30       41.00   \n",
            "2025-09-05        39.70        40.75        40.90        42.35       40.00   \n",
            "2025-09-08        38.90        39.70        40.75        40.90       38.90   \n",
            "2025-09-09        38.80        38.90        39.70        40.75       34.80   \n",
            "2025-09-10        34.76        38.80        38.90        39.70       35.21   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04       41.35       42.40       44.30       43.50       42.20   \n",
            "2025-09-05       41.00       41.35       42.40       44.30       41.50   \n",
            "2025-09-08       40.00       41.00       41.35       42.40       39.45   \n",
            "2025-09-09       38.90       40.00       41.00       41.35       35.90   \n",
            "2025-09-10       34.80       38.90       40.00       41.00       35.50   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04       41.80       42.80        45.4        46.0   -0.020151   \n",
            "2025-09-05       42.20       41.80        42.8        45.4   -0.002571   \n",
            "2025-09-08       41.50       42.20        41.8        42.8   -0.104124   \n",
            "2025-09-09       39.45       41.50        42.2        41.8   -0.042002   \n",
            "2025-09-10       35.90       39.45        41.5        42.2    0.029429   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.025767    -0.003667    -0.034238    -0.044018     0.009112   \n",
            "2025-09-05    -0.020151    -0.025767    -0.003667    -0.034238    -0.044018   \n",
            "2025-09-08    -0.002571    -0.020151    -0.025767    -0.003667    -0.034238   \n",
            "2025-09-09    -0.104124    -0.002571    -0.020151    -0.025767    -0.003667   \n",
            "2025-09-10    -0.042002    -0.104124    -0.002571    -0.020151    -0.025767   \n",
            "\n",
            "                  RSI        ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                    \n",
            "2025-09-04   4.678363 -12.189616 -5.606235   -5.564554      -0.041681   \n",
            "2025-09-05   6.779661  -8.382527 -5.216144   -5.448417       0.232273   \n",
            "2025-09-08   0.000000 -15.012225 -6.087647   -5.661494      -0.426153   \n",
            "2025-09-09   0.000000 -18.282209 -6.769690   -6.030893      -0.738798   \n",
            "2025-09-10  11.421911 -13.652393 -6.389561   -6.150449      -0.239112   \n",
            "\n",
            "                  EWO  EWO_Signal  EWO_Histogram    SMA5    SMA13    SMA26  \\\n",
            "Date                                                                         \n",
            "2025-09-04 -20.064792  -17.816080      -2.248712  40.520  46.0769  52.7723   \n",
            "2025-09-05 -20.321971  -18.651377      -1.670594  39.810  44.7615  51.9638   \n",
            "2025-09-08 -22.552375  -19.951710      -2.600666  38.582  43.3354  51.0515   \n",
            "2025-09-09 -24.580991  -21.494803      -3.086188  37.092  41.8277  50.1858   \n",
            "2025-09-10 -24.989434  -22.659680      -2.329754  36.008  40.4569  49.3408   \n",
            "\n",
            "              SMA50   SMA200  Volatility  Max_Gain_from_Open_Current  \\\n",
            "Date                                                                   \n",
            "2025-09-04  52.6836  79.3488    8.366410                    0.037500   \n",
            "2025-09-05  52.3568  78.9390    8.455211                    0.014139   \n",
            "2025-09-08  51.9470  78.5236    8.705006                    0.031609   \n",
            "2025-09-09  51.5058  78.1086    8.808547                    0.008236   \n",
            "2025-09-10  51.1354  77.7219    8.778400                    0.046687   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_1  Max_Gain_from_Open_Lag_2  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.029268                  0.020556   \n",
            "2025-09-05                  0.037500                  0.029268   \n",
            "2025-09-08                  0.014139                  0.037500   \n",
            "2025-09-09                  0.031609                  0.014139   \n",
            "2025-09-10                  0.008236                  0.031609   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_3  Max_Gain_from_Open_Lag_4  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.009434                  0.024831   \n",
            "2025-09-05                  0.020556                  0.009434   \n",
            "2025-09-08                  0.029268                  0.020556   \n",
            "2025-09-09                  0.037500                  0.029268   \n",
            "2025-09-10                  0.014139                  0.037500   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_5  Max_Gain_from_Open_Lag_6  Label_raw  \\\n",
            "Date                                                                        \n",
            "2025-09-04                  0.057471                  0.000000          1   \n",
            "2025-09-05                  0.024831                  0.057471          1   \n",
            "2025-09-08                  0.009434                  0.024831          1   \n",
            "2025-09-09                  0.020556                  0.009434          1   \n",
            "2025-09-10                  0.029268                  0.020556          0   \n",
            "\n",
            "            Label  \n",
            "Date               \n",
            "2025-09-04    1.0  \n",
            "2025-09-05    1.0  \n",
            "2025-09-08    1.0  \n",
            "2025-09-09    0.0  \n",
            "2025-09-10    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "\n",
            "Overall historical target distribution for COME.BA (before train/test split):\n",
            "Label\n",
            "1.0    0.570756\n",
            "0.0    0.429244\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "DEBUG: Reached feature distribution table analysis section for COME.BA.\n",
            "Generating feature distribution analysis table for COME.BA by target class...\n",
            "\n",
            "Feature Distribution Analysis Table for COME.BA by Target Class:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Label                                   0.0          1.0\n",
              "RSI                      count  2096.000000  2787.000000\n",
              "                         mean     50.878266    53.236464\n",
              "                         std      33.025019    30.029602\n",
              "                         min       0.000000     0.000000\n",
              "                         25%      29.411765    33.333333\n",
              "...                                     ...          ...\n",
              "Max_Gain_from_Open_Lag_6 min       0.000000     0.000000\n",
              "                         25%       0.000000     0.000000\n",
              "                         50%       0.016632     0.029851\n",
              "                         75%       0.083333     0.071429\n",
              "                         max       3.000000     4.000000\n",
              "\n",
              "[328 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae25f46b-2600-469d-b297-45655c143f95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">RSI</th>\n",
              "      <th>count</th>\n",
              "      <td>2096.000000</td>\n",
              "      <td>2787.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>50.878266</td>\n",
              "      <td>53.236464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>33.025019</td>\n",
              "      <td>30.029602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>29.411765</td>\n",
              "      <td>33.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Max_Gain_from_Open_Lag_6</th>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.016632</td>\n",
              "      <td>0.029851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>328 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae25f46b-2600-469d-b297-45655c143f95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae25f46b-2600-469d-b297-45655c143f95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae25f46b-2600-469d-b297-45655c143f95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-056ce88f-fbaf-4446-9804-52cef9beca11\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-056ce88f-fbaf-4446-9804-52cef9beca11')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-056ce88f-fbaf-4446-9804-52cef9beca11 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_de764a4c-f2a7-4167-b498-37103b2e9ba8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_distribution_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_de764a4c-f2a7-4167-b498-37103b2e9ba8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_distribution_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_distribution_table",
              "summary": "{\n  \"name\": \"feature_distribution_table\",\n  \"rows\": 328,\n  \"fields\": [\n    {\n      \"column\": 0.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 690.9507362017125,\n        \"min\": -45.45454545454546,\n        \"max\": 2096.0,\n        \"num_unique_values\": 178,\n        \"samples\": [\n          14.496216362081396,\n          0.7716507227887779,\n          134.34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 919.1805520873817,\n        \"min\": -40.00000000000001,\n        \"max\": 2787.0,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          1.91635,\n          -9.658056559189742,\n          -0.44950948577002714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished generating feature distribution analysis table for COME.BA.\n",
            "Correlacion con label para COME.BA:\n",
            "Label                         1.000000\n",
            "Volatility                    0.171419\n",
            "high_lag_1                    0.171386\n",
            "open_lag_1                    0.171181\n",
            "close_lag_1                   0.171041\n",
            "high_lag_2                    0.171028\n",
            "high_lag_3                    0.170970\n",
            "close_lag_2                   0.170963\n",
            "SMA5                          0.170942\n",
            "open_lag_2                    0.170849\n",
            "high_lag_4                    0.170803\n",
            "close_lag_3                   0.170715\n",
            "open_lag_3                    0.170605\n",
            "open_lag_4                    0.170575\n",
            "close_lag_4                   0.170529\n",
            "SMA13                         0.170464\n",
            "high_lag_5                    0.170405\n",
            "close_lag_5                   0.170390\n",
            "open_lag_5                    0.169937\n",
            "SMA26                         0.169821\n",
            "SMA200                        0.169495\n",
            "SMA50                         0.169389\n",
            "Max_Gain_from_Open_Current    0.067044\n",
            "EWO_Signal                    0.058505\n",
            "EWO                           0.057775\n",
            "PPO                           0.039733\n",
            "PPO_Signal                    0.038475\n",
            "RSI                           0.037214\n",
            "Max_Gain_from_Open_Lag_2      0.036018\n",
            "Max_Gain_from_Open_Lag_3      0.035001\n",
            "Max_Gain_from_Open_Lag_1      0.028926\n",
            "ROC                           0.021517\n",
            "Max_Gain_from_Open_Lag_6      0.020316\n",
            "lag_change2                   0.017156\n",
            "PPO_Histogram                 0.016950\n",
            "EWO_Histogram                 0.011493\n",
            "lag_change5                   0.007965\n",
            "Max_Gain_from_Open_Lag_4      0.002118\n",
            "lag_change3                   0.002020\n",
            "lag_change1                   0.001079\n",
            "lag_change4                  -0.003918\n",
            "Max_Gain_from_Open_Lag_5     -0.007338\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para COME.BA\n",
            "\n",
            "Applying SMOTE to training data for COME.BA...\n",
            "Original training data shape: (4365, 41), Resampled shape: (4700, 41)\n",
            "Original training target distribution: Label\n",
            "1.0    2350\n",
            "0.0    2015\n",
            "Name: count, dtype: int64, Resampled target distribution: Label\n",
            "0.0    2350\n",
            "1.0    2350\n",
            "Name: count, dtype: int64\n",
            "Mejores hiperparámetros para COME.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for COME.BA:\n",
            "high_lag_2                    0.096518\n",
            "Volatility                    0.048586\n",
            "Max_Gain_from_Open_Current    0.046609\n",
            "SMA26                         0.029681\n",
            "high_lag_3                    0.027823\n",
            "close_lag_1                   0.026258\n",
            "high_lag_4                    0.024836\n",
            "open_lag_5                    0.024748\n",
            "close_lag_3                   0.022689\n",
            "high_lag_1                    0.022661\n",
            "high_lag_5                    0.022516\n",
            "PPO                           0.022070\n",
            "open_lag_1                    0.021955\n",
            "Max_Gain_from_Open_Lag_1      0.021686\n",
            "Max_Gain_from_Open_Lag_6      0.021526\n",
            "close_lag_4                   0.021425\n",
            "Max_Gain_from_Open_Lag_5      0.021221\n",
            "SMA50                         0.021176\n",
            "open_lag_4                    0.020951\n",
            "PPO_Signal                    0.020881\n",
            "EWO_Histogram                 0.020863\n",
            "EWO_Signal                    0.020774\n",
            "SMA200                        0.020773\n",
            "SMA13                         0.020497\n",
            "open_lag_3                    0.020463\n",
            "Max_Gain_from_Open_Lag_2      0.020037\n",
            "open_lag_2                    0.020020\n",
            "ROC                           0.019958\n",
            "lag_change2                   0.019930\n",
            "Max_Gain_from_Open_Lag_3      0.019911\n",
            "lag_change1                   0.019867\n",
            "RSI                           0.019844\n",
            "close_lag_2                   0.019842\n",
            "lag_change3                   0.019581\n",
            "EWO                           0.019558\n",
            "lag_change5                   0.019457\n",
            "Max_Gain_from_Open_Lag_4      0.019200\n",
            "PPO_Histogram                 0.019158\n",
            "lag_change4                   0.019074\n",
            "SMA5                          0.018060\n",
            "close_lag_5                   0.017317\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum F1-score on training data (ORIGINAL distribution) for COME.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor umbral para maximizar F1-score en entrenamiento (ORIGINAL distribution) para COME.BA: 0.3600 (F1-score: 0.9520)\n",
            "\n",
            "Evaluating best model on test set for COME.BA with best threshold (0.3600):\n",
            "\n",
            "Classification Report (Test Set) for COME.BA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.01      0.02        81\n",
            "         1.0       0.84      1.00      0.92       437\n",
            "\n",
            "    accuracy                           0.84       518\n",
            "   macro avg       0.67      0.51      0.47       518\n",
            "weighted avg       0.79      0.84      0.78       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para COME.BA:\n",
            "Label\n",
            "1.0    437\n",
            "0.0     81\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para COME.BA: 0.8436 \n",
            "\n",
            "ROC-AUC (Test Set) para COME.BA: 0.5479\n",
            "\n",
            "Downloading data for CRES.BA...\n",
            "MultiIndex columns detected for CRES.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for CRES.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close  Volume  Adj Close\n",
            "Date                                                         \n",
            "2025-09-08  1270.0  1300.0  1217.0  1271.0  707563     1271.0\n",
            "2025-09-09  1267.0  1301.0  1237.0  1239.0  381354     1239.0\n",
            "2025-09-10  1270.0  1284.0  1228.0  1278.0  304007     1278.0\n",
            "2025-09-11  1285.0  1330.0  1255.0  1273.0  377957     1273.0\n",
            "2025-09-12  1275.0  1285.0  1234.0  1254.0  330141     1254.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close  Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04  1300.0  1360.0  1265.0  1325.0  664275     1325.0       1305.0   \n",
            "2025-09-05  1325.0  1355.0  1300.0  1335.0  503476     1335.0       1325.0   \n",
            "2025-09-08  1270.0  1300.0  1217.0  1271.0  707563     1271.0       1335.0   \n",
            "2025-09-09  1267.0  1301.0  1237.0  1239.0  381354     1239.0       1271.0   \n",
            "2025-09-10  1270.0  1284.0  1228.0  1278.0  304007     1278.0       1239.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       1350.0       1325.0       1355.0       1395.0      1340.0   \n",
            "2025-09-05       1305.0       1350.0       1325.0       1355.0      1300.0   \n",
            "2025-09-08       1325.0       1305.0       1350.0       1325.0      1325.0   \n",
            "2025-09-09       1335.0       1325.0       1305.0       1350.0      1270.0   \n",
            "2025-09-10       1271.0       1335.0       1325.0       1305.0      1267.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      1335.0      1355.0      1400.0      1385.0      1375.0   \n",
            "2025-09-05      1340.0      1335.0      1355.0      1400.0      1360.0   \n",
            "2025-09-08      1300.0      1340.0      1335.0      1355.0      1355.0   \n",
            "2025-09-09      1325.0      1300.0      1340.0      1335.0      1300.0   \n",
            "2025-09-10      1270.0      1325.0      1300.0      1340.0      1301.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      1370.0      1370.0      1410.0      1415.0    0.015326   \n",
            "2025-09-05      1375.0      1370.0      1370.0      1410.0    0.007547   \n",
            "2025-09-08      1360.0      1375.0      1370.0      1370.0   -0.047940   \n",
            "2025-09-09      1355.0      1360.0      1375.0      1370.0   -0.025177   \n",
            "2025-09-10      1300.0      1355.0      1360.0      1375.0    0.031477   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.033333     0.018868    -0.022140    -0.028674     0.000000   \n",
            "2025-09-05     0.015326    -0.033333     0.018868    -0.022140    -0.028674   \n",
            "2025-09-08     0.007547     0.015326    -0.033333     0.018868    -0.022140   \n",
            "2025-09-09    -0.047940     0.007547     0.015326    -0.033333     0.018868   \n",
            "2025-09-10    -0.025177    -0.047940     0.007547     0.015326    -0.033333   \n",
            "\n",
            "                  RSI       ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                   \n",
            "2025-09-04  23.684211 -5.017921 -1.568769   -1.430066      -0.138704   \n",
            "2025-09-05  32.352941 -1.476015 -1.283405   -1.381179       0.097774   \n",
            "2025-09-08  23.504274 -4.075472 -1.693711   -1.485356      -0.208355   \n",
            "2025-09-09  24.336283 -8.222222 -2.141673   -1.704128      -0.437544   \n",
            "2025-09-10  40.000000 -2.068966 -1.840794   -1.749683      -0.091110   \n",
            "\n",
            "                 EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13      SMA26  \\\n",
            "Date                                                                            \n",
            "2025-09-04 -4.763231   -3.747683      -1.015548  1332.0  1381.5385  1435.3846   \n",
            "2025-09-05 -4.559292   -4.018220      -0.541073  1328.0  1377.6923  1428.4615   \n",
            "2025-09-08 -5.636568   -4.557669      -1.078899  1317.2  1368.9231  1419.0769   \n",
            "2025-09-09 -6.875933   -5.330424      -1.545509  1295.0  1354.6154  1409.6154   \n",
            "2025-09-10 -6.753535   -5.804794      -0.948741  1289.6  1340.2308  1400.8846   \n",
            "\n",
            "              SMA50    SMA200  Volatility  Max_Gain_from_Open_Current  \\\n",
            "Date                                                                    \n",
            "2025-09-04  1408.90  1396.400   58.608312                    0.046154   \n",
            "2025-09-05  1409.80  1397.150   58.202799                    0.022642   \n",
            "2025-09-08  1409.42  1397.655   63.311656                    0.024409   \n",
            "2025-09-09  1408.30  1398.050   67.897756                    0.049724   \n",
            "2025-09-10  1407.86  1398.540   65.524523                    0.047244   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_1  Max_Gain_from_Open_Lag_2  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.026119                  0.029963   \n",
            "2025-09-05                  0.046154                  0.026119   \n",
            "2025-09-08                  0.022642                  0.046154   \n",
            "2025-09-09                  0.024409                  0.022642   \n",
            "2025-09-10                  0.049724                  0.024409   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_3  Max_Gain_from_Open_Lag_4  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.014760                  0.007143   \n",
            "2025-09-05                  0.029963                  0.014760   \n",
            "2025-09-08                  0.026119                  0.029963   \n",
            "2025-09-09                  0.046154                  0.026119   \n",
            "2025-09-10                  0.022642                  0.046154   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_5  Max_Gain_from_Open_Lag_6  Label_raw  \\\n",
            "Date                                                                        \n",
            "2025-09-04                  0.021661                  0.000000          1   \n",
            "2025-09-05                  0.007143                  0.021661          1   \n",
            "2025-09-08                  0.014760                  0.007143          1   \n",
            "2025-09-09                  0.029963                  0.014760          1   \n",
            "2025-09-10                  0.026119                  0.029963          1   \n",
            "\n",
            "            Label  \n",
            "Date               \n",
            "2025-09-04    1.0  \n",
            "2025-09-05    1.0  \n",
            "2025-09-08    1.0  \n",
            "2025-09-09    1.0  \n",
            "2025-09-10    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "\n",
            "Overall historical target distribution for CRES.BA (before train/test split):\n",
            "Label\n",
            "1.0    0.620352\n",
            "0.0    0.379648\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "DEBUG: Reached feature distribution table analysis section for CRES.BA.\n",
            "Generating feature distribution analysis table for CRES.BA by target class...\n",
            "\n",
            "Feature Distribution Analysis Table for CRES.BA by Target Class:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Label                                   0.0          1.0\n",
              "RSI                      count  2246.000000  3670.000000\n",
              "                         mean     52.933957    52.317664\n",
              "                         std      26.445104    25.455665\n",
              "                         min       0.000000     0.000000\n",
              "                         25%      33.969156    33.333333\n",
              "...                                     ...          ...\n",
              "Max_Gain_from_Open_Lag_6 min       0.000000     0.000000\n",
              "                         25%       0.003687     0.008828\n",
              "                         50%       0.019540     0.027237\n",
              "                         75%       0.042816     0.054197\n",
              "                         max       0.946768     0.969231\n",
              "\n",
              "[328 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a725e2a4-4909-41cd-9ca9-2ff16de8ad59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">RSI</th>\n",
              "      <th>count</th>\n",
              "      <td>2246.000000</td>\n",
              "      <td>3670.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>52.933957</td>\n",
              "      <td>52.317664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>26.445104</td>\n",
              "      <td>25.455665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.969156</td>\n",
              "      <td>33.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Max_Gain_from_Open_Lag_6</th>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.003687</td>\n",
              "      <td>0.008828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.019540</td>\n",
              "      <td>0.027237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.042816</td>\n",
              "      <td>0.054197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.946768</td>\n",
              "      <td>0.969231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>328 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a725e2a4-4909-41cd-9ca9-2ff16de8ad59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a725e2a4-4909-41cd-9ca9-2ff16de8ad59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a725e2a4-4909-41cd-9ca9-2ff16de8ad59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9218364c-b06b-4180-85bb-7febfe55f042\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9218364c-b06b-4180-85bb-7febfe55f042')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9218364c-b06b-4180-85bb-7febfe55f042 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f9b0190b-cc44-43fe-9b0a-580da33c2aed\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_distribution_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f9b0190b-cc44-43fe-9b0a-580da33c2aed button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_distribution_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_distribution_table",
              "summary": "{\n  \"name\": \"feature_distribution_table\",\n  \"rows\": 328,\n  \"fields\": [\n    {\n      \"column\": 0.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 795.3598543849315,\n        \"min\": -38.262910798122064,\n        \"max\": 2246.0,\n        \"num_unique_values\": 225,\n        \"samples\": [\n          6.576701097132229,\n          62.0105520926091,\n          -0.012448132780083054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1225.3201654556406,\n        \"min\": -31.531531531531538,\n        \"max\": 3670.0,\n        \"num_unique_values\": 230,\n        \"samples\": [\n          0.0545215240471091,\n          0.54,\n          8.081095303280533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished generating feature distribution analysis table for CRES.BA.\n",
            "Correlacion con label para CRES.BA:\n",
            "Label                         1.000000\n",
            "Volatility                    0.160670\n",
            "high_lag_2                    0.154254\n",
            "high_lag_3                    0.154199\n",
            "high_lag_4                    0.154151\n",
            "high_lag_1                    0.153946\n",
            "open_lag_3                    0.153906\n",
            "open_lag_1                    0.153852\n",
            "close_lag_2                   0.153846\n",
            "open_lag_4                    0.153823\n",
            "open_lag_2                    0.153796\n",
            "close_lag_5                   0.153657\n",
            "high_lag_5                    0.153645\n",
            "SMA5                          0.153611\n",
            "close_lag_4                   0.153597\n",
            "close_lag_3                   0.153584\n",
            "close_lag_1                   0.153364\n",
            "open_lag_5                    0.153022\n",
            "SMA13                         0.152940\n",
            "SMA26                         0.152026\n",
            "SMA50                         0.150828\n",
            "SMA200                        0.142999\n",
            "Max_Gain_from_Open_Current    0.121072\n",
            "Max_Gain_from_Open_Lag_1      0.089178\n",
            "Max_Gain_from_Open_Lag_4      0.088744\n",
            "Max_Gain_from_Open_Lag_3      0.085609\n",
            "Max_Gain_from_Open_Lag_5      0.084699\n",
            "Max_Gain_from_Open_Lag_2      0.078683\n",
            "Max_Gain_from_Open_Lag_6      0.076766\n",
            "EWO_Signal                    0.023399\n",
            "EWO                           0.018184\n",
            "lag_change5                   0.015565\n",
            "lag_change2                   0.014122\n",
            "lag_change4                   0.002967\n",
            "PPO_Signal                    0.002620\n",
            "PPO                          -0.004489\n",
            "ROC                          -0.007366\n",
            "RSI                          -0.011578\n",
            "lag_change3                  -0.012558\n",
            "EWO_Histogram                -0.018416\n",
            "PPO_Histogram                -0.018520\n",
            "lag_change1                  -0.020337\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para CRES.BA\n",
            "\n",
            "Applying SMOTE to training data for CRES.BA...\n",
            "Original training data shape: (5398, 41), Resampled shape: (6472, 41)\n",
            "Original training target distribution: Label\n",
            "1.0    3236\n",
            "0.0    2162\n",
            "Name: count, dtype: int64, Resampled target distribution: Label\n",
            "1.0    3236\n",
            "0.0    3236\n",
            "Name: count, dtype: int64\n",
            "Mejores hiperparámetros para CRES.BA: {'subsample': 0.8, 'scale_pos_weight': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "\n",
            "Feature Importance for CRES.BA:\n",
            "Volatility                    0.050940\n",
            "SMA50                         0.040502\n",
            "SMA200                        0.034386\n",
            "open_lag_5                    0.033956\n",
            "close_lag_2                   0.033778\n",
            "high_lag_4                    0.030286\n",
            "open_lag_3                    0.028993\n",
            "close_lag_3                   0.028449\n",
            "Max_Gain_from_Open_Current    0.027476\n",
            "high_lag_1                    0.026605\n",
            "close_lag_1                   0.026097\n",
            "open_lag_1                    0.025919\n",
            "SMA13                         0.025805\n",
            "close_lag_4                   0.025454\n",
            "open_lag_2                    0.023935\n",
            "high_lag_2                    0.023444\n",
            "high_lag_5                    0.022941\n",
            "SMA26                         0.022806\n",
            "EWO_Histogram                 0.022447\n",
            "high_lag_3                    0.022272\n",
            "Max_Gain_from_Open_Lag_2      0.021527\n",
            "EWO_Signal                    0.021365\n",
            "PPO_Signal                    0.021223\n",
            "RSI                           0.021201\n",
            "lag_change5                   0.021201\n",
            "EWO                           0.021128\n",
            "open_lag_4                    0.020950\n",
            "lag_change2                   0.020581\n",
            "Max_Gain_from_Open_Lag_5      0.020577\n",
            "Max_Gain_from_Open_Lag_1      0.020460\n",
            "ROC                           0.020379\n",
            "Max_Gain_from_Open_Lag_3      0.020314\n",
            "lag_change1                   0.020207\n",
            "close_lag_5                   0.019866\n",
            "lag_change4                   0.019855\n",
            "PPO                           0.019596\n",
            "Max_Gain_from_Open_Lag_4      0.019356\n",
            "PPO_Histogram                 0.019307\n",
            "lag_change3                   0.018929\n",
            "Max_Gain_from_Open_Lag_6      0.017976\n",
            "SMA5                          0.017513\n",
            "dtype: float32\n",
            "Optimizing threshold for maximum F1-score on training data (ORIGINAL distribution) for CRES.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor umbral para maximizar F1-score en entrenamiento (ORIGINAL distribution) para CRES.BA: 0.3100 (F1-score: 0.9543)\n",
            "\n",
            "Evaluating best model on test set for CRES.BA with best threshold (0.3100):\n",
            "\n",
            "Classification Report (Test Set) for CRES.BA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        84\n",
            "         1.0       0.84      1.00      0.91       434\n",
            "\n",
            "    accuracy                           0.84       518\n",
            "   macro avg       0.42      0.50      0.46       518\n",
            "weighted avg       0.70      0.84      0.76       518\n",
            "\n",
            "Tamaño de y_test (cleaned): 518\n",
            "Distribución de clases en y_test (cleaned) para CRES.BA:\n",
            "Label\n",
            "1.0    434\n",
            "0.0     84\n",
            "Name: count, dtype: int64\n",
            "% clase 1 test para CRES.BA: 0.8378 \n",
            "\n",
            "ROC-AUC (Test Set) para CRES.BA: 0.4519\n",
            "\n",
            "Downloading data for EDN.BA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex columns detected for EDN.BA.\n",
            "Successfully extracted and flattened MultiIndex columns for EDN.BA.\n",
            "Últimas filas del DataFrame antes de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close\n",
            "Date                                                          \n",
            "2025-09-08  1380.0  1380.0  1255.0  1258.0  1505729     1258.0\n",
            "2025-09-09  1280.0  1322.0  1245.0  1259.0  1488830     1259.0\n",
            "2025-09-10  1300.0  1358.0  1268.0  1351.0  1052553     1351.0\n",
            "2025-09-11  1358.0  1388.0  1291.0  1297.0   769554     1297.0\n",
            "2025-09-12  1310.0  1310.0  1210.0  1248.0   773007     1248.0\n",
            "\n",
            "Últimas filas del DataFrame después de crear features:\n",
            "              Open    High     Low   Close   Volume  Adj Close  close_lag_1  \\\n",
            "Date                                                                          \n",
            "2025-09-04  1420.0  1495.0  1415.0  1480.0   759997     1480.0       1415.0   \n",
            "2025-09-05  1450.0  1520.0  1435.0  1515.0   984492     1515.0       1480.0   \n",
            "2025-09-08  1380.0  1380.0  1255.0  1258.0  1505729     1258.0       1515.0   \n",
            "2025-09-09  1280.0  1322.0  1245.0  1259.0  1488830     1259.0       1258.0   \n",
            "2025-09-10  1300.0  1358.0  1268.0  1351.0  1052553     1351.0       1259.0   \n",
            "\n",
            "            close_lag_2  close_lag_3  close_lag_4  close_lag_5  open_lag_1  \\\n",
            "Date                                                                         \n",
            "2025-09-04       1430.0       1410.0       1455.0       1500.0      1430.0   \n",
            "2025-09-05       1415.0       1430.0       1410.0       1455.0      1420.0   \n",
            "2025-09-08       1480.0       1415.0       1430.0       1410.0      1450.0   \n",
            "2025-09-09       1515.0       1480.0       1415.0       1430.0      1380.0   \n",
            "2025-09-10       1258.0       1515.0       1480.0       1415.0      1280.0   \n",
            "\n",
            "            open_lag_2  open_lag_3  open_lag_4  open_lag_5  high_lag_1  \\\n",
            "Date                                                                     \n",
            "2025-09-04      1440.0      1455.0      1500.0      1470.0      1485.0   \n",
            "2025-09-05      1430.0      1440.0      1455.0      1500.0      1495.0   \n",
            "2025-09-08      1420.0      1430.0      1440.0      1455.0      1520.0   \n",
            "2025-09-09      1450.0      1420.0      1430.0      1440.0      1380.0   \n",
            "2025-09-10      1380.0      1450.0      1420.0      1430.0      1322.0   \n",
            "\n",
            "            high_lag_2  high_lag_3  high_lag_4  high_lag_5  Pct_change  \\\n",
            "Date                                                                     \n",
            "2025-09-04      1460.0      1475.0      1520.0      1530.0    0.045936   \n",
            "2025-09-05      1485.0      1460.0      1475.0      1520.0    0.023649   \n",
            "2025-09-08      1495.0      1485.0      1460.0      1475.0   -0.169637   \n",
            "2025-09-09      1520.0      1495.0      1485.0      1460.0    0.000795   \n",
            "2025-09-10      1380.0      1520.0      1495.0      1485.0    0.073074   \n",
            "\n",
            "            lag_change1  lag_change2  lag_change3  lag_change4  lag_change5  \\\n",
            "Date                                                                          \n",
            "2025-09-04    -0.010490     0.014184    -0.030928    -0.030000     0.045296   \n",
            "2025-09-05     0.045936    -0.010490     0.014184    -0.030928    -0.030000   \n",
            "2025-09-08     0.023649     0.045936    -0.010490     0.014184    -0.030928   \n",
            "2025-09-09    -0.169637     0.023649     0.045936    -0.010490     0.014184   \n",
            "2025-09-10     0.000795    -0.169637     0.023649     0.045936    -0.010490   \n",
            "\n",
            "                  RSI        ROC       PPO  PPO_Signal  PPO_Histogram  \\\n",
            "Date                                                                    \n",
            "2025-09-04  50.000000  -1.333333 -2.135459   -3.087734       0.952275   \n",
            "2025-09-05  63.793103   4.123711 -1.153110   -2.442859       1.289750   \n",
            "2025-09-08  24.896266 -10.780142 -2.946813   -2.610844      -0.335969   \n",
            "2025-09-09  27.625571 -11.958042 -3.774925   -2.998871      -0.776054   \n",
            "2025-09-10  43.917526  -4.522968 -3.076658   -3.024800      -0.051858   \n",
            "\n",
            "                  EWO  EWO_Signal  EWO_Histogram    SMA5      SMA13  \\\n",
            "Date                                                                  \n",
            "2025-09-04 -11.772406  -12.176573       0.404168  1438.0  1505.0000   \n",
            "2025-09-05 -10.129443  -11.494197       1.364753  1450.0  1491.1538   \n",
            "2025-09-08 -13.399909  -12.129434      -1.270475  1419.6  1464.4615   \n",
            "2025-09-09 -15.299133  -13.186000      -2.113132  1385.4  1437.0769   \n",
            "2025-09-10 -14.633985  -13.668662      -0.965323  1372.6  1419.8462   \n",
            "\n",
            "                SMA26    SMA50    SMA200  Volatility  \\\n",
            "Date                                                   \n",
            "2025-09-04  1716.1538  1680.30  2006.250  203.669624   \n",
            "2025-09-05  1701.5385  1678.70  2004.375  194.227722   \n",
            "2025-09-08  1675.3077  1671.76  2001.465  198.804162   \n",
            "2025-09-09  1649.5000  1663.64  1998.585  198.762726   \n",
            "2025-09-10  1625.5000  1658.66  1995.865  179.328066   \n",
            "\n",
            "            Max_Gain_from_Open_Current  Max_Gain_from_Open_Lag_1  \\\n",
            "Date                                                               \n",
            "2025-09-04                    0.070423                  0.062937   \n",
            "2025-09-05                    0.048276                  0.070423   \n",
            "2025-09-08                    0.000000                  0.048276   \n",
            "2025-09-09                    0.084375                  0.000000   \n",
            "2025-09-10                    0.067692                  0.084375   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_2  Max_Gain_from_Open_Lag_3  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.038194                  0.020619   \n",
            "2025-09-05                  0.062937                  0.038194   \n",
            "2025-09-08                  0.070423                  0.062937   \n",
            "2025-09-09                  0.048276                  0.070423   \n",
            "2025-09-10                  0.000000                  0.048276   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_4  Max_Gain_from_Open_Lag_5  \\\n",
            "Date                                                             \n",
            "2025-09-04                  0.013333                  0.040816   \n",
            "2025-09-05                  0.020619                  0.013333   \n",
            "2025-09-08                  0.038194                  0.020619   \n",
            "2025-09-09                  0.062937                  0.038194   \n",
            "2025-09-10                  0.070423                  0.062937   \n",
            "\n",
            "            Max_Gain_from_Open_Lag_6  Label_raw  Label  \n",
            "Date                                                    \n",
            "2025-09-04                  0.033784          1    1.0  \n",
            "2025-09-05                  0.040816          1    1.0  \n",
            "2025-09-08                  0.013333          1    1.0  \n",
            "2025-09-09                  0.020619          1    1.0  \n",
            "2025-09-10                  0.038194          1    0.0  \n",
            "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'close_lag_1',\n",
            "       'close_lag_2', 'close_lag_3', 'close_lag_4', 'close_lag_5',\n",
            "       'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_4', 'open_lag_5',\n",
            "       'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_4', 'high_lag_5',\n",
            "       'Pct_change', 'lag_change1', 'lag_change2', 'lag_change3',\n",
            "       'lag_change4', 'lag_change5', 'RSI', 'ROC', 'PPO', 'PPO_Signal',\n",
            "       'PPO_Histogram', 'EWO', 'EWO_Signal', 'EWO_Histogram', 'SMA5', 'SMA13',\n",
            "       'SMA26', 'SMA50', 'SMA200', 'Volatility', 'Max_Gain_from_Open_Current',\n",
            "       'Max_Gain_from_Open_Lag_1', 'Max_Gain_from_Open_Lag_2',\n",
            "       'Max_Gain_from_Open_Lag_3', 'Max_Gain_from_Open_Lag_4',\n",
            "       'Max_Gain_from_Open_Lag_5', 'Max_Gain_from_Open_Lag_6', 'Label_raw',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "\n",
            "Overall historical target distribution for EDN.BA (before train/test split):\n",
            "Label\n",
            "1.0    0.725577\n",
            "0.0    0.274423\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "DEBUG: Reached feature distribution table analysis section for EDN.BA.\n",
            "Generating feature distribution analysis table for EDN.BA by target class...\n",
            "\n",
            "Feature Distribution Analysis Table for EDN.BA by Target Class:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Label                                   0.0          1.0\n",
              "RSI                      count  1177.000000  3112.000000\n",
              "                         mean     51.239581    52.243195\n",
              "                         std      25.934395    25.488300\n",
              "                         min       0.000000     0.000000\n",
              "                         25%      31.343284    33.129098\n",
              "...                                     ...          ...\n",
              "Max_Gain_from_Open_Lag_6 min       0.000000    -0.014286\n",
              "                         25%       0.009662     0.011791\n",
              "                         50%       0.026316     0.031536\n",
              "                         75%       0.055160     0.065789\n",
              "                         max       3.368932     3.411765\n",
              "\n",
              "[328 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-633c05a7-25fc-4703-b45f-4a8def4a963d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">RSI</th>\n",
              "      <th>count</th>\n",
              "      <td>1177.000000</td>\n",
              "      <td>3112.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>51.239581</td>\n",
              "      <td>52.243195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.934395</td>\n",
              "      <td>25.488300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>31.343284</td>\n",
              "      <td>33.129098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">Max_Gain_from_Open_Lag_6</th>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.009662</td>\n",
              "      <td>0.011791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.031536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.055160</td>\n",
              "      <td>0.065789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.368932</td>\n",
              "      <td>3.411765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>328 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-633c05a7-25fc-4703-b45f-4a8def4a963d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-633c05a7-25fc-4703-b45f-4a8def4a963d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-633c05a7-25fc-4703-b45f-4a8def4a963d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-50435128-12d2-4687-9232-89f833733bff\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50435128-12d2-4687-9232-89f833733bff')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-50435128-12d2-4687-9232-89f833733bff button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f8136c82-86aa-4f00-a470-0d7e998cc323\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_distribution_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f8136c82-86aa-4f00-a470-0d7e998cc323 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_distribution_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_distribution_table",
              "summary": "{\n  \"name\": \"feature_distribution_table\",\n  \"rows\": 328,\n  \"fields\": [\n    {\n      \"column\": 0.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 707.2735335605129,\n        \"min\": -28.363065361977714,\n        \"max\": 2825.0,\n        \"num_unique_values\": 236,\n        \"samples\": [\n          2628.0,\n          120.69203058623619,\n          39.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1.0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1147.38628960718,\n        \"min\": -69.30232558139534,\n        \"max\": 3112.0,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          0.10457392861495868,\n          0.556,\n          9.900701789360289\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished generating feature distribution analysis table for EDN.BA.\n",
            "Correlacion con label para EDN.BA:\n",
            "Label                         1.000000\n",
            "Volatility                    0.092790\n",
            "high_lag_2                    0.092041\n",
            "high_lag_1                    0.091952\n",
            "open_lag_2                    0.091774\n",
            "close_lag_2                   0.091624\n",
            "close_lag_1                   0.091549\n",
            "open_lag_1                    0.091467\n",
            "close_lag_3                   0.091342\n",
            "SMA5                          0.091264\n",
            "high_lag_3                    0.091061\n",
            "SMA13                         0.090891\n",
            "open_lag_3                    0.090391\n",
            "close_lag_4                   0.090370\n",
            "SMA26                         0.090336\n",
            "open_lag_5                    0.090291\n",
            "close_lag_5                   0.090262\n",
            "high_lag_5                    0.090148\n",
            "high_lag_4                    0.090137\n",
            "open_lag_4                    0.090055\n",
            "SMA50                         0.089287\n",
            "SMA200                        0.087495\n",
            "Max_Gain_from_Open_Current    0.072709\n",
            "Max_Gain_from_Open_Lag_1      0.068376\n",
            "Max_Gain_from_Open_Lag_2      0.065951\n",
            "Max_Gain_from_Open_Lag_3      0.062516\n",
            "Max_Gain_from_Open_Lag_4      0.058350\n",
            "Max_Gain_from_Open_Lag_5      0.057192\n",
            "EWO                           0.041623\n",
            "EWO_Signal                    0.040997\n",
            "ROC                           0.040093\n",
            "lag_change3                   0.037360\n",
            "Max_Gain_from_Open_Lag_6      0.030261\n",
            "PPO                           0.025331\n",
            "PPO_Signal                    0.023894\n",
            "lag_change1                   0.022870\n",
            "RSI                           0.017487\n",
            "lag_change5                   0.013318\n",
            "PPO_Histogram                 0.010696\n",
            "EWO_Histogram                 0.009447\n",
            "lag_change4                   0.009142\n",
            "lag_change2                  -0.001792\n",
            "Name: Label, dtype: float64\n",
            "Optimizar hiperparámetros con RandomizedSearchCV para EDN.BA\n",
            "\n",
            "Applying SMOTE to training data for EDN.BA...\n",
            "Original training data shape: (3771, 41), Resampled shape: (5338, 41)\n",
            "Original training target distribution: Label\n",
            "1.0    2669\n",
            "0.0    1102\n",
            "Name: count, dtype: int64, Resampled target distribution: Label\n",
            "1.0    2669\n",
            "0.0    2669\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-851338570.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    484\u001b[0m                   \u001b[0;31m# Fit RandomizedSearchCV on the resampled training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                   \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtscv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Usar precision_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                   \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Fit on resampled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mejores hiperparámetros para {symbol}:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}